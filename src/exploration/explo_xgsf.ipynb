{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T16:52:01.742896Z",
     "start_time": "2025-11-24T16:52:01.341017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "train_enhanced = pd.read_csv('../../data/train_pivot.csv', sep = ',')\n",
    "eval_enhanced = pd.read_csv('../../data/eval_pivot.csv', sep = ',')\n"
   ],
   "id": "ec8d70b4c7051f9e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T16:52:02.481466Z",
     "start_time": "2025-11-24T16:52:01.747902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.util import Surv\n",
    "\n",
    "time_col = \"OS_YEARS\"\n",
    "event_col = \"OS_STATUS\"\n",
    "\n",
    "# Build feature matrix X by dropping time/event/ID from train_enhanced\n",
    "exclude_cols = {time_col, event_col, \"ID\"}\n",
    "feature_cols = [c for c in train_enhanced.columns if c not in exclude_cols]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = train_enhanced[feature_cols].to_numpy(dtype=float, na_value=0.0)\n",
    "\n",
    "time_vals = train_enhanced[time_col].to_numpy(dtype=float)\n",
    "event_vals = train_enhanced[event_col].to_numpy(dtype=bool)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'time': time_vals,\n",
    "    'event': event_vals\n",
    "})\n",
    "\n",
    "y = Surv.from_dataframe(\"event\", \"time\", df)\n",
    "\n"
   ],
   "id": "51c6141502934001",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Résumé du plan:\n",
    "- Préparer les données à partir de train_enhanced et y (temps et statut).\n",
    "- Entraîner un XGB AFT avec K-fold cross-validation (K=5 par défaut) et évaluer les scores via concordance (C-index).\n",
    "- Former le modèle sur l’ensemble des données et faire des prédictions sur le jeu d’évaluation, en générant un CSV avec les colonnes \"ID\" et \"risk_score\" (risque = opposé du temps de survie).\n",
    "- Sauvegarder le CSV final dans le répertoire approprié."
   ],
   "id": "e455c1051fdd899f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T16:52:02.849434Z",
     "start_time": "2025-11-24T16:52:02.785646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "import xgboost as xgb  # <--- ajout important\n",
    "\n",
    "# Chargement des données existantes\n",
    "train_enhanced = pd.read_csv('../../data/train_pivot.csv', sep = ',')\n",
    "eval_enhanced = pd.read_csv('../../data/eval_pivot.csv', sep = ',')\n",
    "\n",
    "time_col = \"OS_YEARS\"\n",
    "event_col = \"OS_STATUS\"\n",
    "exclude_cols = {time_col, event_col, \"ID\"}\n",
    "feature_cols = [c for c in train_enhanced.columns if c not in exclude_cols]\n",
    "\n",
    "X = train_enhanced[feature_cols].fillna(0.0).to_numpy(dtype=float)\n",
    "time_vals = train_enhanced[time_col].to_numpy(dtype=float)     # temps bruts\n",
    "event_vals = train_enhanced[event_col].to_numpy(dtype=bool)    # 1 = event, 0 = censuré\n",
    "\n",
    "# Préparer y pour XGBoost AFT : log(1 + temps)\n",
    "y_log_time = np.log1p(time_vals)\n"
   ],
   "id": "4a6de7d85c7437e9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T16:52:04.613403Z",
     "start_time": "2025-11-24T16:52:03.500683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Paramètres AFT\n",
    "params = {\n",
    "    \"objective\": \"survival:aft\",\n",
    "    \"eval_metric\": \"aft-nloglik\",\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"max_depth\": 4,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"min_child_weight\": 1,\n",
    "    \"gamma\": 0.0,\n",
    "    \"aft_loss_distribution\": \"normal\",\n",
    "    \"aft_loss_distribution_scale\": 1.0,\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "num_boost_round = 200\n",
    "\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "c_indices = []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, val_idx in kf.split(X):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train_log, y_val_log = y_log_time[train_idx], y_log_time[val_idx]\n",
    "    e_train, e_val = event_vals[train_idx], event_vals[val_idx]\n",
    "\n",
    "    # Bornes inf / sup en log-temps :\n",
    "    # - non censuré : [log(t), log(t)]\n",
    "    # - censuré à droite : [log(t), +inf]\n",
    "    lb_train = y_train_log.copy()\n",
    "    ub_train = y_train_log.copy()\n",
    "    ub_train[e_train == 0] = np.inf\n",
    "\n",
    "    lb_val = y_val_log.copy()\n",
    "    ub_val = y_val_log.copy()\n",
    "    ub_val[e_val == 0] = np.inf\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train)\n",
    "    dtrain.set_float_info(\"label_lower_bound\", lb_train)\n",
    "    dtrain.set_float_info(\"label_upper_bound\", ub_train)\n",
    "\n",
    "    dval = xgb.DMatrix(X_val)\n",
    "    dval.set_float_info(\"label_lower_bound\", lb_val)\n",
    "    dval.set_float_info(\"label_upper_bound\", ub_val)\n",
    "\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        evals=[(dval, \"valid\")],\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "\n",
    "    # Prédictions de log-temps sur la validation\n",
    "    y_pred_log = model.predict(dval)\n",
    "\n",
    "    # C-index : on prend -y_pred_log comme \"risque\"\n",
    "    c_index = concordance_index_censored(\n",
    "    e_val.astype(bool),      # event_indicator\n",
    "    time_vals[val_idx],      # event_time\n",
    "    -y_pred_log)[0]\n",
    "\n",
    "\n",
    "    c_indices.append(c_index)\n",
    "    print(f\"Fold {fold} — C-index: {c_index:.4f}\")\n",
    "    fold += 1\n",
    "\n",
    "print(\"\\nC-index moyen :\", np.mean(c_indices))\n"
   ],
   "id": "8d8d9440a44816d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 — C-index: 0.7475\n",
      "Fold 2 — C-index: 0.7134\n",
      "Fold 3 — C-index: 0.7453\n",
      "Fold 4 — C-index: 0.7248\n",
      "Fold 5 — C-index: 0.7225\n",
      "\n",
      "C-index moyen : 0.7307112247567796\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Entraînement sur l'ensemble complet et prédiction",
   "id": "8370f7ff8ef04267"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T16:52:06.733796Z",
     "start_time": "2025-11-24T16:52:06.578771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_full = train_enhanced[feature_cols].fillna(0.0).to_numpy(dtype=float)\n",
    "y_full_log_time = np.log1p(time_vals)\n",
    "\n",
    "lb_full = y_full_log_time.copy()\n",
    "ub_full = y_full_log_time.copy()\n",
    "ub_full[event_vals == 0] = np.inf\n",
    "\n",
    "dfull = xgb.DMatrix(X_full)\n",
    "dfull.set_float_info(\"label_lower_bound\", lb_full)\n",
    "dfull.set_float_info(\"label_upper_bound\", ub_full)\n",
    "\n",
    "model_full = xgb.train(\n",
    "    params,\n",
    "    dfull,\n",
    "    num_boost_round=num_boost_round,\n",
    "    verbose_eval=False\n",
    ")"
   ],
   "id": "4010b40ec265d465",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tuning des hyperparamètres XGBoost AFT avec Optuna",
   "id": "e014582f27bac2db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T16:52:06.776977Z",
     "start_time": "2025-11-24T16:52:06.741508Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install optuna",
   "id": "448c33fe85a91fdc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T16:52:08.418608Z",
     "start_time": "2025-11-24T16:52:08.300152Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sksurv.metrics import concordance_index_censored"
   ],
   "id": "10b91a07f3f53b08",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T16:52:08.969863Z",
     "start_time": "2025-11-24T16:52:08.965047Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"survival:aft\",\n",
    "        \"eval_metric\": \"aft-nloglik\",\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.3, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 7),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
    "        \"aft_loss_distribution\": trial.suggest_categorical(\"aft_loss_distribution\", [\"normal\", \"logistic\", \"extreme\"]),\n",
    "        \"aft_loss_distribution_scale\": trial.suggest_float(\"aft_loss_distribution_scale\", 0.3, 2.0),\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"seed\": 42,\n",
    "    }\n",
    "\n",
    "    num_boost_round = trial.suggest_int(\"num_boost_round\", 50, 500)\n",
    "\n",
    "    n_splits = 7\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    c_indices = []\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "        y_train_log_fold, y_val_log_fold = y_log_time[train_idx], y_log_time[val_idx]\n",
    "        e_train_fold, e_val_fold = event_vals[train_idx], event_vals[val_idx]\n",
    "\n",
    "        lb_train_fold = y_train_log_fold.copy()\n",
    "        ub_train_fold = y_train_log_fold.copy()\n",
    "        ub_train_fold[e_train_fold == 0] = np.inf\n",
    "\n",
    "        lb_val_fold = y_val_log_fold.copy()\n",
    "        ub_val_fold = y_val_log_fold.copy()\n",
    "        ub_val_fold[e_val_fold == 0] = np.inf\n",
    "\n",
    "        dtrain_fold = xgb.DMatrix(X_train_fold)\n",
    "        dtrain_fold.set_float_info(\"label_lower_bound\", lb_train_fold)\n",
    "        dtrain_fold.set_float_info(\"label_upper_bound\", ub_train_fold)\n",
    "\n",
    "        dval_fold = xgb.DMatrix(X_val_fold)\n",
    "        dval_fold.set_float_info(\"label_lower_bound\", lb_val_fold)\n",
    "        dval_fold.set_float_info(\"label_upper_bound\", ub_val_fold)\n",
    "\n",
    "        model_fold = xgb.train(\n",
    "            params,\n",
    "            dtrain_fold,\n",
    "            num_boost_round=num_boost_round,\n",
    "            evals=[(dval_fold, \"valid\")],\n",
    "            verbose_eval=False,\n",
    "        )\n",
    "\n",
    "        y_pred_log_fold = model_fold.predict(dval_fold)\n",
    "\n",
    "        c_index = concordance_index_censored(\n",
    "            e_val_fold.astype(bool),\n",
    "            time_vals[val_idx],\n",
    "            -y_pred_log_fold\n",
    "        )[0]\n",
    "\n",
    "        c_indices.append(c_index)\n",
    "\n",
    "    return np.mean(c_indices)"
   ],
   "id": "4e029f85d0c24fb5",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T17:29:06.036072Z",
     "start_time": "2025-11-24T16:52:09.696541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "study = optuna.create_study(direction=\"maximize\", study_name=\"xgb_aft_tuning\")\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study.optimize(objective, n_trials=1000, show_progress_bar=True)"
   ],
   "id": "c6b51be58d744ec7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-24 17:52:09,698] A new study created in memory with name: xgb_aft_tuning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "24f7cb68669e4b4eb24bec0bbbb1a749"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T20:33:33.142120Z",
     "start_time": "2025-11-24T20:33:33.138621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Meilleurs hyperparamètres:\")\n",
    "print(study.best_params)\n",
    "print(f\"\\nMeilleur C-index moyen: {study.best_value:.4f}\")"
   ],
   "id": "70bb8a6015964d91",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyperparamètres:\n",
      "{'learning_rate': 0.013914798174316866, 'max_depth': 4, 'subsample': 0.6154145891104238, 'colsample_bytree': 0.622522206489519, 'min_child_weight': 6, 'gamma': 4.147781712513235, 'aft_loss_distribution': 'extreme', 'aft_loss_distribution_scale': 0.5696884124763241, 'num_boost_round': 439}\n",
      "\n",
      "Meilleur C-index moyen: 0.7423\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Save current results and retrain with different seeds\n",
    "\n",
    "Saving the current best model results (seed=42) and retraining with 4 additional seeds (36, 500, 4321, 137)."
   ],
   "id": "3eafc48adab84747"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T17:52:36.424884Z",
     "start_time": "2025-11-24T17:52:36.419224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "results_dir = '../../results'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "results_seed_42 = {\n",
    "    'seed': 42,\n",
    "    'best_params': best_params.copy(),\n",
    "    'best_num_boost_round': best_num_boost_round,\n",
    "    'best_c_index': study.best_value,\n",
    "    'submission_file': 'submission_xgb_aft_tuned_avg10.csv'\n",
    "}\n",
    "\n",
    "with open(f'{results_dir}/xgb_aft_seed_42.json', 'w') as f:\n",
    "    json.dump(results_seed_42, f, indent=2)\n",
    "\n",
    "print(\"Results for seed 42 saved to 'results/xgb_aft_seed_42.json'\")"
   ],
   "id": "6bc8f8b14b99308d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for seed 42 saved to 'results/xgb_aft_seed_42.json'\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T20:23:59.680446Z",
     "start_time": "2025-11-24T17:52:55.844343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "additional_seeds = [36, 500, 4321, 137]\n",
    "all_seed_results = [results_seed_42]\n",
    "\n",
    "for seed_value in additional_seeds:\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"Starting tuning with seed={seed_value}\")\n",
    "    print(f\"{'=' * 60}\\n\")\n",
    "\n",
    "\n",
    "    def objective_seed(trial):\n",
    "        params = {\n",
    "            \"objective\": \"survival:aft\",\n",
    "            \"eval_metric\": \"aft-nloglik\",\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.3, log=True),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 7),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n",
    "            \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
    "            \"aft_loss_distribution\": trial.suggest_categorical(\"aft_loss_distribution\",\n",
    "                                                               [\"normal\", \"logistic\", \"extreme\"]),\n",
    "            \"aft_loss_distribution_scale\": trial.suggest_float(\"aft_loss_distribution_scale\", 0.3, 2.0),\n",
    "            \"tree_method\": \"hist\",\n",
    "            \"seed\": seed_value,\n",
    "        }\n",
    "\n",
    "        num_boost_round = trial.suggest_int(\"num_boost_round\", 50, 500)\n",
    "\n",
    "        n_splits = 7\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed_value)\n",
    "\n",
    "        c_indices = []\n",
    "\n",
    "        for train_idx, val_idx in kf.split(X):\n",
    "            X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "            y_train_log_fold, y_val_log_fold = y_log_time[train_idx], y_log_time[val_idx]\n",
    "            e_train_fold, e_val_fold = event_vals[train_idx], event_vals[val_idx]\n",
    "\n",
    "            lb_train_fold = y_train_log_fold.copy()\n",
    "            ub_train_fold = y_train_log_fold.copy()\n",
    "            ub_train_fold[e_train_fold == 0] = np.inf\n",
    "\n",
    "            lb_val_fold = y_val_log_fold.copy()\n",
    "            ub_val_fold = y_val_log_fold.copy()\n",
    "            ub_val_fold[e_val_fold == 0] = np.inf\n",
    "\n",
    "            dtrain_fold = xgb.DMatrix(X_train_fold)\n",
    "            dtrain_fold.set_float_info(\"label_lower_bound\", lb_train_fold)\n",
    "            dtrain_fold.set_float_info(\"label_upper_bound\", ub_train_fold)\n",
    "\n",
    "            dval_fold = xgb.DMatrix(X_val_fold)\n",
    "            dval_fold.set_float_info(\"label_lower_bound\", lb_val_fold)\n",
    "            dval_fold.set_float_info(\"label_upper_bound\", ub_val_fold)\n",
    "\n",
    "            model_fold = xgb.train(\n",
    "                params,\n",
    "                dtrain_fold,\n",
    "                num_boost_round=num_boost_round,\n",
    "                evals=[(dval_fold, \"valid\")],\n",
    "                verbose_eval=False,\n",
    "            )\n",
    "\n",
    "            y_pred_log_fold = model_fold.predict(dval_fold)\n",
    "\n",
    "            c_index = concordance_index_censored(\n",
    "                e_val_fold.astype(bool),\n",
    "                time_vals[val_idx],\n",
    "                -y_pred_log_fold\n",
    "            )[0]\n",
    "\n",
    "            c_indices.append(c_index)\n",
    "\n",
    "        return np.mean(c_indices)\n",
    "\n",
    "\n",
    "    study_seed = optuna.create_study(direction=\"maximize\", study_name=f\"xgb_aft_seed_{seed_value}\")\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "    study_seed.optimize(objective_seed, n_trials=1000, show_progress_bar=True)\n",
    "\n",
    "    print(f\"\\nBest C-index for seed {seed_value}: {study_seed.best_value:.4f}\")\n",
    "\n",
    "    best_params_seed = study_seed.best_params.copy()\n",
    "    best_params_seed[\"objective\"] = \"survival:aft\"\n",
    "    best_params_seed[\"eval_metric\"] = \"aft-nloglik\"\n",
    "    best_params_seed[\"tree_method\"] = \"hist\"\n",
    "    best_params_seed[\"seed\"] = seed_value\n",
    "\n",
    "    best_num_boost_round_seed = best_params_seed.pop(\"num_boost_round\")\n",
    "\n",
    "    lb_full_seed = y_full_log_time.copy()\n",
    "    ub_full_seed = y_full_log_time.copy()\n",
    "    ub_full_seed[event_vals == 0] = np.inf\n",
    "\n",
    "    dfull_seed = xgb.DMatrix(X_full)\n",
    "    dfull_seed.set_float_info(\"label_lower_bound\", lb_full_seed)\n",
    "    dfull_seed.set_float_info(\"label_upper_bound\", ub_full_seed)\n",
    "\n",
    "    model_tuned_seed = xgb.train(\n",
    "        best_params_seed,\n",
    "        dfull_seed,\n",
    "        num_boost_round=best_num_boost_round_seed,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "\n",
    "    X_eval_seed = eval_enhanced[feature_cols].fillna(0.0).to_numpy(dtype=float)\n",
    "    deval_seed = xgb.DMatrix(X_eval_seed)\n",
    "\n",
    "    y_pred_log_seed = model_tuned_seed.predict(deval_seed)\n",
    "    risk_score_seed = -y_pred_log_seed\n",
    "\n",
    "    submission_seed = pd.DataFrame({\n",
    "        'ID': eval_enhanced['ID'],\n",
    "        'risk_score': risk_score_seed\n",
    "    })\n",
    "\n",
    "    results_seed = {\n",
    "        'seed': seed_value,\n",
    "        'best_params': best_params_seed.copy(),\n",
    "        'best_num_boost_round': best_num_boost_round_seed,\n",
    "        'best_c_index': study_seed.best_value,\n",
    "    }\n",
    "\n",
    "    with open(f'{results_dir}/xgb_aft_seed_{seed_value}.json', 'w') as f:\n",
    "        json.dump(results_seed, f, indent=2)\n",
    "\n",
    "    all_seed_results.append(results_seed)\n",
    "\n",
    "    print(f\"Results saved to 'results/xgb_aft_seed_{seed_value}.json'\")"
   ],
   "id": "73b015debec1ec41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Starting tuning with seed=36\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "358594d4048047659aed3a4f8fd55984"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best C-index for seed 36: 0.7444\n",
      "Results saved to 'results/xgb_aft_seed_36.json'\n",
      "\n",
      "============================================================\n",
      "Starting tuning with seed=500\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad936d5e77044cf1808c8b66257d4007"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best C-index for seed 500: 0.7435\n",
      "Results saved to 'results/xgb_aft_seed_500.json'\n",
      "\n",
      "============================================================\n",
      "Starting tuning with seed=4321\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3b1b553aacd34a37a90bc356387c3dc6"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best C-index for seed 4321: 0.7426\n",
      "Results saved to 'results/xgb_aft_seed_4321.json'\n",
      "\n",
      "============================================================\n",
      "Starting tuning with seed=137\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "480510fabb024b9b836b63a6a5059420"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best C-index for seed 137: 0.7448\n",
      "Results saved to 'results/xgb_aft_seed_137.json'\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T21:20:09.407177Z",
     "start_time": "2025-11-24T21:20:09.404653Z"
    }
   },
   "cell_type": "code",
   "source": "#TODO: Simplifier tt ça et déseeder le kfold",
   "id": "6ae00a24bac6549b",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T20:24:07.670180Z",
     "start_time": "2025-11-24T20:24:07.660276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUMMARY OF ALL SEEDS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "summary_df = pd.DataFrame([\n",
    "    {\n",
    "        'Seed': r['seed'],\n",
    "        'Best C-Index': r['best_c_index'],\n",
    "        'Num Boost Rounds': r['best_num_boost_round'],\n",
    "    }\n",
    "    for r in all_seed_results\n",
    "])\n",
    "\n",
    "summary_df"
   ],
   "id": "6e8d6216cbf6d7c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUMMARY OF ALL SEEDS\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   Seed  Best C-Index  Num Boost Rounds\n",
       "0    42      0.742321               439\n",
       "1    36      0.744425               468\n",
       "2   500      0.743527               474\n",
       "3  4321      0.742554               256\n",
       "4   137      0.744798               361"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seed</th>\n",
       "      <th>Best C-Index</th>\n",
       "      <th>Num Boost Rounds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>0.742321</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>0.744425</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>0.743527</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4321</td>\n",
       "      <td>0.742554</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137</td>\n",
       "      <td>0.744798</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Smart Weighted Ensemble of 5 Seeded Models\n",
    "\n",
    "Creating a weighted ensemble that:\n",
    "1. Normalizes predictions by dividing by absolute mean\n",
    "2. Weights models by their best C-index\n",
    "3. Evaluates in K-Fold CV\n",
    "4. Generates final submission"
   ],
   "id": "a90816b7fff7217d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T20:32:19.777093Z",
     "start_time": "2025-11-24T20:32:19.772848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "seeds_to_use = [42, 36, 500, 4321, 137]\n",
    "\n",
    "best_params_per_seed = {}\n",
    "for seed_val in seeds_to_use:\n",
    "    json_path = f'{results_dir}/xgb_aft_seed_{seed_val}.json'\n",
    "    with open(json_path, 'r') as f:\n",
    "        seed_data = json.load(f)\n",
    "        best_params_per_seed[seed_val] = seed_data\n",
    "\n",
    "print(\"Loaded best parameters for all seeds\")\n",
    "for seed_val in seeds_to_use:\n",
    "    print(f\"Seed {seed_val}: C-Index = {best_params_per_seed[seed_val]['best_c_index']:.4f}\")"
   ],
   "id": "b02cfe941c2261cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best parameters for all seeds\n",
      "Seed 42: C-Index = 0.7423\n",
      "Seed 36: C-Index = 0.7444\n",
      "Seed 500: C-Index = 0.7435\n",
      "Seed 4321: C-Index = 0.7426\n",
      "Seed 137: C-Index = 0.7448\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "import xgboost as xgb\n",
    "\n",
    "def train_and_predict_seed_model(seed_val, dtrain, dval):\n",
    "    best_params = best_params_per_seed[seed_val]['best_params'].copy()\n",
    "    \n",
    "    params = {\n",
    "        \"objective\": \"survival:aft\",\n",
    "        \"eval_metric\": \"aft-nloglik\",\n",
    "        \"learning_rate\": best_params['learning_rate'],\n",
    "        \"max_depth\": best_params['max_depth'],\n",
    "        \"subsample\": best_params['subsample'],\n",
    "        \"colsample_bytree\": best_params['colsample_bytree'],\n",
    "        \"min_child_weight\": best_params['min_child_weight'],\n",
    "        \"gamma\": best_params['gamma'],\n",
    "        \"aft_loss_distribution\": best_params['aft_loss_distribution'],\n",
    "        \"aft_loss_distribution_scale\": best_params['aft_loss_distribution_scale'],\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"seed\": seed_val,\n",
    "    }\n",
    "    \n",
    "    num_boost_round = best_params_per_seed[seed_val]['best_num_boost_round']\n",
    "    best_c = best_params_per_seed[seed_val]['best_c_index']\n",
    "    \n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        evals=[(dval, \"valid\")],\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "    \n",
    "    y_pred_log = model.predict(dval)\n",
    "    \n",
    "    return y_pred_log, best_c\n",
    "    \n",
    "    #c_index = concordance_index_censored(\n",
    "    #    e_val.astype(bool),\n",
    "    #    time_vals[val_idx],\n",
    "    #    -y_pred_log\n",
    "    #)[0]\n",
    "   # \n",
    "   #     c_indices.append(c_index)\n",
    "   #     print(f\"Fold {fold} — C-index: {c_index:.4f}\")\n",
    "   #     fold += 1\n",
    "   # \n",
    "   #print(f\"\\nC-index moyen : {np.mean(c_indices):.4f}\")"
   ],
   "id": "3a2d23b9c17255a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T21:00:14.970060Z",
     "start_time": "2025-11-24T21:00:03.116605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Evaluating Weighted Ensemble with K-Fold Cross-Validation\\n\")\n",
    "\n",
    "kf_ensemble = KFold(n_splits=7, shuffle=True)\n",
    "cv_scores_ensemble = []\n",
    "\n",
    "fold = 1\n",
    "    \n",
    "seeds_score = {}\n",
    "for seed_val in seeds_to_use:\n",
    "    seeds_score[seed_val] = []\n",
    "for train_idx, val_idx in kf.split(X):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train_log, y_val_log = y_log_time[train_idx], y_log_time[val_idx]\n",
    "    e_train, e_val = event_vals[train_idx], event_vals[val_idx]\n",
    "    \n",
    "    lb_train = y_train_log.copy()\n",
    "    ub_train = y_train_log.copy()\n",
    "    ub_train[e_train == 0] = np.inf\n",
    "    \n",
    "    lb_val = y_val_log.copy()\n",
    "    ub_val = y_val_log.copy()\n",
    "    ub_val[e_val == 0] = np.inf\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train)\n",
    "    dtrain.set_float_info(\"label_lower_bound\", lb_train)\n",
    "    dtrain.set_float_info(\"label_upper_bound\", ub_train)\n",
    "    \n",
    "    dval = xgb.DMatrix(X_val)\n",
    "    dval.set_float_info(\"label_lower_bound\", lb_val)\n",
    "    dval.set_float_info(\"label_upper_bound\", ub_val)\n",
    "\n",
    "    \n",
    "    for seed_val in seeds_to_use:\n",
    "        y_pred_log, best_c = train_and_predict_seed_model(seed_val, dtrain, dval)\n",
    "        c_index = concordance_index_censored(\n",
    "            e_val.astype(bool),\n",
    "            time_vals[val_idx],\n",
    "            -y_pred_log\n",
    "        )[0]\n",
    "        \n",
    "        print(f\"Fold {fold} >> Model seed {seed_val} - Best C-Index: {best_c:.4f}. ON FOLD: {c_index}\")\n",
    "        seeds_score[seed_val].append(c_index)\n",
    "\n",
    "    fold += 1\n",
    "    \n",
    "scores_final = [np.mean(seeds_score[seed]) for seed in seeds_to_use]\n",
    "print(scores_final)\n",
    "print(np.mean(scores_final))"
   ],
   "id": "632d96ee83a9fc25",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Weighted Ensemble with K-Fold Cross-Validation\n",
      "\n",
      "Fold 1 >> Model seed 42 - Best C-Index: 0.7423. ON FOLD: 0.7590540364945889\n",
      "Fold 1 >> Model seed 36 - Best C-Index: 0.7444. ON FOLD: 0.7590911622208609\n",
      "Fold 1 >> Model seed 500 - Best C-Index: 0.7435. ON FOLD: 0.7600749939670695\n",
      "Fold 1 >> Model seed 4321 - Best C-Index: 0.7426. ON FOLD: 0.759258227989085\n",
      "Fold 1 >> Model seed 137 - Best C-Index: 0.7448. ON FOLD: 0.7508492509884724\n",
      "Fold 2 >> Model seed 42 - Best C-Index: 0.7423. ON FOLD: 0.7351578106272473\n",
      "Fold 2 >> Model seed 36 - Best C-Index: 0.7444. ON FOLD: 0.7318617658809429\n",
      "Fold 2 >> Model seed 500 - Best C-Index: 0.7435. ON FOLD: 0.7298242109468638\n",
      "Fold 2 >> Model seed 4321 - Best C-Index: 0.7426. ON FOLD: 0.7302836596084699\n",
      "Fold 2 >> Model seed 137 - Best C-Index: 0.7448. ON FOLD: 0.7302636835797044\n",
      "Fold 3 >> Model seed 42 - Best C-Index: 0.7423. ON FOLD: 0.7164540056669494\n",
      "Fold 3 >> Model seed 36 - Best C-Index: 0.7444. ON FOLD: 0.721850240935588\n",
      "Fold 3 >> Model seed 500 - Best C-Index: 0.7435. ON FOLD: 0.7225721453193524\n",
      "Fold 3 >> Model seed 4321 - Best C-Index: 0.7426. ON FOLD: 0.7188362901333718\n",
      "Fold 3 >> Model seed 137 - Best C-Index: 0.7448. ON FOLD: 0.7151004349473912\n",
      "Fold 4 >> Model seed 42 - Best C-Index: 0.7423. ON FOLD: 0.786312567584905\n",
      "Fold 4 >> Model seed 36 - Best C-Index: 0.7444. ON FOLD: 0.7727314382067777\n",
      "Fold 4 >> Model seed 500 - Best C-Index: 0.7435. ON FOLD: 0.7790912923150235\n",
      "Fold 4 >> Model seed 4321 - Best C-Index: 0.7426. ON FOLD: 0.7715401110683455\n",
      "Fold 4 >> Model seed 137 - Best C-Index: 0.7448. ON FOLD: 0.7855977713018456\n",
      "Fold 5 >> Model seed 42 - Best C-Index: 0.7423. ON FOLD: 0.7396831683168317\n",
      "Fold 5 >> Model seed 36 - Best C-Index: 0.7444. ON FOLD: 0.7388712871287129\n",
      "Fold 5 >> Model seed 500 - Best C-Index: 0.7435. ON FOLD: 0.7382772277227723\n",
      "Fold 5 >> Model seed 4321 - Best C-Index: 0.7426. ON FOLD: 0.7426534653465346\n",
      "Fold 5 >> Model seed 137 - Best C-Index: 0.7448. ON FOLD: 0.7331683168316832\n",
      "Fold 6 >> Model seed 42 - Best C-Index: 0.7423. ON FOLD: 0.7044826614040034\n",
      "Fold 6 >> Model seed 36 - Best C-Index: 0.7444. ON FOLD: 0.7004416878112959\n",
      "Fold 6 >> Model seed 500 - Best C-Index: 0.7435. ON FOLD: 0.7006484352974345\n",
      "Fold 6 >> Model seed 4321 - Best C-Index: 0.7426. ON FOLD: 0.6990508410863641\n",
      "Fold 6 >> Model seed 137 - Best C-Index: 0.7448. ON FOLD: 0.7073583309839301\n",
      "Fold 7 >> Model seed 42 - Best C-Index: 0.7423. ON FOLD: 0.7551020408163265\n",
      "Fold 7 >> Model seed 36 - Best C-Index: 0.7444. ON FOLD: 0.7501358670189839\n",
      "Fold 7 >> Model seed 500 - Best C-Index: 0.7435. ON FOLD: 0.7526283240568955\n",
      "Fold 7 >> Model seed 4321 - Best C-Index: 0.7426. ON FOLD: 0.7488990086392684\n",
      "Fold 7 >> Model seed 137 - Best C-Index: 0.7448. ON FOLD: 0.7549895991454433\n",
      "[np.float64(0.7423208987015502), np.float64(0.7392833498861661), np.float64(0.7404452328036302), np.float64(0.7386459434102056), np.float64(0.7396181982540673)]\n",
      "0.7400627246111238\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T21:11:01.375901Z",
     "start_time": "2025-11-24T21:10:49.372883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Evaluating Weighted Ensemble with K-Fold Cross-Validation\\n\")\n",
    "\n",
    "kf_ensemble = KFold(n_splits=7, shuffle=True)\n",
    "cv_scores_ensemble = []\n",
    "\n",
    "fold = 1\n",
    "    \n",
    "fold_score = []\n",
    "for seed_val in seeds_to_use:\n",
    "    seeds_score[seed_val] = []\n",
    "for train_idx, val_idx in kf.split(X):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train_log, y_val_log = y_log_time[train_idx], y_log_time[val_idx]\n",
    "    e_train, e_val = event_vals[train_idx], event_vals[val_idx]\n",
    "    \n",
    "    lb_train = y_train_log.copy()\n",
    "    ub_train = y_train_log.copy()\n",
    "    ub_train[e_train == 0] = np.inf\n",
    "    \n",
    "    lb_val = y_val_log.copy()\n",
    "    ub_val = y_val_log.copy()\n",
    "    ub_val[e_val == 0] = np.inf\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train)\n",
    "    dtrain.set_float_info(\"label_lower_bound\", lb_train)\n",
    "    dtrain.set_float_info(\"label_upper_bound\", ub_train)\n",
    "    \n",
    "    dval = xgb.DMatrix(X_val)\n",
    "    dval.set_float_info(\"label_lower_bound\", lb_val)\n",
    "    dval.set_float_info(\"label_upper_bound\", ub_val)\n",
    "\n",
    "    y_preds = []\n",
    "    for seed_val in seeds_to_use:\n",
    "        y_pred_log, best_c = train_and_predict_seed_model(seed_val, dtrain, dval)\n",
    "        best_cs.append(best_c)\n",
    "        \n",
    "        y_preds.append(best_c * y_pred_log / np.mean(np.abs(y_pred_log)))\n",
    "    \n",
    "    y_preds_comb = np.array(y_preds).sum(axis=0)\n",
    "    c_index = concordance_index_censored(\n",
    "        e_val.astype(bool),\n",
    "        time_vals[val_idx],\n",
    "        -y_preds_comb\n",
    "    )[0]\n",
    "        \n",
    "    print(f\"Fold {fold} >> {c_index}\")\n",
    "    fold_score.append(c_index)\n",
    "\n",
    "    fold += 1\n",
    "    \n",
    "print(np.mean(fold_score))"
   ],
   "id": "d3dcae989154430",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Weighted Ensemble with K-Fold Cross-Validation\n",
      "\n",
      "Fold 1 >> 0.7593881680310371\n",
      "Fold 2 >> 0.7328006392329205\n",
      "Fold 3 >> 0.720514717825624\n",
      "Fold 4 >> 0.7804842286614981\n",
      "Fold 5 >> 0.7414059405940594\n",
      "Fold 6 >> 0.7031669955831219\n",
      "Fold 7 >> 0.7536402990948445\n",
      "0.7416287127175866\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T21:13:23.289934Z",
     "start_time": "2025-11-24T21:13:21.772559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_cs = []\n",
    "for seed_val in seeds_to_use:\n",
    "    best_params = best_params_per_seed[seed_val]['best_params'].copy()\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"survival:aft\",\n",
    "        \"eval_metric\": \"aft-nloglik\",\n",
    "        \"learning_rate\": best_params['learning_rate'],\n",
    "        \"max_depth\": best_params['max_depth'],\n",
    "        \"subsample\": best_params['subsample'],\n",
    "        \"colsample_bytree\": best_params['colsample_bytree'],\n",
    "        \"min_child_weight\": best_params['min_child_weight'],\n",
    "        \"gamma\": best_params['gamma'],\n",
    "        \"aft_loss_distribution\": best_params['aft_loss_distribution'],\n",
    "        \"aft_loss_distribution_scale\": best_params['aft_loss_distribution_scale'],\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"seed\": seed_val,\n",
    "    }\n",
    "\n",
    "    num_boost_round = best_params_per_seed[seed_val]['best_num_boost_round']\n",
    "\n",
    "    lb_full = y_full_log_time.copy()\n",
    "    ub_full = y_full_log_time.copy()\n",
    "    ub_full[event_vals == 0] = np.inf\n",
    "\n",
    "    dfull = xgb.DMatrix(X_full)\n",
    "    dfull.set_float_info(\"label_lower_bound\", lb_full)\n",
    "    dfull.set_float_info(\"label_upper_bound\", ub_full)\n",
    "\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dfull,\n",
    "        num_boost_round=num_boost_round,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "\n",
    "    X_eval = eval_enhanced[feature_cols].fillna(0.0).to_numpy(dtype=float)\n",
    "    deval = xgb.DMatrix(X_eval)\n",
    "\n",
    "    y_pred_log = model.predict(deval)\n",
    "\n",
    "    best_c = best_params_per_seed[seed_val]['best_c_index']\n",
    "    best_cs.append(best_c)\n",
    "\n",
    "    pred_normalized = y_pred_log / np.mean(np.abs(y_pred_log))\n",
    "\n",
    "    if seed_val == seeds_to_use[0]:\n",
    "        weighted_pred = best_c * pred_normalized\n",
    "    else:\n",
    "        weighted_pred += best_c * pred_normalized\n",
    "\n",
    "    print(f\"Seed {seed_val} trained on full data, best_c={best_c:.4f}\")"
   ],
   "id": "d32bd13eeaf0b2b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 42 trained on full data, best_c=0.7423\n",
      "Seed 36 trained on full data, best_c=0.7444\n",
      "Seed 500 trained on full data, best_c=0.7435\n",
      "Seed 4321 trained on full data, best_c=0.7426\n",
      "Seed 137 trained on full data, best_c=0.7448\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T21:13:23.318927Z",
     "start_time": "2025-11-24T21:13:23.310741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "risk_scores = -weighted_pred\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'ID': eval_enhanced['ID'],\n",
    "    'risk_score': risk_scores\n",
    "})\n",
    "\n",
    "submission.to_csv('../../submissions/submission_xgb_aft_weighted_ensemble.csv', index=False)\n",
    "\n",
    "print(\"Submission saved to: ../../submissions/submission_xgb_aft_weighted_ensemble.csv\")\n"
   ],
   "id": "a3f65ea1f5cf6a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to: ../../submissions/submission_xgb_aft_weighted_ensemble.csv\n"
     ]
    }
   ],
   "execution_count": 81
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
