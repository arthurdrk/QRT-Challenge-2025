{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51c6141502934001",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T16:52:02.481466Z",
     "start_time": "2025-11-24T16:52:01.747902Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.util import Surv\n",
    "\n",
    "time_col = \"OS_YEARS\"\n",
    "event_col = \"OS_STATUS\"\n",
    "\n",
    "# Build feature matrix X by dropping time/event/ID from train_enhanced\n",
    "exclude_cols = {time_col, event_col, \"ID\"}\n",
    "feature_cols = [c for c in train_enhanced.columns if c not in exclude_cols]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = train_enhanced[feature_cols].to_numpy(dtype=float, na_value=0.0)\n",
    "\n",
    "time_vals = train_enhanced[time_col].to_numpy(dtype=float)\n",
    "event_vals = train_enhanced[event_col].to_numpy(dtype=bool)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'time': time_vals,\n",
    "    'event': event_vals\n",
    "})\n",
    "\n",
    "y = Surv.from_dataframe(\"event\", \"time\", df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e455c1051fdd899f",
   "metadata": {},
   "source": [
    "Résumé du plan:\n",
    "- Préparer les données à partir de train_enhanced et y (temps et statut).\n",
    "- Entraîner un XGB AFT avec K-fold cross-validation (K=5 par défaut) et évaluer les scores via concordance (C-index).\n",
    "- Former le modèle sur l’ensemble des données et faire des prédictions sur le jeu d’évaluation, en générant un CSV avec les colonnes \"ID\" et \"risk_score\" (risque = opposé du temps de survie).\n",
    "- Sauvegarder le CSV final dans le répertoire approprié."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a6de7d85c7437e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T16:52:02.849434Z",
     "start_time": "2025-11-24T16:52:02.785646Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "import xgboost as xgb  # <--- ajout important\n",
    "\n",
    "# Chargement des données existantes\n",
    "train_enhanced = pd.read_csv('../../data/train_enhanced_V2.csv', sep = ',')\n",
    "eval_enhanced = pd.read_csv('../../data/eval_enhanced_V2.csv', sep = ',')\n",
    "\n",
    "time_col = \"OS_YEARS\"\n",
    "event_col = \"OS_STATUS\"\n",
    "exclude_cols = {time_col, event_col, \"ID\"}\n",
    "feature_cols = [c for c in train_enhanced.columns if c not in exclude_cols]\n",
    "\n",
    "X = train_enhanced[feature_cols].fillna(0.0).to_numpy(dtype=float)\n",
    "time_vals = train_enhanced[time_col].to_numpy(dtype=float)     # temps bruts\n",
    "event_vals = train_enhanced[event_col].to_numpy(dtype=bool)    # 1 = event, 0 = censuré\n",
    "\n",
    "# Préparer y pour XGBoost AFT : log(1 + temps)\n",
    "y_log_time = np.log1p(time_vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d8d9440a44816d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T16:52:04.613403Z",
     "start_time": "2025-11-24T16:52:03.500683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 — C-index: 0.7531\n",
      "Fold 2 — C-index: 0.7108\n",
      "Fold 3 — C-index: 0.7426\n",
      "Fold 4 — C-index: 0.7266\n",
      "Fold 5 — C-index: 0.7233\n",
      "\n",
      "C-index moyen : 0.7312803131959719\n"
     ]
    }
   ],
   "source": [
    "# Paramètres AFT\n",
    "params = {\n",
    "    \"objective\": \"survival:aft\",\n",
    "    \"eval_metric\": \"aft-nloglik\",\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"max_depth\": 4,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"min_child_weight\": 1,\n",
    "    \"gamma\": 0.0,\n",
    "    \"aft_loss_distribution\": \"normal\",\n",
    "    \"aft_loss_distribution_scale\": 1.0,\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "num_boost_round = 200\n",
    "\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "c_indices = []\n",
    "fold = 1\n",
    "\n",
    "for train_idx, val_idx in kf.split(X):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train_log, y_val_log = y_log_time[train_idx], y_log_time[val_idx]\n",
    "    e_train, e_val = event_vals[train_idx], event_vals[val_idx]\n",
    "\n",
    "    # Bornes inf / sup en log-temps :\n",
    "    # - non censuré : [log(t), log(t)]\n",
    "    # - censuré à droite : [log(t), +inf]\n",
    "    lb_train = y_train_log.copy()\n",
    "    ub_train = y_train_log.copy()\n",
    "    ub_train[e_train == 0] = np.inf\n",
    "\n",
    "    lb_val = y_val_log.copy()\n",
    "    ub_val = y_val_log.copy()\n",
    "    ub_val[e_val == 0] = np.inf\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train)\n",
    "    dtrain.set_float_info(\"label_lower_bound\", lb_train)\n",
    "    dtrain.set_float_info(\"label_upper_bound\", ub_train)\n",
    "\n",
    "    dval = xgb.DMatrix(X_val)\n",
    "    dval.set_float_info(\"label_lower_bound\", lb_val)\n",
    "    dval.set_float_info(\"label_upper_bound\", ub_val)\n",
    "\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        evals=[(dval, \"valid\")],\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "\n",
    "    # Prédictions de log-temps sur la validation\n",
    "    y_pred_log = model.predict(dval)\n",
    "\n",
    "    # C-index : on prend -y_pred_log comme \"risque\"\n",
    "    c_index = concordance_index_censored(\n",
    "    e_val.astype(bool),      # event_indicator\n",
    "    time_vals[val_idx],      # event_time\n",
    "    -y_pred_log)[0]\n",
    "\n",
    "\n",
    "    c_indices.append(c_index)\n",
    "    print(f\"Fold {fold} — C-index: {c_index:.4f}\")\n",
    "    fold += 1\n",
    "\n",
    "print(\"\\nC-index moyen :\", np.mean(c_indices))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8370f7ff8ef04267",
   "metadata": {},
   "source": [
    "## Entraînement sur l'ensemble complet et prédiction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4010b40ec265d465",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T16:52:06.733796Z",
     "start_time": "2025-11-24T16:52:06.578771Z"
    }
   },
   "outputs": [],
   "source": [
    "X_full = train_enhanced[feature_cols].fillna(0.0).to_numpy(dtype=float)\n",
    "y_full_log_time = np.log1p(time_vals)\n",
    "\n",
    "lb_full = y_full_log_time.copy()\n",
    "ub_full = y_full_log_time.copy()\n",
    "ub_full[event_vals == 0] = np.inf\n",
    "\n",
    "dfull = xgb.DMatrix(X_full)\n",
    "dfull.set_float_info(\"label_lower_bound\", lb_full)\n",
    "dfull.set_float_info(\"label_upper_bound\", ub_full)\n",
    "\n",
    "model_full = xgb.train(\n",
    "    params,\n",
    "    dfull,\n",
    "    num_boost_round=num_boost_round,\n",
    "    verbose_eval=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e014582f27bac2db",
   "metadata": {},
   "source": [
    "## Tuning des hyperparamètres XGBoost AFT avec Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "448c33fe85a91fdc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T16:52:06.776977Z",
     "start_time": "2025-11-24T16:52:06.741508Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10b91a07f3f53b08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T16:52:08.418608Z",
     "start_time": "2025-11-24T16:52:08.300152Z"
    }
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sksurv.metrics import concordance_index_censored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e029f85d0c24fb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T16:52:08.969863Z",
     "start_time": "2025-11-24T16:52:08.965047Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"survival:aft\",\n",
    "        \"eval_metric\": \"aft-nloglik\",\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.3, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 7),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
    "        \"aft_loss_distribution\": trial.suggest_categorical(\"aft_loss_distribution\", [\"normal\", \"logistic\", \"extreme\"]),\n",
    "        \"aft_loss_distribution_scale\": trial.suggest_float(\"aft_loss_distribution_scale\", 0.3, 2.0),\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"seed\": 42,\n",
    "    }\n",
    "\n",
    "    num_boost_round = trial.suggest_int(\"num_boost_round\", 50, 500)\n",
    "\n",
    "    n_splits = 7\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    c_indices = []\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "        y_train_log_fold, y_val_log_fold = y_log_time[train_idx], y_log_time[val_idx]\n",
    "        e_train_fold, e_val_fold = event_vals[train_idx], event_vals[val_idx]\n",
    "\n",
    "        lb_train_fold = y_train_log_fold.copy()\n",
    "        ub_train_fold = y_train_log_fold.copy()\n",
    "        ub_train_fold[e_train_fold == 0] = np.inf\n",
    "\n",
    "        lb_val_fold = y_val_log_fold.copy()\n",
    "        ub_val_fold = y_val_log_fold.copy()\n",
    "        ub_val_fold[e_val_fold == 0] = np.inf\n",
    "\n",
    "        dtrain_fold = xgb.DMatrix(X_train_fold)\n",
    "        dtrain_fold.set_float_info(\"label_lower_bound\", lb_train_fold)\n",
    "        dtrain_fold.set_float_info(\"label_upper_bound\", ub_train_fold)\n",
    "\n",
    "        dval_fold = xgb.DMatrix(X_val_fold)\n",
    "        dval_fold.set_float_info(\"label_lower_bound\", lb_val_fold)\n",
    "        dval_fold.set_float_info(\"label_upper_bound\", ub_val_fold)\n",
    "\n",
    "        model_fold = xgb.train(\n",
    "            params,\n",
    "            dtrain_fold,\n",
    "            num_boost_round=num_boost_round,\n",
    "            evals=[(dval_fold, \"valid\")],\n",
    "            verbose_eval=False,\n",
    "        )\n",
    "\n",
    "        y_pred_log_fold = model_fold.predict(dval_fold)\n",
    "\n",
    "        c_index = concordance_index_censored(\n",
    "            e_val_fold.astype(bool),\n",
    "            time_vals[val_idx],\n",
    "            -y_pred_log_fold\n",
    "        )[0]\n",
    "\n",
    "        c_indices.append(c_index)\n",
    "\n",
    "    return np.mean(c_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6b51be58d744ec7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T17:29:06.036072Z",
     "start_time": "2025-11-24T16:52:09.696541Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-06 11:35:42,740] A new study created in memory with name: xgb_aft_tuning\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b66784351145d296d994c733339d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\", study_name=\"xgb_aft_tuning\")\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study.optimize(objective, n_trials=1000, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70bb8a6015964d91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T20:33:33.142120Z",
     "start_time": "2025-11-24T20:33:33.138621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyperparamètres:\n",
      "{'learning_rate': 0.022561607522321357, 'max_depth': 4, 'subsample': 0.5878453201230895, 'colsample_bytree': 0.5707522886919048, 'min_child_weight': 10, 'gamma': 0.2809539949765667, 'aft_loss_distribution': 'extreme', 'aft_loss_distribution_scale': 0.40342091989236506, 'num_boost_round': 239}\n",
      "\n",
      "Meilleur C-index moyen: 0.7428\n"
     ]
    }
   ],
   "source": [
    "print(\"Meilleurs hyperparamètres:\")\n",
    "print(study.best_params)\n",
    "print(f\"\\nMeilleur C-index moyen: {study.best_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eafc48adab84747",
   "metadata": {},
   "source": [
    "## Save current results and retrain with different seeds\n",
    "\n",
    "Saving the current best model results (seed=42) and retraining with 4 additional seeds (36, 500, 4321, 137)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bc8f8b14b99308d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T17:52:36.424884Z",
     "start_time": "2025-11-24T17:52:36.419224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for seed 42 saved to 'results/xgb_aft_seed_42.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "results_dir = '../../results'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "best_params = study.best_params\n",
    "best_num_boost_round = best_params.pop('num_boost_round')\n",
    "\n",
    "results_seed_42 = {\n",
    "    'seed': 42,\n",
    "    'best_params': best_params.copy(),\n",
    "    'best_num_boost_round': best_num_boost_round,\n",
    "    'best_c_index': study.best_value,\n",
    "    'submission_file': 'submission_xgb_aft_tuned_avg10.csv'\n",
    "}\n",
    "\n",
    "with open(f'{results_dir}/xgb_aft_seed_42.json', 'w') as f:\n",
    "    json.dump(results_seed_42, f, indent=2)\n",
    "\n",
    "print(\"Results for seed 42 saved to 'results/xgb_aft_seed_42.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73b015debec1ec41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T20:23:59.680446Z",
     "start_time": "2025-11-24T17:52:55.844343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Starting tuning with seed=36\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db0a77444c28421d931cb6bebdb506a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-12-06 12:43:06,724] Trial 397 failed with parameters: {'learning_rate': 0.006821405447168617, 'max_depth': 3, 'subsample': 0.5186227438823673, 'colsample_bytree': 0.7233758229915569, 'min_child_weight': 9, 'gamma': 4.571704486657374, 'aft_loss_distribution': 'logistic', 'aft_loss_distribution_scale': 0.390837155015343, 'num_boost_round': 461} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\arthr\\AppData\\Local\\Temp\\ipykernel_15496\\2388980546.py\", line 55, in objective_seed\n",
      "    model_fold = xgb.train(\n",
      "                 ^^^^^^^^^^\n",
      "  File \"c:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\xgboost\\core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\xgboost\\training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"c:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\xgboost\\core.py\", line 2101, in update\n",
      "    _LIB.XGBoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2025-12-06 12:43:06,825] Trial 397 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 78\u001b[39m\n\u001b[32m     76\u001b[39m study_seed = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m, study_name=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mxgb_aft_seed_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     77\u001b[39m optuna.logging.set_verbosity(optuna.logging.WARNING)\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m \u001b[43mstudy_seed\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_seed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mBest C-index for seed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy_seed.best_value\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     82\u001b[39m best_params_seed = study_seed.best_params.copy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\optuna\\study\\study.py:489\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    388\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    389\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    397\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    398\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    399\u001b[39m \n\u001b[32m    400\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    487\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:64\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:161\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:253\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    249\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    252\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 55\u001b[39m, in \u001b[36mobjective_seed\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     52\u001b[39m dval_fold.set_float_info(\u001b[33m\"\u001b[39m\u001b[33mlabel_lower_bound\u001b[39m\u001b[33m\"\u001b[39m, lb_val_fold)\n\u001b[32m     53\u001b[39m dval_fold.set_float_info(\u001b[33m\"\u001b[39m\u001b[33mlabel_upper_bound\u001b[39m\u001b[33m\"\u001b[39m, ub_val_fold)\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m model_fold = \u001b[43mxgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtrain_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdval_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalid\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m y_pred_log_fold = model_fold.predict(dval_fold)\n\u001b[32m     65\u001b[39m c_index = concordance_index_censored(\n\u001b[32m     66\u001b[39m     e_val_fold.astype(\u001b[38;5;28mbool\u001b[39m),\n\u001b[32m     67\u001b[39m     time_vals[val_idx],\n\u001b[32m     68\u001b[39m     -y_pred_log_fold\n\u001b[32m     69\u001b[39m )[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\xgboost\\core.py:726\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    724\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    725\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m726\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\xgboost\\training.py:181\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.before_iteration(bst, i, dtrain, evals):\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m \u001b[43mbst\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cb_container.after_iteration(bst, i, dtrain, evals):\n\u001b[32m    183\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\xgboost\\core.py:2101\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, dtrain, iteration, fobj)\u001b[39m\n\u001b[32m   2097\u001b[39m \u001b[38;5;28mself\u001b[39m._assign_dmatrix_features(dtrain)\n\u001b[32m   2099\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2100\u001b[39m     _check_call(\n\u001b[32m-> \u001b[39m\u001b[32m2101\u001b[39m         \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2102\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle\u001b[49m\n\u001b[32m   2103\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2104\u001b[39m     )\n\u001b[32m   2105\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2106\u001b[39m     pred = \u001b[38;5;28mself\u001b[39m.predict(dtrain, output_margin=\u001b[38;5;28;01mTrue\u001b[39;00m, training=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "additional_seeds = [36, 500, 4321, 137]\n",
    "all_seed_results = [results_seed_42]\n",
    "\n",
    "for seed_value in additional_seeds:\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"Starting tuning with seed={seed_value}\")\n",
    "    print(f\"{'=' * 60}\\n\")\n",
    "\n",
    "\n",
    "    def objective_seed(trial):\n",
    "        params = {\n",
    "            \"objective\": \"survival:aft\",\n",
    "            \"eval_metric\": \"aft-nloglik\",\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.005, 0.3, log=True),\n",
    "            \"max_depth\": trial.suggest_int(\"max_depth\", 3, 7),\n",
    "            \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "            \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.4, 1.0),\n",
    "            \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "            \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
    "            \"aft_loss_distribution\": trial.suggest_categorical(\"aft_loss_distribution\",\n",
    "                                                               [\"normal\", \"logistic\", \"extreme\"]),\n",
    "            \"aft_loss_distribution_scale\": trial.suggest_float(\"aft_loss_distribution_scale\", 0.3, 2.0),\n",
    "            \"tree_method\": \"hist\",\n",
    "            \"seed\": seed_value,\n",
    "        }\n",
    "\n",
    "        num_boost_round = trial.suggest_int(\"num_boost_round\", 50, 500)\n",
    "\n",
    "        n_splits = 7\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed_value)\n",
    "\n",
    "        c_indices = []\n",
    "\n",
    "        for train_idx, val_idx in kf.split(X):\n",
    "            X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "            y_train_log_fold, y_val_log_fold = y_log_time[train_idx], y_log_time[val_idx]\n",
    "            e_train_fold, e_val_fold = event_vals[train_idx], event_vals[val_idx]\n",
    "\n",
    "            lb_train_fold = y_train_log_fold.copy()\n",
    "            ub_train_fold = y_train_log_fold.copy()\n",
    "            ub_train_fold[e_train_fold == 0] = np.inf\n",
    "\n",
    "            lb_val_fold = y_val_log_fold.copy()\n",
    "            ub_val_fold = y_val_log_fold.copy()\n",
    "            ub_val_fold[e_val_fold == 0] = np.inf\n",
    "\n",
    "            dtrain_fold = xgb.DMatrix(X_train_fold)\n",
    "            dtrain_fold.set_float_info(\"label_lower_bound\", lb_train_fold)\n",
    "            dtrain_fold.set_float_info(\"label_upper_bound\", ub_train_fold)\n",
    "\n",
    "            dval_fold = xgb.DMatrix(X_val_fold)\n",
    "            dval_fold.set_float_info(\"label_lower_bound\", lb_val_fold)\n",
    "            dval_fold.set_float_info(\"label_upper_bound\", ub_val_fold)\n",
    "\n",
    "            model_fold = xgb.train(\n",
    "                params,\n",
    "                dtrain_fold,\n",
    "                num_boost_round=num_boost_round,\n",
    "                evals=[(dval_fold, \"valid\")],\n",
    "                verbose_eval=False,\n",
    "            )\n",
    "\n",
    "            y_pred_log_fold = model_fold.predict(dval_fold)\n",
    "\n",
    "            c_index = concordance_index_censored(\n",
    "                e_val_fold.astype(bool),\n",
    "                time_vals[val_idx],\n",
    "                -y_pred_log_fold\n",
    "            )[0]\n",
    "\n",
    "            c_indices.append(c_index)\n",
    "\n",
    "        return np.mean(c_indices)\n",
    "\n",
    "\n",
    "    study_seed = optuna.create_study(direction=\"maximize\", study_name=f\"xgb_aft_seed_{seed_value}\")\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "    study_seed.optimize(objective_seed, n_trials=1000, show_progress_bar=True)\n",
    "\n",
    "    print(f\"\\nBest C-index for seed {seed_value}: {study_seed.best_value:.4f}\")\n",
    "\n",
    "    best_params_seed = study_seed.best_params.copy()\n",
    "    best_params_seed[\"objective\"] = \"survival:aft\"\n",
    "    best_params_seed[\"eval_metric\"] = \"aft-nloglik\"\n",
    "    best_params_seed[\"tree_method\"] = \"hist\"\n",
    "    best_params_seed[\"seed\"] = seed_value\n",
    "\n",
    "    best_num_boost_round_seed = best_params_seed.pop(\"num_boost_round\")\n",
    "\n",
    "    lb_full_seed = y_full_log_time.copy()\n",
    "    ub_full_seed = y_full_log_time.copy()\n",
    "    ub_full_seed[event_vals == 0] = np.inf\n",
    "\n",
    "    dfull_seed = xgb.DMatrix(X_full)\n",
    "    dfull_seed.set_float_info(\"label_lower_bound\", lb_full_seed)\n",
    "    dfull_seed.set_float_info(\"label_upper_bound\", ub_full_seed)\n",
    "\n",
    "    model_tuned_seed = xgb.train(\n",
    "        best_params_seed,\n",
    "        dfull_seed,\n",
    "        num_boost_round=best_num_boost_round_seed,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "\n",
    "    X_eval_seed = eval_enhanced[feature_cols].fillna(0.0).to_numpy(dtype=float)\n",
    "    deval_seed = xgb.DMatrix(X_eval_seed)\n",
    "\n",
    "    y_pred_log_seed = model_tuned_seed.predict(deval_seed)\n",
    "    risk_score_seed = -y_pred_log_seed\n",
    "\n",
    "    submission_seed = pd.DataFrame({\n",
    "        'ID': eval_enhanced['ID'],\n",
    "        'risk_score': risk_score_seed\n",
    "    })\n",
    "\n",
    "    results_seed = {\n",
    "        'seed': seed_value,\n",
    "        'best_params': best_params_seed.copy(),\n",
    "        'best_num_boost_round': best_num_boost_round_seed,\n",
    "        'best_c_index': study_seed.best_value,\n",
    "    }\n",
    "\n",
    "    with open(f'{results_dir}/xgb_aft_seed_{seed_value}.json', 'w') as f:\n",
    "        json.dump(results_seed, f, indent=2)\n",
    "\n",
    "    all_seed_results.append(results_seed)\n",
    "\n",
    "    print(f\"Results saved to 'results/xgb_aft_seed_{seed_value}.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6ae00a24bac6549b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T21:20:09.407177Z",
     "start_time": "2025-11-24T21:20:09.404653Z"
    }
   },
   "outputs": [],
   "source": [
    "#TODO: Simplifier tt ça et déseeder le kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e8d6216cbf6d7c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T20:24:07.670180Z",
     "start_time": "2025-11-24T20:24:07.660276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUMMARY OF ALL SEEDS\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seed</th>\n",
       "      <th>Best C-Index</th>\n",
       "      <th>Num Boost Rounds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>0.742321</td>\n",
       "      <td>439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>0.744425</td>\n",
       "      <td>468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>0.743527</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4321</td>\n",
       "      <td>0.742554</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137</td>\n",
       "      <td>0.744798</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Seed  Best C-Index  Num Boost Rounds\n",
       "0    42      0.742321               439\n",
       "1    36      0.744425               468\n",
       "2   500      0.743527               474\n",
       "3  4321      0.742554               256\n",
       "4   137      0.744798               361"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUMMARY OF ALL SEEDS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "summary_df = pd.DataFrame([\n",
    "    {\n",
    "        'Seed': r['seed'],\n",
    "        'Best C-Index': r['best_c_index'],\n",
    "        'Num Boost Rounds': r['best_num_boost_round'],\n",
    "    }\n",
    "    for r in all_seed_results\n",
    "])\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90816b7fff7217d",
   "metadata": {},
   "source": [
    "## Smart Weighted Ensemble of 5 Seeded Models\n",
    "\n",
    "Creating a weighted ensemble that:\n",
    "1. Normalizes predictions by dividing by absolute mean\n",
    "2. Weights models by their best C-index\n",
    "3. Evaluates in K-Fold CV\n",
    "4. Generates final submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b02cfe941c2261cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T20:32:19.777093Z",
     "start_time": "2025-11-24T20:32:19.772848Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best parameters for all seeds\n",
      "Seed 42: C-Index = 0.7423\n",
      "Seed 36: C-Index = 0.7444\n",
      "Seed 500: C-Index = 0.7435\n",
      "Seed 4321: C-Index = 0.7426\n",
      "Seed 137: C-Index = 0.7448\n"
     ]
    }
   ],
   "source": [
    "seeds_to_use = [42, 36, 500, 4321, 137]\n",
    "\n",
    "best_params_per_seed = {}\n",
    "for seed_val in seeds_to_use:\n",
    "    json_path = f'{results_dir}/xgb_aft_seed_{seed_val}.json'\n",
    "    with open(json_path, 'r') as f:\n",
    "        seed_data = json.load(f)\n",
    "        best_params_per_seed[seed_val] = seed_data\n",
    "\n",
    "print(\"Loaded best parameters for all seeds\")\n",
    "for seed_val in seeds_to_use:\n",
    "    print(f\"Seed {seed_val}: C-Index = {best_params_per_seed[seed_val]['best_c_index']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2d23b9c17255a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "import xgboost as xgb\n",
    "\n",
    "def train_and_predict_seed_model(seed_val, dtrain, dval):\n",
    "    best_params = best_params_per_seed[seed_val]['best_params'].copy()\n",
    "    \n",
    "    params = {\n",
    "        \"objective\": \"survival:aft\",\n",
    "        \"eval_metric\": \"aft-nloglik\",\n",
    "        \"learning_rate\": best_params['learning_rate'],\n",
    "        \"max_depth\": best_params['max_depth'],\n",
    "        \"subsample\": best_params['subsample'],\n",
    "        \"colsample_bytree\": best_params['colsample_bytree'],\n",
    "        \"min_child_weight\": best_params['min_child_weight'],\n",
    "        \"gamma\": best_params['gamma'],\n",
    "        \"aft_loss_distribution\": best_params['aft_loss_distribution'],\n",
    "        \"aft_loss_distribution_scale\": best_params['aft_loss_distribution_scale'],\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"seed\": seed_val,\n",
    "    }\n",
    "    \n",
    "    num_boost_round = best_params_per_seed[seed_val]['best_num_boost_round']\n",
    "    best_c = best_params_per_seed[seed_val]['best_c_index']\n",
    "    \n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=num_boost_round,\n",
    "        evals=[(dval, \"valid\")],\n",
    "        verbose_eval=False,\n",
    "    )\n",
    "    \n",
    "    y_pred_log = model.predict(dval)\n",
    "    \n",
    "    return y_pred_log, best_c\n",
    "    \n",
    "    #c_index = concordance_index_censored(\n",
    "    #    e_val.astype(bool),\n",
    "    #    time_vals[val_idx],\n",
    "    #    -y_pred_log\n",
    "    #)[0]\n",
    "   # \n",
    "   #     c_indices.append(c_index)\n",
    "   #     print(f\"Fold {fold} — C-index: {c_index:.4f}\")\n",
    "   #     fold += 1\n",
    "   # \n",
    "   #print(f\"\\nC-index moyen : {np.mean(c_indices):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "632d96ee83a9fc25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T21:00:14.970060Z",
     "start_time": "2025-11-24T21:00:03.116605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Weighted Ensemble with K-Fold Cross-Validation\n",
      "\n",
      "Fold 1 >> Model seed 42 - Best C-Index: 0.7423. ON FOLD: 0.7590540364945889\n",
      "Fold 1 >> Model seed 36 - Best C-Index: 0.7444. ON FOLD: 0.7590911622208609\n",
      "Fold 1 >> Model seed 500 - Best C-Index: 0.7435. ON FOLD: 0.7600749939670695\n",
      "Fold 1 >> Model seed 4321 - Best C-Index: 0.7426. ON FOLD: 0.759258227989085\n",
      "Fold 1 >> Model seed 137 - Best C-Index: 0.7448. ON FOLD: 0.7508492509884724\n",
      "Fold 2 >> Model seed 42 - Best C-Index: 0.7423. ON FOLD: 0.7351578106272473\n",
      "Fold 2 >> Model seed 36 - Best C-Index: 0.7444. ON FOLD: 0.7318617658809429\n",
      "Fold 2 >> Model seed 500 - Best C-Index: 0.7435. ON FOLD: 0.7298242109468638\n",
      "Fold 2 >> Model seed 4321 - Best C-Index: 0.7426. ON FOLD: 0.7302836596084699\n",
      "Fold 2 >> Model seed 137 - Best C-Index: 0.7448. ON FOLD: 0.7302636835797044\n",
      "Fold 3 >> Model seed 42 - Best C-Index: 0.7423. ON FOLD: 0.7164540056669494\n",
      "Fold 3 >> Model seed 36 - Best C-Index: 0.7444. ON FOLD: 0.721850240935588\n",
      "Fold 3 >> Model seed 500 - Best C-Index: 0.7435. ON FOLD: 0.7225721453193524\n",
      "Fold 3 >> Model seed 4321 - Best C-Index: 0.7426. ON FOLD: 0.7188362901333718\n",
      "Fold 3 >> Model seed 137 - Best C-Index: 0.7448. ON FOLD: 0.7151004349473912\n",
      "Fold 4 >> Model seed 42 - Best C-Index: 0.7423. ON FOLD: 0.786312567584905\n",
      "Fold 4 >> Model seed 36 - Best C-Index: 0.7444. ON FOLD: 0.7727314382067777\n",
      "Fold 4 >> Model seed 500 - Best C-Index: 0.7435. ON FOLD: 0.7790912923150235\n",
      "Fold 4 >> Model seed 4321 - Best C-Index: 0.7426. ON FOLD: 0.7715401110683455\n",
      "Fold 4 >> Model seed 137 - Best C-Index: 0.7448. ON FOLD: 0.7855977713018456\n",
      "Fold 5 >> Model seed 42 - Best C-Index: 0.7423. ON FOLD: 0.7396831683168317\n",
      "Fold 5 >> Model seed 36 - Best C-Index: 0.7444. ON FOLD: 0.7388712871287129\n",
      "Fold 5 >> Model seed 500 - Best C-Index: 0.7435. ON FOLD: 0.7382772277227723\n",
      "Fold 5 >> Model seed 4321 - Best C-Index: 0.7426. ON FOLD: 0.7426534653465346\n",
      "Fold 5 >> Model seed 137 - Best C-Index: 0.7448. ON FOLD: 0.7331683168316832\n",
      "Fold 6 >> Model seed 42 - Best C-Index: 0.7423. ON FOLD: 0.7044826614040034\n",
      "Fold 6 >> Model seed 36 - Best C-Index: 0.7444. ON FOLD: 0.7004416878112959\n",
      "Fold 6 >> Model seed 500 - Best C-Index: 0.7435. ON FOLD: 0.7006484352974345\n",
      "Fold 6 >> Model seed 4321 - Best C-Index: 0.7426. ON FOLD: 0.6990508410863641\n",
      "Fold 6 >> Model seed 137 - Best C-Index: 0.7448. ON FOLD: 0.7073583309839301\n",
      "Fold 7 >> Model seed 42 - Best C-Index: 0.7423. ON FOLD: 0.7551020408163265\n",
      "Fold 7 >> Model seed 36 - Best C-Index: 0.7444. ON FOLD: 0.7501358670189839\n",
      "Fold 7 >> Model seed 500 - Best C-Index: 0.7435. ON FOLD: 0.7526283240568955\n",
      "Fold 7 >> Model seed 4321 - Best C-Index: 0.7426. ON FOLD: 0.7488990086392684\n",
      "Fold 7 >> Model seed 137 - Best C-Index: 0.7448. ON FOLD: 0.7549895991454433\n",
      "[np.float64(0.7423208987015502), np.float64(0.7392833498861661), np.float64(0.7404452328036302), np.float64(0.7386459434102056), np.float64(0.7396181982540673)]\n",
      "0.7400627246111238\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating Weighted Ensemble with K-Fold Cross-Validation\\n\")\n",
    "\n",
    "kf_ensemble = KFold(n_splits=7, shuffle=True)\n",
    "cv_scores_ensemble = []\n",
    "\n",
    "fold = 1\n",
    "    \n",
    "seeds_score = {}\n",
    "for seed_val in seeds_to_use:\n",
    "    seeds_score[seed_val] = []\n",
    "for train_idx, val_idx in kf.split(X):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train_log, y_val_log = y_log_time[train_idx], y_log_time[val_idx]\n",
    "    e_train, e_val = event_vals[train_idx], event_vals[val_idx]\n",
    "    \n",
    "    lb_train = y_train_log.copy()\n",
    "    ub_train = y_train_log.copy()\n",
    "    ub_train[e_train == 0] = np.inf\n",
    "    \n",
    "    lb_val = y_val_log.copy()\n",
    "    ub_val = y_val_log.copy()\n",
    "    ub_val[e_val == 0] = np.inf\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train)\n",
    "    dtrain.set_float_info(\"label_lower_bound\", lb_train)\n",
    "    dtrain.set_float_info(\"label_upper_bound\", ub_train)\n",
    "    \n",
    "    dval = xgb.DMatrix(X_val)\n",
    "    dval.set_float_info(\"label_lower_bound\", lb_val)\n",
    "    dval.set_float_info(\"label_upper_bound\", ub_val)\n",
    "\n",
    "    \n",
    "    for seed_val in seeds_to_use:\n",
    "        y_pred_log, best_c = train_and_predict_seed_model(seed_val, dtrain, dval)\n",
    "        c_index = concordance_index_censored(\n",
    "            e_val.astype(bool),\n",
    "            time_vals[val_idx],\n",
    "            -y_pred_log\n",
    "        )[0]\n",
    "        \n",
    "        print(f\"Fold {fold} >> Model seed {seed_val} - Best C-Index: {best_c:.4f}. ON FOLD: {c_index}\")\n",
    "        seeds_score[seed_val].append(c_index)\n",
    "\n",
    "    fold += 1\n",
    "    \n",
    "scores_final = [np.mean(seeds_score[seed]) for seed in seeds_to_use]\n",
    "print(scores_final)\n",
    "print(np.mean(scores_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d3dcae989154430",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T21:11:01.375901Z",
     "start_time": "2025-11-24T21:10:49.372883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Weighted Ensemble with K-Fold Cross-Validation\n",
      "\n",
      "Fold 1 >> 0.7593881680310371\n",
      "Fold 2 >> 0.7328006392329205\n",
      "Fold 3 >> 0.720514717825624\n",
      "Fold 4 >> 0.7804842286614981\n",
      "Fold 5 >> 0.7414059405940594\n",
      "Fold 6 >> 0.7031669955831219\n",
      "Fold 7 >> 0.7536402990948445\n",
      "0.7416287127175866\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating Weighted Ensemble with K-Fold Cross-Validation\\n\")\n",
    "\n",
    "kf_ensemble = KFold(n_splits=7, shuffle=True)\n",
    "cv_scores_ensemble = []\n",
    "\n",
    "fold = 1\n",
    "    \n",
    "fold_score = []\n",
    "for seed_val in seeds_to_use:\n",
    "    seeds_score[seed_val] = []\n",
    "for train_idx, val_idx in kf.split(X):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train_log, y_val_log = y_log_time[train_idx], y_log_time[val_idx]\n",
    "    e_train, e_val = event_vals[train_idx], event_vals[val_idx]\n",
    "    \n",
    "    lb_train = y_train_log.copy()\n",
    "    ub_train = y_train_log.copy()\n",
    "    ub_train[e_train == 0] = np.inf\n",
    "    \n",
    "    lb_val = y_val_log.copy()\n",
    "    ub_val = y_val_log.copy()\n",
    "    ub_val[e_val == 0] = np.inf\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train)\n",
    "    dtrain.set_float_info(\"label_lower_bound\", lb_train)\n",
    "    dtrain.set_float_info(\"label_upper_bound\", ub_train)\n",
    "    \n",
    "    dval = xgb.DMatrix(X_val)\n",
    "    dval.set_float_info(\"label_lower_bound\", lb_val)\n",
    "    dval.set_float_info(\"label_upper_bound\", ub_val)\n",
    "\n",
    "    y_preds = []\n",
    "    for seed_val in seeds_to_use:\n",
    "        y_pred_log, best_c = train_and_predict_seed_model(seed_val, dtrain, dval)\n",
    "        best_cs.append(best_c)\n",
    "        \n",
    "        y_preds.append(best_c * y_pred_log / np.mean(np.abs(y_pred_log)))\n",
    "    \n",
    "    y_preds_comb = np.array(y_preds).sum(axis=0)\n",
    "    c_index = concordance_index_censored(\n",
    "        e_val.astype(bool),\n",
    "        time_vals[val_idx],\n",
    "        -y_preds_comb\n",
    "    )[0]\n",
    "        \n",
    "    print(f\"Fold {fold} >> {c_index}\")\n",
    "    fold_score.append(c_index)\n",
    "\n",
    "    fold += 1\n",
    "    \n",
    "print(np.mean(fold_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d32bd13eeaf0b2b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T21:13:23.289934Z",
     "start_time": "2025-11-24T21:13:21.772559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 42 trained on full data, best_c=0.7423\n",
      "Seed 36 trained on full data, best_c=0.7444\n",
      "Seed 500 trained on full data, best_c=0.7435\n",
      "Seed 4321 trained on full data, best_c=0.7426\n",
      "Seed 137 trained on full data, best_c=0.7448\n"
     ]
    }
   ],
   "source": [
    "best_cs = []\n",
    "for seed_val in seeds_to_use:\n",
    "    best_params = best_params_per_seed[seed_val]['best_params'].copy()\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"survival:aft\",\n",
    "        \"eval_metric\": \"aft-nloglik\",\n",
    "        \"learning_rate\": best_params['learning_rate'],\n",
    "        \"max_depth\": best_params['max_depth'],\n",
    "        \"subsample\": best_params['subsample'],\n",
    "        \"colsample_bytree\": best_params['colsample_bytree'],\n",
    "        \"min_child_weight\": best_params['min_child_weight'],\n",
    "        \"gamma\": best_params['gamma'],\n",
    "        \"aft_loss_distribution\": best_params['aft_loss_distribution'],\n",
    "        \"aft_loss_distribution_scale\": best_params['aft_loss_distribution_scale'],\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"seed\": seed_val,\n",
    "    }\n",
    "\n",
    "    num_boost_round = best_params_per_seed[seed_val]['best_num_boost_round']\n",
    "\n",
    "    lb_full = y_full_log_time.copy()\n",
    "    ub_full = y_full_log_time.copy()\n",
    "    ub_full[event_vals == 0] = np.inf\n",
    "\n",
    "    dfull = xgb.DMatrix(X_full)\n",
    "    dfull.set_float_info(\"label_lower_bound\", lb_full)\n",
    "    dfull.set_float_info(\"label_upper_bound\", ub_full)\n",
    "\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dfull,\n",
    "        num_boost_round=num_boost_round,\n",
    "        verbose_eval=False\n",
    "    )\n",
    "\n",
    "    X_eval = eval_enhanced[feature_cols].fillna(0.0).to_numpy(dtype=float)\n",
    "    deval = xgb.DMatrix(X_eval)\n",
    "\n",
    "    y_pred_log = model.predict(deval)\n",
    "\n",
    "    best_c = best_params_per_seed[seed_val]['best_c_index']\n",
    "    best_cs.append(best_c)\n",
    "\n",
    "    pred_normalized = y_pred_log / np.mean(np.abs(y_pred_log))\n",
    "\n",
    "    if seed_val == seeds_to_use[0]:\n",
    "        weighted_pred = best_c * pred_normalized\n",
    "    else:\n",
    "        weighted_pred += best_c * pred_normalized\n",
    "\n",
    "    print(f\"Seed {seed_val} trained on full data, best_c={best_c:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a3f65ea1f5cf6a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T21:13:23.318927Z",
     "start_time": "2025-11-24T21:13:23.310741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to: ../../submissions/submission_xgb_aft_weighted_ensemble.csv\n"
     ]
    }
   ],
   "source": [
    "risk_scores = -weighted_pred\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'ID': eval_enhanced['ID'],\n",
    "    'risk_score': risk_scores\n",
    "})\n",
    "\n",
    "submission.to_csv('../../submissions/submission_xgb_aft_weighted_ensemble.csv', index=False)\n",
    "\n",
    "print(\"Submission saved to: ../../submissions/submission_xgb_aft_weighted_ensemble.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
