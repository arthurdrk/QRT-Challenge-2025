{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "collapsed": true,
    "id": "cJYyGsEWwBsx",
    "outputId": "484a2621-e6b3-4063-a765-2642a03b0f9c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.metrics import concordance_index_censored , concordance_index_ipcw\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sksurv.util import Surv\n",
    "from lifelines.utils import concordance_index\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle MTLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-10 00:36:35,682] A new study created in memory with name: mtlr_survival_improved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device utilisé : cpu\n",
      "Nombre de covariables : 164\n",
      "Nombre de time bins (bords) : 40\n",
      "Dimension logits/target     : 41\n",
      "=== Début optimisation Optuna ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46762a3c2bd04185b8a4ef3a2f58a1d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-10 00:40:00,674] Trial 0 finished with value: 0.5 and parameters: {'n_layers': 3, 'hidden_size': 256, 'dropout': 0.2683595842828394, 'C1': 1.0924356736442253, 'C2': 6.496271281628262e-06, 'lr': 0.0062552696262983265, 'batch_size': 64, 'num_epochs': 175}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-12-10 00:40:33,685] Trial 1 finished with value: 0.5 and parameters: {'n_layers': 2, 'hidden_size': 32, 'dropout': 0.3550257041979083, 'C1': 0.0006957609770187876, 'C2': 1.9716367787104583e-06, 'lr': 0.0037439784696579304, 'batch_size': 64, 'num_epochs': 50}. Best is trial 0 with value: 0.5.\n",
      "[I 2025-12-10 00:41:25,000] Trial 2 finished with value: 0.5 and parameters: {'n_layers': 3, 'hidden_size': 128, 'dropout': 0.3407811116676015, 'C1': 0.044233442046629906, 'C2': 0.0014399673781958634, 'lr': 3.181901418364637e-05, 'batch_size': 256, 'num_epochs': 150}. Best is trial 0 with value: 0.5.\n",
      "[W 2025-12-10 00:41:53,299] Trial 3 failed with parameters: {'n_layers': 3, 'hidden_size': 128, 'dropout': 0.17397050685261628, 'C1': 0.010982628318613376, 'C2': 0.0022543931934365723, 'lr': 6.361890987022594e-05, 'batch_size': 64, 'num_epochs': 175} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\arthr\\AppData\\Local\\Temp\\ipykernel_6904\\3155433596.py\", line 532, in enhanced_objective\n",
      "    mean_c, std_c = crossval_cindex(\n",
      "                    ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\arthr\\AppData\\Local\\Temp\\ipykernel_6904\\3155433596.py\", line 394, in crossval_cindex\n",
      "    model = train_mtlr(\n",
      "            ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\arthr\\AppData\\Local\\Temp\\ipykernel_6904\\3155433596.py\", line 269, in train_mtlr\n",
      "    loss.backward()\n",
      "  File \"c:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\torch\\_tensor.py\", line 625, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"c:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py\", line 354, in backward\n",
      "    _engine_run_backward(\n",
      "  File \"c:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py\", line 841, in _engine_run_backward\n",
      "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-12-10 00:41:53,382] Trial 3 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 550\u001b[39m\n\u001b[32m    548\u001b[39m study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m, study_name=\u001b[33m\"\u001b[39m\u001b[33mmtlr_survival_improved\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    549\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== Début optimisation Optuna ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m550\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43menhanced_objective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== Fin optimisation Optuna ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    553\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMeilleurs hyperparamètres Optuna :\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\optuna\\study\\study.py:489\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    388\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    389\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    397\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    398\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    399\u001b[39m \n\u001b[32m    400\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    487\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:64\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:161\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:253\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    249\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    252\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 532\u001b[39m, in \u001b[36menhanced_objective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m    521\u001b[39m train_kwargs = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    522\u001b[39m     C1=C1,\n\u001b[32m    523\u001b[39m     C2=C2,\n\u001b[32m   (...)\u001b[39m\u001b[32m    528\u001b[39m     verbose=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    529\u001b[39m )\n\u001b[32m    531\u001b[39m \u001b[38;5;66;03m# 5-fold CV time-aware par défaut\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m mean_c, std_c = \u001b[43mcrossval_cindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_builder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_builder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    536\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_time_aware\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    539\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m    540\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    542\u001b[39m trial.set_user_attr(\u001b[33m\"\u001b[39m\u001b[33mstd_cindex\u001b[39m\u001b[33m\"\u001b[39m, std_c)\n\u001b[32m    544\u001b[39m \u001b[38;5;66;03m# Optuna va maximiser ce retour\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 394\u001b[39m, in \u001b[36mcrossval_cindex\u001b[39m\u001b[34m(data, n_splits, model_builder, train_kwargs, use_time_aware, device, verbose)\u001b[39m\n\u001b[32m    391\u001b[39m model = model_builder()\n\u001b[32m    393\u001b[39m \u001b[38;5;66;03m# Entraînement (⚠️ ici on ne repasse plus device deux fois)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m model = \u001b[43mtrain_mtlr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_fold_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtime_bins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrain_kwargs\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;66;03m# Évaluation C-index\u001b[39;00m\n\u001b[32m    402\u001b[39m x_val = torch.tensor(\n\u001b[32m    403\u001b[39m     val_fold_norm[feature_cols].values,\n\u001b[32m    404\u001b[39m     dtype=torch.float32,\n\u001b[32m    405\u001b[39m     device=device\n\u001b[32m    406\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 269\u001b[39m, in \u001b[36mtrain_mtlr\u001b[39m\u001b[34m(model, df, time_bins, C1, C2, num_epochs, lr, batch_size, device, verbose)\u001b[39m\n\u001b[32m    266\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[32m    268\u001b[39m optimizer.zero_grad()\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m optimizer.step()\n\u001b[32m    272\u001b[39m epoch_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\torch\\_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from torchmtlr import (\n",
    "    MTLR,\n",
    "    mtlr_neg_log_likelihood,\n",
    "    mtlr_survival,\n",
    "    mtlr_risk,\n",
    ")\n",
    "from torchmtlr.utils import make_time_bins, encode_survival\n",
    "\n",
    "import optuna\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ====================\n",
    "# 0. Device\n",
    "# ====================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device utilisé :\", device)\n",
    "\n",
    "# ====================\n",
    "# 1. Chargement des données\n",
    "# ====================\n",
    "df_train = pd.read_csv(\"../data/train_pivot3.csv\")\n",
    "df_val   = pd.read_csv(\"../data/eval_pivot3.csv\")\n",
    "\n",
    "# Renommer pour coller à la notation du notebook MTLR\n",
    "df_train = df_train.rename(columns={\n",
    "    \"OS_STATUS\": \"event\",\n",
    "    \"OS_YEARS\":  \"time\"\n",
    "})\n",
    "\n",
    "# Enlever les lignes avec time/event manquants\n",
    "df_train = df_train.dropna(subset=[\"time\", \"event\"])\n",
    "\n",
    "# Temps >= 0\n",
    "df_train[\"time\"] = df_train[\"time\"].clip(lower=0)\n",
    "\n",
    "# Enlever ID des features (si présent)\n",
    "for col in [\"ID\"]:\n",
    "    if col in df_train.columns:\n",
    "        df_train = df_train.drop(columns=[col])\n",
    "\n",
    "# Définition des colonnes de features\n",
    "feature_cols = [c for c in df_train.columns if c not in [\"time\", \"event\"]]\n",
    "print(\"Nombre de covariables :\", len(feature_cols))\n",
    "\n",
    "# ====================\n",
    "# 2. Time bins\n",
    "# ====================\n",
    "time_bins = make_time_bins(\n",
    "    df_train[\"time\"].values,\n",
    "    event=df_train[\"event\"].values\n",
    ")\n",
    "num_time_bins = len(time_bins)\n",
    "in_features = len(feature_cols)\n",
    "\n",
    "print(\"Nombre de time bins   :\", num_time_bins)\n",
    "\n",
    "# ====================\n",
    "# 3. Helpers de normalisation\n",
    "# ====================\n",
    "def fit_normalizer(df, feature_cols):\n",
    "    \"\"\"\n",
    "    Calcule médianes (pour imputation), moyennes, std pour standardisation.\n",
    "    Remplace inf/-inf par NaN avant.\n",
    "    \"\"\"\n",
    "    X = df[feature_cols].replace([np.inf, -np.inf], np.nan)\n",
    "    med = X.median()\n",
    "    X = X.fillna(med)\n",
    "    mean = X.mean()\n",
    "    std = X.std()\n",
    "    std[std == 0] = 1.0  # évite division par 0\n",
    "    return med, mean, std\n",
    "\n",
    "def apply_normalizer(df, feature_cols, med, mean, std):\n",
    "    X = df[feature_cols].replace([np.inf, -np.inf], np.nan)\n",
    "    X = X.fillna(med)\n",
    "    X = (X - mean) / std\n",
    "    df_norm = df.copy()\n",
    "    df_norm[feature_cols] = X\n",
    "    return df_norm\n",
    "\n",
    "# ====================\n",
    "# 4. Reset des paramètres du modèle\n",
    "# ====================\n",
    "def reset_parameters(model):\n",
    "    for param in model.parameters():\n",
    "        if param.dim() > 1:  # poids (matrices)\n",
    "            torch.nn.init.xavier_uniform_(param)\n",
    "        else:  # biais (vecteurs)\n",
    "            torch.nn.init.zeros_(param)\n",
    "\n",
    "def make_model():\n",
    "    model = MTLR(\n",
    "        in_features=in_features,\n",
    "        num_time_bins=num_time_bins\n",
    "    ).to(device)\n",
    "    reset_parameters(model)\n",
    "    return model\n",
    "\n",
    "# ====================\n",
    "# 5. Fonction d'entraînement MTLR (un dataset)\n",
    "# ====================\n",
    "def train_mtlr(\n",
    "    model,\n",
    "    df,\n",
    "    time_bins,\n",
    "    C1=1.0,\n",
    "    num_epochs=100,\n",
    "    lr=1e-3,\n",
    "    batch_size=512,\n",
    "    device=device,\n",
    "    verbose=False\n",
    "):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Labels survival\n",
    "    y = encode_survival(\n",
    "        df[\"time\"].values,\n",
    "        df[\"event\"].values,\n",
    "        time_bins\n",
    "    ).to(device)\n",
    "\n",
    "    # Features\n",
    "    X = torch.tensor(\n",
    "        df[feature_cols].values,\n",
    "        dtype=torch.float32,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    n = df.shape[0]\n",
    "    n_batches = int(np.ceil(n / batch_size))\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # barre de progression sur les epochs\n",
    "    if verbose:\n",
    "        epoch_iter = tqdm(range(num_epochs), desc=\"Entraînement MTLR\", leave=False)\n",
    "    else:\n",
    "        epoch_iter = range(num_epochs)\n",
    "\n",
    "    for epoch in epoch_iter:\n",
    "        indices = np.random.permutation(n)\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for b in range(n_batches):\n",
    "            batch_idx = indices[b*batch_size:(b+1)*batch_size]\n",
    "            xb = X[batch_idx]\n",
    "            yb = y[batch_idx]\n",
    "\n",
    "            logits = model(xb)\n",
    "            loss = mtlr_neg_log_likelihood(\n",
    "                logits,\n",
    "                yb,\n",
    "                model,\n",
    "                C1=C1\n",
    "            )\n",
    "\n",
    "            if not torch.isfinite(loss):\n",
    "                # on log et on arrête l'entraînement pour ce modèle\n",
    "                if verbose:\n",
    "                    print(\"⚠️ Loss non finie (NaN/inf) à l'epoch\", epoch)\n",
    "                return model\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        epoch_loss /= n_batches\n",
    "\n",
    "        if verbose:\n",
    "            epoch_iter.set_postfix(loss=f\"{epoch_loss:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# ====================\n",
    "# 6. C-index de Harrell\n",
    "# ====================\n",
    "def concordance_index(event_times, event_observed, predicted_risk):\n",
    "    \"\"\"\n",
    "    C-index de Harrell.\n",
    "    event_times : array-like (n,)\n",
    "    event_observed : array-like (n,) 1=event, 0=censuré\n",
    "    predicted_risk : array-like (n,) (plus grand = plus à risque)\n",
    "    \"\"\"\n",
    "    t = np.asarray(event_times, dtype=float)\n",
    "    e = np.asarray(event_observed, dtype=int)\n",
    "    r = np.asarray(predicted_risk, dtype=float)\n",
    "\n",
    "    n = len(t)\n",
    "    assert len(e) == n and len(r) == n\n",
    "\n",
    "    num = 0.0\n",
    "    den = 0.0\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            # On regarde si (i, j) forme une paire comparable\n",
    "            if t[i] == t[j]:\n",
    "                continue\n",
    "\n",
    "            # L'évènement le plus tôt\n",
    "            if t[i] < t[j]:\n",
    "                if e[i] == 0:\n",
    "                    continue  # censure avant l'autre\n",
    "                ti, tj = i, j\n",
    "            else:\n",
    "                if e[j] == 0:\n",
    "                    continue\n",
    "                ti, tj = j, i\n",
    "\n",
    "            den += 1.0\n",
    "\n",
    "            # concordance : plus de risque pour celui qui a l'évènement le plus tôt\n",
    "            if r[ti] > r[tj]:\n",
    "                num += 1.0\n",
    "            elif r[ti] == r[tj]:\n",
    "                num += 0.5\n",
    "\n",
    "    return num / den if den > 0 else np.nan\n",
    "\n",
    "# ====================\n",
    "# 7. Cross-validation générique (utile pour Optuna)\n",
    "# ====================\n",
    "def crossval_cindex(\n",
    "    data,\n",
    "    n_splits,\n",
    "    C1,\n",
    "    num_epochs,\n",
    "    lr,\n",
    "    batch_size,\n",
    "    device=device,\n",
    "    verbose=False\n",
    "):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    fold_cindex = []\n",
    "\n",
    "    # liste des splits pour tqdm\n",
    "    splits = list(kf.split(data))\n",
    "\n",
    "    if verbose:\n",
    "        fold_iter = tqdm(splits, desc=\"Cross-validation\", total=n_splits)\n",
    "    else:\n",
    "        fold_iter = splits\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(fold_iter, start=1):\n",
    "        train_fold = data.iloc[train_idx].reset_index(drop=True)\n",
    "        val_fold   = data.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "        # Normalisation apprise sur le train du fold\n",
    "        med, mean, std = fit_normalizer(train_fold, feature_cols)\n",
    "        train_fold_norm = apply_normalizer(train_fold, feature_cols, med, mean, std)\n",
    "        val_fold_norm   = apply_normalizer(val_fold, feature_cols, med, mean, std)\n",
    "\n",
    "        # Modèle\n",
    "        model = make_model()\n",
    "\n",
    "        # Entraînement\n",
    "        model = train_mtlr(\n",
    "            model,\n",
    "            train_fold_norm,\n",
    "            time_bins,\n",
    "            C1=C1,\n",
    "            num_epochs=num_epochs,\n",
    "            lr=lr,\n",
    "            batch_size=batch_size,\n",
    "            device=device,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "        # Évaluation C-index\n",
    "        x_val = torch.tensor(\n",
    "            val_fold_norm[feature_cols].values,\n",
    "            dtype=torch.float32,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits_val = model(x_val)\n",
    "            risk_val = mtlr_risk(logits_val).cpu().numpy().reshape(-1)\n",
    "\n",
    "        times_val  = val_fold_norm[\"time\"].values\n",
    "        events_val = val_fold_norm[\"event\"].values\n",
    "\n",
    "        cidx = concordance_index(times_val, events_val, risk_val)\n",
    "        fold_cindex.append(cidx)\n",
    "\n",
    "        if verbose:\n",
    "            fold_iter.set_postfix(c_index=f\"{cidx:.4f}\")\n",
    "\n",
    "    mean_c = float(np.mean(fold_cindex))\n",
    "    std_c  = float(np.std(fold_cindex))\n",
    "    if verbose:\n",
    "        print(f\"--> C-index moyen = {mean_c:.4f} ± {std_c:.4f}\")\n",
    "\n",
    "    return mean_c, std_c\n",
    "\n",
    "# ====================\n",
    "# 8. Optuna : optimisation hyperparamètres\n",
    "# ====================\n",
    "def objective(trial):\n",
    "    # Espace de recherche\n",
    "    C1 = trial.suggest_float(\"C1\", 1e-3, 10.0, log=True)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 5e-3, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [128, 256, 512, 1024])\n",
    "    # Tu peux aussi tuner le nombre d'epochs, mais c'est plus coûteux :\n",
    "    num_epochs = trial.suggest_int(\"num_epochs\", 50, 150, step=25)\n",
    "\n",
    "    # On fait typiquement un 3 à 5-fold CV\n",
    "    mean_c, std_c = crossval_cindex(\n",
    "        data=df_train,\n",
    "        n_splits=5,\n",
    "        C1=C1,\n",
    "        num_epochs=num_epochs,\n",
    "        lr=lr,\n",
    "        batch_size=batch_size,\n",
    "        device=device,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # Tu peux logguer les infos si tu veux\n",
    "    trial.set_user_attr(\"std_cindex\", std_c)\n",
    "\n",
    "    # Optuna va MAXIMISER ce retour si on le précise\n",
    "    return mean_c\n",
    "\n",
    "# Création de l’étude\n",
    "study = optuna.create_study(direction=\"maximize\", study_name=\"mtlr_survival\")\n",
    "print(\"=== Début optimisation Optuna ===\")\n",
    "study.optimize(objective, n_trials=20, show_progress_bar=True)  # barre Optuna\n",
    "print(\"=== Fin optimisation Optuna ===\")\n",
    "\n",
    "print(\"Meilleurs hyperparamètres Optuna :\")\n",
    "print(study.best_params)\n",
    "print(\"Meilleur C-index moyen :\", study.best_value)\n",
    "\n",
    "best_params = study.best_params\n",
    "best_C1        = best_params[\"C1\"]\n",
    "best_lr        = best_params[\"lr\"]\n",
    "best_batchsize = best_params[\"batch_size\"]\n",
    "best_epochs    = best_params[\"num_epochs\"]\n",
    "\n",
    "# ====================\n",
    "# 9. Entraînement final sur tout df_train avec les meilleurs hyperparamètres\n",
    "# ====================\n",
    "print(\"\\n=== Entraînement final avec hyperparamètres Optuna ===\")\n",
    "print(f\"C1 = {best_C1:.4g}, lr = {best_lr:.4g}, \"\n",
    "      f\"batch_size = {best_batchsize}, num_epochs = {best_epochs}\")\n",
    "\n",
    "# Normalisation sur tout df_train\n",
    "med_full, mean_full, std_full = fit_normalizer(df_train, feature_cols)\n",
    "df_train_norm = apply_normalizer(df_train, feature_cols, med_full, mean_full, std_full)\n",
    "\n",
    "mtlr_model = make_model()\n",
    "mtlr_model = train_mtlr(\n",
    "    mtlr_model,\n",
    "    df_train_norm,\n",
    "    time_bins,\n",
    "    C1=best_C1,\n",
    "    num_epochs=best_epochs,\n",
    "    lr=best_lr,\n",
    "    batch_size=best_batchsize,\n",
    "    device=device,\n",
    "    verbose=True  # pour afficher la barre sur l'entraînement final\n",
    ")\n",
    "\n",
    "norm_params = {\"med\": med_full, \"mean\": mean_full, \"std\": std_full}\n",
    "\n",
    "print(\"Entraînement final terminé.\")\n",
    "\n",
    "# ====================\n",
    "# 10. Prédictions sur df_val avec le modèle optimisé\n",
    "# ====================\n",
    "\n",
    "# Enlever ID de df_val (si présent)\n",
    "df_val_feats = df_val.copy()\n",
    "for col in [\"ID\"]:\n",
    "    if col in df_val_feats.columns:\n",
    "        df_val_feats = df_val_feats.drop(columns=[col])\n",
    "\n",
    "# Garder exactement les mêmes features que dans df_train, dans le même ordre\n",
    "df_val_feats = df_val_feats[feature_cols]\n",
    "\n",
    "# Appliquer le normalizer appris sur tout df_train\n",
    "df_val_norm = apply_normalizer(\n",
    "    df_val_feats,\n",
    "    feature_cols,\n",
    "    norm_params[\"med\"],\n",
    "    norm_params[\"mean\"],\n",
    "    norm_params[\"std\"]\n",
    ")\n",
    "\n",
    "x_val_tensor = torch.tensor(\n",
    "    df_val_norm[feature_cols].values,\n",
    "    dtype=torch.float32,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits_val = mtlr_model(x_val_tensor)\n",
    "    surv_val = mtlr_survival(logits_val).cpu().numpy()         # (n_samples, num_time_bins)\n",
    "    risk_val = mtlr_risk(logits_val).cpu().numpy().reshape(-1) # (n_samples,)\n",
    "\n",
    "print(\"Shape des prédictions de survie sur df_val :\", surv_val.shape)\n",
    "print(\"Exemple de risk scores (5 premiers) :\", risk_val[:5])\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
