{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "206b09dc",
   "metadata": {},
   "source": [
    "# Meta-Ensemble: MTLR Ensemble + XGBoost AFT Ensemble\n",
    "\n",
    "This notebook combines two survival models:\n",
    "- an **MTLR ensemble**\n",
    "- an **XGBoost AFT ensemble**\n",
    "\n",
    "Both ensembles are assumed to produce risk scores on the **same validation or test set**.\n",
    "\n",
    "We build a **meta-ensemble** by averaging the ranks of their risk scores (rank-based ensembling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224c4c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sksurv.util import Surv\n",
    "from sksurv.metrics import concordance_index_ipcw\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "# Paths to the prediction files produced by the MTLR and XGB AFT ensembles.\n",
    "# Each file must contain at least: 'ID' and 'risk_score'.\n",
    "\n",
    "MTLR_PRED_PATH = \"submission_mtlr_ensemble_nestedcv.csv\"  # adapt if needed\n",
    "XGB_PRED_PATH = \"../submissions/submission_xgb_aft_ensemble_nestedcv.csv\"  # adapt if needed\n",
    "\n",
    "# Optional: path to a labeled validation set to evaluate IPCW C-index\n",
    "# The file should contain columns: 'ID', 'OS_STATUS', 'OS_YEARS'.\n",
    "\n",
    "VAL_DATA_PATH = \"../../data/val_enhanced.csv\"  # adapt or set to None if not available\n",
    "TIME_COL = \"OS_YEARS\"\n",
    "EVENT_COL = \"OS_STATUS\"\n",
    "TAU_CINDEX = 7.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552f6b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LOAD PREDICTIONS ===\n",
    "mtlr_pred = pd.read_csv(MTLR_PRED_PATH)\n",
    "xgb_pred = pd.read_csv(XGB_PRED_PATH)\n",
    "\n",
    "print(\"MTLR predictions:\")\n",
    "print(mtlr_pred.head())\n",
    "print(\"\\nXGB AFT predictions:\")\n",
    "print(xgb_pred.head())\n",
    "\n",
    "# Sanity check on columns\n",
    "assert \"ID\" in mtlr_pred.columns and \"risk_score\" in mtlr_pred.columns, \"MTLR file must contain 'ID' and 'risk_score' columns.\"\n",
    "assert \"ID\" in xgb_pred.columns and \"risk_score\" in xgb_pred.columns, \"XGB file must contain 'ID' and 'risk_score' columns.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d0d7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === MERGE PREDICTIONS ON ID ===\n",
    "merged = (\n",
    "    mtlr_pred.rename(columns={\"risk_score\": \"risk_mtlr\"})\n",
    "    .merge(xgb_pred.rename(columns={\"risk_score\": \"risk_xgb\"}), on=\"ID\", how=\"inner\")\n",
    ")\n",
    "\n",
    "print(f\"Merged shape: {merged.shape}\")\n",
    "print(merged.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0307e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === RANK-BASED AVERAGE ENSEMBLING ===\n",
    "\n",
    "def rank_based_ensemble(df, risk_cols):\n",
    "    \"\"\"Compute rank-based ensemble from given risk columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame containing risk score columns.\n",
    "    risk_cols : list of str\n",
    "        Names of the risk score columns to ensemble.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Average ranks (1 = lowest risk, N = highest risk).\n",
    "    \"\"\"\n",
    "    n = len(df)\n",
    "    ranks = []\n",
    "    for col in risk_cols:\n",
    "        # ascending: lowest risk -> rank 1\n",
    "        order = np.argsort(df[col].values)\n",
    "        rank = np.empty_like(order, dtype=float)\n",
    "        rank[order] = np.arange(1, n + 1)\n",
    "        ranks.append(rank)\n",
    "\n",
    "    ranks = np.vstack(ranks)  # shape (n_models, n_samples)\n",
    "    return ranks.mean(axis=0)\n",
    "\n",
    "risk_cols = [\"risk_mtlr\", \"risk_xgb\"]\n",
    "merged[\"risk_ensemble_rank\"] = rank_based_ensemble(merged, risk_cols)\n",
    "\n",
    "# Optional: normalize ensemble risk between 0 and 1 for interpretability\n",
    "r_min = merged[\"risk_ensemble_rank\"].min()\n",
    "r_max = merged[\"risk_ensemble_rank\"].max()\n",
    "merged[\"risk_ensemble_rank_norm\"] = (\n",
    "    (merged[\"risk_ensemble_rank\"] - r_min) / (r_max - r_min + 1e-8)\n",
    ")\n",
    "\n",
    "print(\"\\nMerged with ensemble risk:\")\n",
    "print(merged.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1050f0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === OPTIONAL: EVALUATE IPCW C-INDEX ON A LABELED VALIDATION SET ===\n",
    "\n",
    "def compute_ipcw_cindex(time_train, event_train, time_test, event_test, risk_scores, tau):\n",
    "    y_train_struct = Surv.from_arrays(event=event_train.astype(bool), time=time_train)\n",
    "    y_test_struct = Surv.from_arrays(event=event_test.astype(bool), time=time_test)\n",
    "    return concordance_index_ipcw(y_train_struct, y_test_struct, risk_scores, tau=tau)[0]\n",
    "\n",
    "try:\n",
    "    val_df = pd.read_csv(VAL_DATA_PATH)\n",
    "    print(f\"\\nLoaded validation data: {val_df.shape}\")\n",
    "\n",
    "    assert TIME_COL in val_df.columns and EVENT_COL in val_df.columns and \"ID\" in val_df.columns,\n",
    "        \"Validation data must contain 'ID', time and event columns.\"\n",
    "\n",
    "    # Align merged predictions with validation labels\n",
    "    val_merged = val_df[[\"ID\", TIME_COL, EVENT_COL]].merge(merged, on=\"ID\", how=\"inner\")\n",
    "    print(f\"Aligned validation + predictions shape: {val_merged.shape}\")\n",
    "\n",
    "    time_all = val_merged[TIME_COL].to_numpy(dtype=float)\n",
    "    event_all = val_merged[EVENT_COL].to_numpy(dtype=bool)\n",
    "\n",
    "    # For IPCW, we need a \"training\" sample to estimate weights.\n",
    "    # Here, we simply reuse the same validation data as reference.\n",
    "    time_train_ref = time_all\n",
    "    event_train_ref = event_all\n",
    "\n",
    "    # MTLR C-index\n",
    "    cindex_mtlr = compute_ipcw_cindex(\n",
    "        time_train_ref,\n",
    "        event_train_ref,\n",
    "        time_all,\n",
    "        event_all,\n",
    "        val_merged[\"risk_mtlr\"].values,\n",
    "        tau=TAU_CINDEX,\n",
    "    )\n",
    "\n",
    "    # XGB C-index\n",
    "    cindex_xgb = compute_ipcw_cindex(\n",
    "        time_train_ref,\n",
    "        event_train_ref,\n",
    "        time_all,\n",
    "        event_all,\n",
    "        val_merged[\"risk_xgb\"].values,\n",
    "        tau=TAU_CINDEX,\n",
    "    )\n",
    "\n",
    "    # Ensemble C-index\n",
    "    cindex_ens = compute_ipcw_cindex(\n",
    "        time_train_ref,\n",
    "        event_train_ref,\n",
    "        time_all,\n",
    "        event_all,\n",
    "        val_merged[\"risk_ensemble_rank\"].values,\n",
    "        tau=TAU_CINDEX,\n",
    "    )\n",
    "\n",
    "    print(\"\\nIPCW C-index on validation:\")\n",
    "    print(f\"  MTLR ensemble      : {cindex_mtlr:.4f}\")\n",
    "    print(f\"  XGB AFT ensemble   : {cindex_xgb:.4f}\")\n",
    "    print(f\"  Rank-avg ensemble  : {cindex_ens:.4f}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Validation data file not found. Skipping IPCW C-index evaluation.\")\n",
    "except AssertionError as e:\n",
    "    print(f\"Validation data format issue: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected error during evaluation: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb15767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SAVE FINAL META-ENSEMBLE PREDICTIONS ===\n",
    "\n",
    "final_submission = merged[[\"ID\", \"risk_ensemble_rank_norm\"]].rename(\n",
    "    columns={\"risk_ensemble_rank_norm\": \"risk_score\"}\n",
    ")\n",
    "\n",
    "output_path = \"../submissions/submission_meta_ensemble_rank_avg.csv\"\n",
    "final_submission.to_csv(output_path, index=False)\n",
    "print(f\"Meta-ensemble predictions saved to: {output_path}\")\n",
    "print(final_submission.head())\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
