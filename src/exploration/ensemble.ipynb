{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a659ef26ef22b93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T16:31:51.101671600Z",
     "start_time": "2025-10-01T16:27:44.196794Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sksurv.ensemble import GradientBoostingSurvivalAnalysis\n",
    "from sksurv.util import Surv\n",
    "import numpy as np\n",
    "from sksurv.metrics import concordance_index_ipcw\n",
    "from sksurv.linear_model import CoxnetSurvivalAnalysis, CoxPHSurvivalAnalysis\n",
    "from torchmtlr import MTLR, mtlr_neg_log_likelihood, mtlr_survival\n",
    "from torchmtlr.utils import encode_survival, make_time_bins\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "df = pd.read_csv('../../data/train_enhanced.csv', sep =',')\n",
    "eval = pd.read_csv('../../data/eval_enhanced.csv', sep =',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55268b801913d64f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T16:31:51.124440800Z",
     "start_time": "2025-10-01T16:27:44.533496Z"
    }
   },
   "outputs": [],
   "source": [
    "target = [\"OS_STATUS\", \"OS_YEARS\"]\n",
    "X = df.drop(columns = target + [\"ID\"])\n",
    "y = Surv.from_dataframe(*target, df[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27a93ce048820626",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T16:31:51.125945700Z",
     "start_time": "2025-10-01T16:27:44.798284Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9925c4371650389",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T16:31:51.125945700Z",
     "start_time": "2025-10-01T16:27:45.122502Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[( True, 0.83013699) ( True, 0.60273973) ( True, 1.03561644) ...\n",
      " (False, 0.84383562) ( True, 2.36164384) (False, 1.25753425)]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76d68a6b1e4a8e87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T16:31:51.127290100Z",
     "start_time": "2025-10-01T16:29:13.326391Z"
    }
   },
   "outputs": [],
   "source": [
    "if not isinstance(y_train, np.ndarray) or y_train.dtype.fields is None or len(y_train.dtype.fields) != 2:\n",
    "    print(\"cc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a035dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MTLRWrapper(BaseEstimator):\n",
    "    def __init__(self, input_dim, time_bins, n_hidden1=64, n_hidden2=32, dropout1=0.2, dropout2=0.2, activation='relu', n_epochs=100, lr=0.001, C1=1.0):\n",
    "        self.input_dim = input_dim\n",
    "        self.time_bins = time_bins\n",
    "        self.n_hidden1 = n_hidden1\n",
    "        self.n_hidden2 = n_hidden2\n",
    "        self.dropout1 = dropout1\n",
    "        self.dropout2 = dropout2\n",
    "        self.activation = activation\n",
    "        self.n_epochs = n_epochs\n",
    "        self.lr = lr\n",
    "        self.C1 = C1\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # y est un numpy structured array avec les champs 'event' et 'time'\n",
    "        # On force la copie pour Ã©viter le bug de strides\n",
    "        y_event = torch.tensor(np.copy(y['OS_STATUS'] if 'OS_STATUS' in y.dtype.names else y['event']), dtype=torch.float32)\n",
    "        y_time = torch.tensor(np.copy(y['OS_YEARS'] if 'OS_YEARS' in y.dtype.names else y['time']), dtype=torch.float32)\n",
    "        X_tensor = torch.tensor(np.copy(X.values), dtype=torch.float32)\n",
    "        target = encode_survival(y_time, y_event, self.time_bins)\n",
    "        act_fn = nn.ReLU() if self.activation == 'relu' else nn.ELU()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.n_hidden1),\n",
    "            act_fn,\n",
    "            nn.Dropout(self.dropout1),\n",
    "            nn.Linear(self.n_hidden1, self.n_hidden2),\n",
    "            act_fn,\n",
    "            nn.Dropout(self.dropout2),\n",
    "            MTLR(self.n_hidden2, len(self.time_bins))\n",
    "        )\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        self.model.train()\n",
    "        for epoch in range(self.n_epochs):\n",
    "            optimizer.zero_grad()\n",
    "            logits = self.model(X_tensor)\n",
    "            loss = mtlr_neg_log_likelihood(logits, target, self.model[-1], C1=self.C1, average=True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        import torch\n",
    "        X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = self.model(X_tensor)\n",
    "            risk_scores = torch.logsumexp(logits, dim=1).numpy()\n",
    "        return risk_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "941fa764d013d8f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T16:36:53.496627Z",
     "start_time": "2025-10-01T16:36:30.938382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=4)]: Done   9 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=4)]: Done  11 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=4)]: Done  13 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=4)]: Done  14 out of  20 | elapsed:   10.8s remaining:    4.6s\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "given numpy array strides not a multiple of the element byte size. Copy the numpy array to reallocate the memory.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31m_RemoteTraceback\u001b[39m                          Traceback (most recent call last)",
      "\u001b[31m_RemoteTraceback\u001b[39m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 490, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"c:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\joblib\\parallel.py\", line 607, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\sksurv\\meta\\ensemble_selection.py\", line 79, in _fit_and_score_fold\n    score = _fit_and_score(est, x, y, scorer, train_index, test_index, est.get_params(), fit_params, {})\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\sksurv\\meta\\base.py\", line 25, in _fit_and_score\n    est.fit(X_train, y_train, **train_params)\n  File \"C:\\Users\\arthr\\AppData\\Local\\Temp\\ipykernel_22144\\1607393882.py\", line 20, in fit\nValueError: given numpy array strides not a multiple of the element byte size. Copy the numpy array to reallocate the memory.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 54\u001b[39m\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m EnsembleSelection(\n\u001b[32m     42\u001b[39m         base_estimators=[\n\u001b[32m     43\u001b[39m             (\u001b[33m\"\u001b[39m\u001b[33mcoxNet\u001b[39m\u001b[33m\"\u001b[39m, coxNet),\n\u001b[32m   (...)\u001b[39m\u001b[32m     50\u001b[39m         verbose=\u001b[32m100\u001b[39m\n\u001b[32m     51\u001b[39m     )\n\u001b[32m     53\u001b[39m model = get_ensemble_model()\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# Evaluate the model using Concordance Index IPCW\u001b[39;00m\n\u001b[32m     57\u001b[39m cox_cindex_train = concordance_index_ipcw(y_train, y_train, model.predict(X_train), tau=\u001b[32m7\u001b[39m)[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\sksurv\\meta\\ensemble_selection.py:320\u001b[39m, in \u001b[36mBaseEnsembleSelection.fit\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;28mself\u001b[39m._check_params()\n\u001b[32m    319\u001b[39m cv = check_cv(\u001b[38;5;28mself\u001b[39m.cv, X)\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\sksurv\\meta\\ensemble_selection.py:433\u001b[39m, in \u001b[36mEnsembleSelection._fit\u001b[39m\u001b[34m(self, X, y, cv, **fit_params)\u001b[39m\n\u001b[32m    432\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, cv, **fit_params):\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m     scores, base_ensemble = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_and_score_ensemble\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    434\u001b[39m     \u001b[38;5;28mself\u001b[39m.fitted_models_, \u001b[38;5;28mself\u001b[39m.scores_ = \u001b[38;5;28mself\u001b[39m._prune_by_cv_score(scores, base_ensemble)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\sksurv\\meta\\ensemble_selection.py:265\u001b[39m, in \u001b[36mBaseEnsembleSelection._fit_and_score_ensemble\u001b[39m\u001b[34m(self, X, y, cv, **fit_params)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;66;03m# Take care of custom kernel functions\u001b[39;00m\n\u001b[32m    263\u001b[39m base_estimators, kernel_cache = \u001b[38;5;28mself\u001b[39m._get_base_estimators(X)\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m out = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score_fold\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkernel_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkernel_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbase_estimators\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_index\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfolds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kernel_cache) > \u001b[32m0\u001b[39m:\n\u001b[32m    282\u001b[39m     out = \u001b[38;5;28mself\u001b[39m._restore_base_estimators(kernel_cache, out, X, folds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1784\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1778\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._wait_retrieval():\n\u001b[32m   1779\u001b[39m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[32m   1780\u001b[39m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[32m   1781\u001b[39m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[32m   1782\u001b[39m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[32m   1783\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._aborting:\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1785\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1787\u001b[39m     nb_jobs = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1859\u001b[39m, in \u001b[36mParallel._raise_error_fast\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1855\u001b[39m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[32m   1856\u001b[39m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[32m   1857\u001b[39m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1859\u001b[39m     \u001b[43merror_job\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\joblib\\parallel.py:758\u001b[39m, in \u001b[36mBatchCompletionCallBack.get_result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    752\u001b[39m backend = \u001b[38;5;28mself\u001b[39m.parallel._backend\n\u001b[32m    754\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend.supports_retrieve_callback:\n\u001b[32m    755\u001b[39m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[32m    756\u001b[39m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[32m    757\u001b[39m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\arthr\\Desktop\\ENSAE\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\joblib\\parallel.py:773\u001b[39m, in \u001b[36mBatchCompletionCallBack._return_or_raise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    771\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    772\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.status == TASK_ERROR:\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m    775\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: given numpy array strides not a multiple of the element byte size. Copy the numpy array to reallocate the memory."
     ]
    }
   ],
   "source": [
    "from sksurv.meta import EnsembleSelection\n",
    "\n",
    "# Initialize and train the Cox Proportional Hazards model\n",
    "\n",
    "\n",
    "def get_ensemble_model():\n",
    "    coxNet = CoxnetSurvivalAnalysis(\n",
    "      l1_ratio=0.7773238493438969,\n",
    "      alpha_min_ratio=0.007495756210143564,\n",
    "      n_alphas=52,\n",
    "      max_iter=717302,\n",
    "      tol=7.904569805860203e-06\n",
    "    )\n",
    "\n",
    "    coxPH = CoxPHSurvivalAnalysis(\n",
    "        alpha=9.560874711411728,\n",
    "        n_iter=570,\n",
    "        tol=3.921651247591744e-08\n",
    "    )\n",
    "\n",
    "    gbSurv = GradientBoostingSurvivalAnalysis(\n",
    "        n_estimators=238,\n",
    "        learning_rate= 0.22161644549500695,\n",
    "        max_depth= 3,\n",
    "        min_samples_split= 14,\n",
    "        min_samples_leaf= 9,\n",
    "        max_features= 'sqrt',\n",
    "        subsample= 0.8525763914058241,\n",
    "        dropout_rate= 0.0002948696684484872,\n",
    "    )\n",
    "\n",
    "    mtlr = MTLRWrapper(\n",
    "        input_dim=X.shape[1],\n",
    "        time_bins=make_time_bins(df['OS_YEARS'], event=df['OS_STATUS']),\n",
    "        n_hidden1=64, n_hidden2=32, n_epochs=100\n",
    "    )\n",
    "\n",
    "    def scorer(estimator, X_test, y_test, **test_predict_params):\n",
    "        return concordance_index_ipcw(y, y_test, estimator.predict(X_test), tau=7)[0]\n",
    "\n",
    "    return EnsembleSelection(\n",
    "        base_estimators=[\n",
    "            (\"coxNet\", coxNet),\n",
    "            (\"coxPH\", coxPH),\n",
    "            (\"gbSurv\", gbSurv),\n",
    "            (\"mtlr\", mtlr)\n",
    "        ],\n",
    "        scorer=scorer,\n",
    "        n_jobs=4,\n",
    "        verbose=100\n",
    "    )\n",
    "\n",
    "model = get_ensemble_model()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model using Concordance Index IPCW\n",
    "cox_cindex_train = concordance_index_ipcw(y_train, y_train, model.predict(X_train), tau=7)[0]\n",
    "cox_cindex_test = concordance_index_ipcw(y_train, y_test, model.predict(X_test), tau=7)[0]\n",
    "print(f\"Cox Proportional Hazard Model Concordance Index IPCW on train: {cox_cindex_train:.4f}\")\n",
    "print(f\"Cox Proportional Hazard Model Concordance Index IPCW on test: {cox_cindex_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e92ae914ba29858",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T16:38:47.193138Z",
     "start_time": "2025-10-01T16:36:53.513409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.020247220993041992s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done   9 out of  15 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  15 | elapsed:    0.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  11 out of  15 | elapsed:   11.7s remaining:    4.2s\n",
      "[Parallel(n_jobs=4)]: Done  12 out of  15 | elapsed:   11.8s remaining:    2.9s\n",
      "[Parallel(n_jobs=4)]: Done  13 out of  15 | elapsed:   11.9s remaining:    1.7s\n",
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:   23.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.02048325538635254s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.021166086196899414s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "Fold 1 - Train C-Index IPCW: 0.7580, Test C-Index IPCW: 0.7243\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.023120403289794922s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done   9 out of  15 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  15 | elapsed:    0.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  11 out of  15 | elapsed:   11.6s remaining:    4.2s\n",
      "[Parallel(n_jobs=4)]: Done  12 out of  15 | elapsed:   11.7s remaining:    2.9s\n",
      "[Parallel(n_jobs=4)]: Done  13 out of  15 | elapsed:   11.8s remaining:    1.7s\n",
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:   22.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.03220653533935547s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.019811630249023438s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "Fold 2 - Train C-Index IPCW: 0.7633, Test C-Index IPCW: 0.6883\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.02004528045654297s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done   9 out of  15 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  15 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  11 out of  15 | elapsed:   11.3s remaining:    4.1s\n",
      "[Parallel(n_jobs=4)]: Done  12 out of  15 | elapsed:   11.3s remaining:    2.8s\n",
      "[Parallel(n_jobs=4)]: Done  13 out of  15 | elapsed:   11.5s remaining:    1.7s\n",
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:   22.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.021937847137451172s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.0246427059173584s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "Fold 3 - Train C-Index IPCW: 0.7558, Test C-Index IPCW: 0.7296\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.019379854202270508s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done   9 out of  15 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  15 | elapsed:    0.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  11 out of  15 | elapsed:   11.4s remaining:    4.1s\n",
      "[Parallel(n_jobs=4)]: Done  12 out of  15 | elapsed:   11.4s remaining:    2.8s\n",
      "[Parallel(n_jobs=4)]: Done  13 out of  15 | elapsed:   11.5s remaining:    1.7s\n",
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:   22.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.020484209060668945s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.020359516143798828s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "Fold 4 - Train C-Index IPCW: 0.7566, Test C-Index IPCW: 0.7095\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.02042865753173828s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done   9 out of  15 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  15 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  11 out of  15 | elapsed:   11.2s remaining:    4.0s\n",
      "[Parallel(n_jobs=4)]: Done  12 out of  15 | elapsed:   11.2s remaining:    2.7s\n",
      "[Parallel(n_jobs=4)]: Done  13 out of  15 | elapsed:   11.2s remaining:    1.6s\n",
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:   22.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.023626089096069336s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.022934675216674805s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   3 out of   3 | elapsed:    0.0s finished\n",
      "Fold 5 - Train C-Index IPCW: 0.7604, Test C-Index IPCW: 0.6986\n",
      "\n",
      "Average Train C-Index IPCW: 0.7588 (+/- 0.0027)\n",
      "Average Test C-Index IPCW: 0.7101 (+/- 0.0155)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Initialize K-Fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Store cross-validation scores\n",
    "cv_scores_train = []\n",
    "cv_scores_test = []\n",
    "\n",
    "# Perform K-Fold cross-validation\n",
    "for fold, (train_idx, test_idx) in enumerate(kf.split(X), 1):\n",
    "    # Split data\n",
    "    X_train_fold = X.iloc[train_idx]\n",
    "    X_test_fold = X.iloc[test_idx]\n",
    "    y_train_fold = y[train_idx]\n",
    "    y_test_fold = y[test_idx]\n",
    "\n",
    "    # Impute missing values\n",
    "    X_train_fold = pd.DataFrame(\n",
    "        X_train_fold,\n",
    "        columns=X_train_fold.columns,\n",
    "        index=X_train_fold.index\n",
    "    )\n",
    "    X_test_fold = pd.DataFrame(\n",
    "        X_test_fold,\n",
    "        columns=X_test_fold.columns,\n",
    "        index=X_test_fold.index\n",
    "    )\n",
    "\n",
    "    # Train Cox model\n",
    "    cox_fold = get_ensemble_model()\n",
    "    cox_fold.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Evaluate\n",
    "    train_score = concordance_index_ipcw(y, y_train_fold, cox_fold.predict(X_train_fold), tau=7)[0]\n",
    "    test_score = concordance_index_ipcw(y, y_test_fold, cox_fold.predict(X_test_fold), tau=7)[0]\n",
    "\n",
    "    cv_scores_train.append(train_score)\n",
    "    cv_scores_test.append(test_score)\n",
    "\n",
    "    print(f\"Fold {fold} - Train C-Index IPCW: {train_score:.4f}, Test C-Index IPCW: {test_score:.4f}\")\n",
    "\n",
    "# Print average scores\n",
    "print(f\"\\nAverage Train C-Index IPCW: {np.mean(cv_scores_train):.4f} (+/- {np.std(cv_scores_train):.4f})\")\n",
    "print(f\"Average Test C-Index IPCW: {np.mean(cv_scores_test):.4f} (+/- {np.std(cv_scores_test):.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8254f8cc7af5400",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T16:39:53.734068Z",
     "start_time": "2025-10-01T16:39:21.457119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.025449037551879883s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done   9 out of  15 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  15 | elapsed:    0.3s remaining:    0.1s\n",
      "[Parallel(n_jobs=4)]: Done  11 out of  15 | elapsed:   16.6s remaining:    6.0s\n",
      "[Parallel(n_jobs=4)]: Done  12 out of  15 | elapsed:   16.6s remaining:    4.1s\n",
      "[Parallel(n_jobs=4)]: Done  13 out of  15 | elapsed:   16.6s remaining:    2.5s\n",
      "[Parallel(n_jobs=4)]: Done  15 out of  15 | elapsed:   32.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Batch computation too fast (0.02171182632446289s.) Setting batch_size=2.\n",
      "[Parallel(n_jobs=4)]: Done   3 out of   3 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "cox_final = get_ensemble_model()\n",
    "cox_final.fit(X, y)\n",
    "prediction = cox_final.predict(eval.drop(columns=[\"ID\"]))\n",
    "submission = pd.Series(prediction, index=eval['ID'], name='risk_score')\n",
    "submission.to_csv('../../submissions/ensemble_one.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb72d23ac31bf028",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T16:43:09.889232Z",
     "start_time": "2025-10-01T16:43:09.886060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned model predictions saved to: ensemble_one.csv\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tuned model predictions saved to: ensemble_one.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930795f965068d49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
