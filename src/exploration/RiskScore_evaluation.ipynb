{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Synthetic Risk Score Validation Notebook\n",
        "\n",
        "This notebook provides a **rigorous validation** of a **synthetic survival risk score**.\n",
        "\n",
        "The goal is to evaluate how well a single feature (e.g., a Cox-based linear predictor)\n",
        "predicts time-to-event outcomes.\n",
        "\n",
        "## Assumptions\n",
        "- The dataset is in a CSV file with at least the following columns:\n",
        "  - `OS_YEARS`: survival time in years.\n",
        "  - `OS_STATUS`: event indicator (1 = event, 0 = censored).\n",
        "  - `RiskScore`: continuous synthetic risk score (higher = worse prognosis).\n",
        "\n",
        "---\n",
        "### What this notebook will compute\n",
        "1. Descriptive analysis of the risk score.\n",
        "2. Kaplanâ€“Meier curves by risk quartiles + log-rank test.\n",
        "3. Univariate Cox proportional hazards model for the risk score.\n",
        "4. Bootstrap confidence intervals for the C-index.\n",
        "5. K-fold cross-validated C-index, AUC(t), and Integrated Brier Score (IBS)\n",
        "   for:\n",
        "   - a baseline model (no RiskScore),\n",
        "   - a Cox model with RiskScore.\n",
        "6. Permutation test.\n",
        "7. Calibration plot at a chosen time horizon.\n",
        "8. Summary + deltas (with - without RiskScore).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ===============================\n",
        "# 0. Imports & configuration\n",
        "# ===============================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from lifelines import CoxPHFitter, KaplanMeierFitter\n",
        "from lifelines.statistics import multivariate_logrank_test\n",
        "from lifelines.utils import concordance_index\n",
        "\n",
        "from sksurv.util import Surv\n",
        "from sksurv.metrics import (\n",
        "    concordance_index_censored,\n",
        "    cumulative_dynamic_auc,\n",
        "    integrated_brier_score,\n",
        ")\n",
        "from sksurv.nonparametric import kaplan_meier_estimator\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (7, 5)\n",
        "plt.rcParams['axes.grid'] = True\n",
        "\n",
        "DATA_PATH = '../../data/train_enhanced.csv'\n",
        "TIME_COL = 'OS_YEARS'\n",
        "EVENT_COL = 'OS_STATUS'\n",
        "RISK_COL = 'RiskScore'\n",
        "\n",
        "AUC_TIMES = np.array([1.0, 2.0, 3.0])\n",
        "CALIBRATION_TIME = 2.0\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "N_BOOTSTRAP = 1000\n",
        "N_SPLITS_CV = 5\n",
        "\n",
        "np.random.seed(RANDOM_STATE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load and inspect data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "df = pd.read_csv(DATA_PATH)\n",
        "df = df[[TIME_COL, EVENT_COL, RISK_COL]].copy().dropna()\n",
        "df[EVENT_COL] = df[EVENT_COL].astype(int)\n",
        "print('Data shape:', df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "print(df[RISK_COL].describe())\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Histogram(x=df[RISK_COL], nbinsx=30, name='Risk score'))\n",
        "fig.update_layout(title='Distribution of synthetic risk score',\n",
        "                  xaxis_title='Risk score', yaxis_title='Count',\n",
        "                  template='simple_white', bargap=0.05)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "df = df.sort_values(RISK_COL).reset_index(drop=True)\n",
        "df['risk_quartile'] = pd.qcut(df[RISK_COL], q=4,\n",
        "                              labels=['Q1 (lowest)','Q2','Q3','Q4 (highest)'])\n",
        "\n",
        "kmf = KaplanMeierFitter()\n",
        "fig = go.Figure()\n",
        "\n",
        "for q in df['risk_quartile'].cat.categories:\n",
        "    mask = df['risk_quartile'] == q\n",
        "    kmf.fit(df.loc[mask, TIME_COL], df.loc[mask, EVENT_COL], label=str(q))\n",
        "    sf = kmf.survival_function_\n",
        "    t = sf.index.values\n",
        "    s = sf.iloc[:,0].values\n",
        "    fig.add_trace(go.Scatter(x=t,y=s,mode='lines',name=str(q)))\n",
        "\n",
        "fig.update_layout(title='KM survival by risk quartile',\n",
        "                  xaxis_title='Time', yaxis_title='Survival probability',\n",
        "                  template='simple_white')\n",
        "fig.show()\n",
        "\n",
        "lr = multivariate_logrank_test(df[TIME_COL], df['risk_quartile'], df[EVENT_COL])\n",
        "print(lr)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "cph = CoxPHFitter()\n",
        "cph.fit(df[[TIME_COL, EVENT_COL, RISK_COL]], duration_col=TIME_COL, event_col=EVENT_COL)\n",
        "cph.print_summary()\n",
        "c_index_in_sample = cph.concordance_index_\n",
        "print(\"In-sample C-index =\", c_index_in_sample)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from lifelines.utils import concordance_index\n",
        "\n",
        "def bootstrap_c_index(df,n_boot=1000):\n",
        "    rng=np.random.RandomState(42)\n",
        "    cvals=[]\n",
        "    for _ in range(n_boot):\n",
        "        idx=rng.randint(0,len(df),size=len(df))\n",
        "        s=df.iloc[idx]\n",
        "        c=concordance_index(s[TIME_COL],-s[RISK_COL],s[EVENT_COL])\n",
        "        cvals.append(c)\n",
        "    cvals=np.array(cvals)\n",
        "    return cvals.mean(),np.percentile(cvals,[2.5,97.5]),cvals\n",
        "\n",
        "mean_c,(low,high),boot=bootstrap_c_index(df,N_BOOTSTRAP)\n",
        "print(mean_c,low,high)\n",
        "\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Histogram(x=boot,nbinsx=30))\n",
        "fig.update_layout(title='Bootstrap C-index',template='simple_white')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ===== 5. Cross-validation =====\n",
        "y_struct = Surv.from_dataframe(event=EVENT_COL,time=TIME_COL,data=df)\n",
        "kf = KFold(n_splits=N_SPLITS_CV,shuffle=True,random_state=RANDOM_STATE)\n",
        "event_field,time_field=y_struct.dtype.names\n",
        "\n",
        "cindex_with=[]; ibs_with=[]; auc_with=[]\n",
        "cindex_base=[]; ibs_base=[]; auc_base=[]\n",
        "\n",
        "for tr,te in kf.split(df):\n",
        "    df_tr=df.iloc[tr]; df_te=df.iloc[te]\n",
        "    y_tr=y_struct[tr]; y_te=y_struct[te]\n",
        "\n",
        "    # Cox with RiskScore\n",
        "    m=CoxPHFitter()\n",
        "    m.fit(df_tr[[TIME_COL,EVENT_COL,RISK_COL]],duration_col=TIME_COL,event_col=EVENT_COL)\n",
        "    risk=m.predict_partial_hazard(df_te[[RISK_COL]]).values.ravel()\n",
        "    cindex_with.append(concordance_index_censored(y_te[event_field].astype(bool),y_te[time_field],risk)[0])\n",
        "\n",
        "    surv=m.predict_survival_function(df_te[[RISK_COL]])\n",
        "    times=surv.index.values\n",
        "    preds=surv.T.values\n",
        "\n",
        "    max_t=y_tr[time_field].max()\n",
        "    mask=y_te[time_field]<max_t\n",
        "    if mask.sum()>0:\n",
        "        y_te_ib=y_te[mask]\n",
        "        preds_ib=preds[mask]\n",
        "        tmin=y_te_ib[time_field].min(); tmax=y_te_ib[time_field].max()\n",
        "        mt=(times>=tmin)&(times<tmax)\n",
        "        if mt.sum()>=2:\n",
        "            ibs_with.append(integrated_brier_score(y_tr,y_te_ib,preds_ib[:,mt],times[mt]))\n",
        "        else:\n",
        "            ibs_with.append(np.nan)\n",
        "    else:\n",
        "        ibs_with.append(np.nan)\n",
        "\n",
        "    auc_vec=np.full(len(AUC_TIMES),np.nan)\n",
        "    tt=y_te[time_field]\n",
        "    ok=AUC_TIMES[(AUC_TIMES>=max(tt.min(),1e-8))&(AUC_TIMES<tt.max())]\n",
        "    if len(ok)>0:\n",
        "        et,av=cumulative_dynamic_auc(y_tr,y_te,risk,ok)\n",
        "        for t0,a0 in zip(et,av):\n",
        "            idx=np.where(np.isclose(AUC_TIMES,t0))[0]\n",
        "            if len(idx)>0: auc_vec[idx[0]]=a0\n",
        "    auc_with.append(auc_vec)\n",
        "\n",
        "    # Baseline KM\n",
        "    ttr,strr=kaplan_meier_estimator(y_tr[event_field].astype(bool),y_tr[time_field])\n",
        "    risk0=np.zeros_like(y_te[time_field])\n",
        "    cindex_base.append(concordance_index_censored(y_te[event_field].astype(bool),y_te[time_field],risk0)[0])\n",
        "\n",
        "    max_t2=y_tr[time_field].max()\n",
        "    mask2=y_te[time_field]<max_t2\n",
        "    if mask2.sum()>0:\n",
        "        y_te2=y_te[mask2]\n",
        "        tmin2=y_te2[time_field].min(); tmax2=y_te2[time_field].max()\n",
        "        mt2=(ttr>=tmin2)&(ttr<tmax2)\n",
        "        if mt2.sum()>=2:\n",
        "            pred=np.tile(strr[mt2],(len(y_te2),1))\n",
        "            ibs_base.append(integrated_brier_score(y_tr,y_te2,pred,ttr[mt2]))\n",
        "        else:\n",
        "            ibs_base.append(np.nan)\n",
        "    else:\n",
        "        ibs_base.append(np.nan)\n",
        "\n",
        "    auc_vec2=np.full(len(AUC_TIMES),np.nan)\n",
        "    if len(ok)>0:\n",
        "        et2,av2=cumulative_dynamic_auc(y_tr,y_te,risk0,ok)\n",
        "        for t0,a0 in zip(et2,av2):\n",
        "            idx=np.where(np.isclose(AUC_TIMES,t0))[0]\n",
        "            if len(idx)>0: auc_vec2[idx[0]]=a0\n",
        "    auc_base.append(auc_vec2)\n",
        "\n",
        "cindex_with=np.array(cindex_with); ibs_with=np.array(ibs_with); auc_with=np.array(auc_with)\n",
        "cindex_base=np.array(cindex_base); ibs_base=np.array(ibs_base); auc_base=np.array(auc_base)\n",
        "\n",
        "print('WITH RiskScore C-index mean=',np.nanmean(cindex_with))\n",
        "print('BASELINE C-index mean=',np.nanmean(cindex_base))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ===== 6. Permutation test =====\n",
        "def permutation_test(df,n_perm=500):\n",
        "    rng=np.random.RandomState(42); vals=[]\n",
        "    for _ in range(n_perm):\n",
        "        s=df.copy()\n",
        "        s[RISK_COL]=rng.permutation(s[RISK_COL].values)\n",
        "        m=CoxPHFitter()\n",
        "        m.fit(s[[TIME_COL,EVENT_COL,RISK_COL]],duration_col=TIME_COL,event_col=EVENT_COL)\n",
        "        vals.append(m.concordance_index_)\n",
        "    return np.array(vals)\n",
        "\n",
        "perm=permutation_test(df,500)\n",
        "true_cindex=c_index_in_sample\n",
        "print(true_cindex,perm.mean())\n",
        "\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Histogram(x=perm,nbinsx=30,opacity=0.75))\n",
        "fig.add_trace(go.Scatter(x=[true_cindex,true_cindex],y=[0,len(perm)/3],mode='lines',name='True'))\n",
        "fig.update_layout(template='simple_white')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ===== 7. Calibration =====\n",
        "m=CoxPHFitter()\n",
        "m.fit(df[[TIME_COL,EVENT_COL,RISK_COL]],duration_col=TIME_COL,event_col=EVENT_COL)\n",
        "surv=m.predict_survival_function(df[[RISK_COL]])\n",
        "times=surv.index.values\n",
        "\n",
        "idx=np.searchsorted(times,CALIBRATION_TIME,side='right')-1\n",
        "t_eff=times[idx]\n",
        "pred=surv.iloc[idx].values\n",
        "\n",
        "n_bins=10\n",
        "q=np.quantile(pred,np.linspace(0,1,n_bins+1))\n",
        "bid=np.digitize(pred,q[1:-1],right=True)\n",
        "\n",
        "bx=[]; by=[]\n",
        "for b in range(n_bins):\n",
        "    mask=bid==b\n",
        "    if mask.sum()<10: continue\n",
        "    bx.append(pred[mask].mean())\n",
        "\n",
        "    t,s=kaplan_meier_estimator(df.loc[mask,EVENT_COL].values.astype(bool),\n",
        "                               df.loc[mask,TIME_COL].values)\n",
        "    if (t<=t_eff).any(): by.append(s[t<=t_eff][-1])\n",
        "    else: by.append(1.0)\n",
        "\n",
        "fig=go.Figure()\n",
        "fig.add_trace(go.Scatter(x=bx,y=by,mode='markers+lines',name='Observed'))\n",
        "fig.add_trace(go.Scatter(x=[0,1],y=[0,1],mode='lines',name='Perfect'))\n",
        "fig.update_layout(title=f'Calibration at t={t_eff:.2f}',template='simple_white')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# ===== 8. Summary + deltas =====\n",
        "def summarize(results,label):\n",
        "    c=np.array(results['c_index']); i=np.array(results['ibs']); a=results['auc_per_time']\n",
        "    times=np.array(results['times_auc'],dtype=float)\n",
        "    out={'label':label,'c_index_mean':float(np.nanmean(c)),'ibs_mean':float(np.nanmean(i))}\n",
        "    if len(a)>0:\n",
        "        aa=np.array(a); \n",
        "        for k,t in enumerate(times):\n",
        "            out[f'auc_{t:.2f}_mean']=float(np.nanmean(aa[:,k]))\n",
        "    return pd.Series(out)\n",
        "\n",
        "results_with={'c_index':cindex_with,'ibs':ibs_with,'auc_per_time':auc_with,'times_auc':AUC_TIMES}\n",
        "results_no={'c_index':cindex_base,'ibs':ibs_base,'auc_per_time':auc_base,'times_auc':AUC_TIMES}\n",
        "\n",
        "s_no=summarize(results_no,'no_risk')\n",
        "s_with=summarize(results_with,'with_risk')\n",
        "\n",
        "print(pd.concat([s_no,s_with],axis=1))\n",
        "\n",
        "delta=pd.Series({'delta_c_index':s_with['c_index_mean']-s_no['c_index_mean'],\n",
        "                 'delta_ibs':s_with['ibs_mean']-s_no['ibs_mean']})\n",
        "print(delta)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}