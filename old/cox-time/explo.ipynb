{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-09T21:27:01.266763Z",
     "start_time": "2025-09-09T21:26:58.184171Z"
    }
   },
   "source": [
    "# pip install pycox torchtuples scikit-survival sklearn-pandas pyarrow\n",
    "# If PyTorch is missing:\n",
    "# pip install torch --index-url https://download.pytorch.org/whl/cpu\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sksurv.nonparametric import kaplan_meier_estimator\n",
    "from sksurv.metrics import concordance_index_ipcw\n",
    "from sksurv.util import Surv\n",
    "\n",
    "from pycox.models import CoxTime\n",
    "from pycox.models.cox_time import MLPVanillaCoxTime\n",
    "import torchtuples as tt\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T21:27:03.173495Z",
     "start_time": "2025-09-09T21:27:03.161168Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# Config\n",
    "# =========================\n",
    "SEED = 42\n",
    "EPOCHS = 80\n",
    "BATCH_SIZE = 128\n",
    "LR = 3e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "HIDDEN = [256, 128]\n",
    "VAL_FRAC = 0.2\n",
    "HORIZON_QUANTILE = 0.7  # quantile des temps d'événement pour définir t*\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ],
   "id": "d7c3086b6272dbfd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1866cf85df0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T21:27:03.727866Z",
     "start_time": "2025-09-09T21:27:03.661969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# Données\n",
    "# =========================\n",
    "# df: doit contenir OS_YEARS, OS_STATUS et des features\n",
    "try:\n",
    "    df = pd.read_csv(\"../data/df_train_scaled.csv\")  # si déjà en mémoire, on l'utilise\n",
    "except NameError:\n",
    "    from pycox.datasets import metabric\n",
    "    df = metabric.read_df().rename(columns={\"duration\": \"OS_YEARS\", \"event\": \"OS_STATUS\"})\n",
    "    print(\"Demo METABRIC. Remplace par ton dataframe `df` avec OS_YEARS, OS_STATUS et tes features.\")\n",
    "\n",
    "target_time = \"OS_YEARS\"\n",
    "target_event = \"OS_STATUS\"\n",
    "feature_cols = [c for c in df.columns if c not in [target_time, target_event]]"
   ],
   "id": "602cd391a1a99eb5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T21:27:04.135463Z",
     "start_time": "2025-09-09T21:27:04.118730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# Split\n",
    "# =========================\n",
    "df_trainval, df_test = train_test_split(df, test_size=0.2, random_state=SEED, stratify=df[target_event])\n",
    "df_train, df_val = train_test_split(df_trainval, test_size=VAL_FRAC, random_state=SEED, stratify=df_trainval[target_event])\n",
    "\n",
    "def xy(df_):\n",
    "    X = df_[feature_cols].copy()\n",
    "    y_time = df_[target_time].to_numpy(dtype=\"float32\")\n",
    "    y_event = df_[target_event].to_numpy(dtype=\"int64\")\n",
    "    return X, y_time, y_event\n",
    "\n",
    "X_train, t_train, e_train = xy(df_train)\n",
    "X_val,   t_val,   e_val   = xy(df_val)\n",
    "X_test,  t_test,  e_test  = xy(df_test)"
   ],
   "id": "4871b0372db4c424",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T21:27:04.598124Z",
     "start_time": "2025-09-09T21:27:04.551543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# Préprocessing float32\n",
    "# =========================\n",
    "num_cols = [c for c in X_train.columns if pd.api.types.is_numeric_dtype(X_train[c])]\n",
    "cat_cols = [c for c in X_train.columns if c not in num_cols]\n",
    "\n",
    "pre = Pipeline(steps=[\n",
    "    (\"ct\", ColumnTransformer([\n",
    "        (\"num\", StandardScaler(), num_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, dtype=np.float32), cat_cols),\n",
    "    ], remainder=\"drop\")),\n",
    "])\n",
    "\n",
    "pre.fit(X_train)\n",
    "Xtr = pre.transform(X_train).astype(np.float32)\n",
    "Xva = pre.transform(X_val).astype(np.float32)\n",
    "Xte = pre.transform(X_test).astype(np.float32)\n",
    "\n",
    "t_train = t_train.astype(np.float32)\n",
    "t_val   = t_val.astype(np.float32)\n",
    "t_test  = t_test.astype(np.float32)\n",
    "e_train = e_train.astype(np.int64)\n",
    "e_val   = e_val.astype(np.int64)\n",
    "e_test  = e_test.astype(np.int64)\n"
   ],
   "id": "c77bb381b4eb5196",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T21:27:07.210678Z",
     "start_time": "2025-09-09T21:27:05.085388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# Cox-Time + coxtimemlp\n",
    "# =========================\n",
    "net = MLPVanillaCoxTime(\n",
    "    in_features=Xtr.shape[1],\n",
    "    num_nodes=HIDDEN,\n",
    "    batch_norm=True,\n",
    "    dropout=0.05,\n",
    ")\n",
    "\n",
    "optimizer = tt.optim.Adam(lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "model = CoxTime(net, optimizer, device=\"cpu\")\n",
    "\n",
    "# Label transform Cox-Time\n",
    "labtrans = CoxTime.label_transform()\n",
    "y_tr = labtrans.fit_transform(t_train, e_train)\n",
    "y_va = labtrans.transform(t_val, e_val)\n",
    "\n",
    "# Entraînement\n",
    "callbacks = [tt.callbacks.EarlyStopping(patience=12)]\n",
    "_ = model.fit(Xtr, y_tr, BATCH_SIZE, EPOCHS, callbacks, verbose=False, val_data=(Xva, y_va))\n"
   ],
   "id": "1c195a88bc417c40",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Concordance\\PycharmProjects\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\torchtuples\\tupletree.py:597: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\autograd\\python_variable_indexing.cpp:312.)\n",
      "  return self.tuple_.apply(lambda x: x[index])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T21:27:10.535272Z",
     "start_time": "2025-09-09T21:27:07.302988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# Survie prédite\n",
    "# =========================\n",
    "model.compute_baseline_hazards()\n",
    "\n",
    "surv_te = model.predict_surv_df(Xte)             # index = grille de temps\n",
    "time_grid = surv_te.index.values.astype(float)\n",
    "\n",
    "# t* depuis les temps d'événement d'entraînement, projeté sur la grille\n",
    "event_times_train = t_train[e_train.astype(bool) == 1]\n",
    "if event_times_train.size == 0:\n",
    "    raise ValueError(\"Aucun événement dans le train. Cox-Time et Uno IPCW en ont besoin.\")\n",
    "t_star_raw = float(np.quantile(event_times_train, HORIZON_QUANTILE))\n",
    "t_star = float(time_grid[np.argmin(np.abs(time_grid - t_star_raw))])"
   ],
   "id": "6b8737e8487e622e",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T21:27:10.653337Z",
     "start_time": "2025-09-09T21:27:10.646227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# =========================\n",
    "# τ sûr via KM de la censure\n",
    "# =========================\n",
    "t_km, Ghat = kaplan_meier_estimator(~e_train.astype(bool), t_train.astype(float))\n",
    "if np.any(Ghat > 0):\n",
    "    tau_max = t_km[Ghat > 0][-1]\n",
    "    tau_safe = float(np.nextafter(tau_max, 0.0))  # léger retrait\n",
    "else:\n",
    "    raise ValueError(\"Aucune observation censurée dans le train. Uno IPCW est indéfini.\")\n",
    "\n",
    "# Clamp de l’horizon à τ\n",
    "t_star_clamped = min(t_star, tau_safe)\n",
    "t_star_clamped = float(time_grid[np.argmin(np.abs(time_grid - t_star_clamped))])\n",
    "\n",
    "# Risk = 1 - S(t*)\n",
    "risk_test = 1.0 - surv_te.loc[t_star_clamped].to_numpy()"
   ],
   "id": "d0a629ab7dcfff24",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T21:27:13.221888Z",
     "start_time": "2025-09-09T21:27:10.659040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- IPCW-C sur plusieurs horizons + IC bootstrap ---\n",
    "from sksurv.metrics import concordance_index_ipcw\n",
    "from sksurv.util import Surv\n",
    "\n",
    "y_train_struct = Surv.from_arrays(event=e_train.astype(bool), time=t_train.astype(float))\n",
    "y_test_struct  = Surv.from_arrays(event=e_test.astype(bool),  time=t_test.astype(float))\n",
    "\n",
    "def nearest_time(t, grid):\n",
    "    g = np.asarray(grid, dtype=float)\n",
    "    return float(g[np.argmin(np.abs(g - t))])\n",
    "\n",
    "# Horizons: quantiles d'événements train, clampés à tau\n",
    "q_list = [0.25, 0.5, 0.75, 0.9]\n",
    "event_times_train = t_train[e_train.astype(bool)]\n",
    "eval_times = []\n",
    "for q in q_list:\n",
    "    tq = float(np.quantile(event_times_train, q))\n",
    "    tq = min(tq, tau_safe)\n",
    "    eval_times.append(nearest_time(tq, surv_te.index.values))\n",
    "\n",
    "def ipcw_at_t(t_eval, idx=None):\n",
    "    # risk = 1 - S(t_eval)\n",
    "    s = surv_te.loc[t_eval].to_numpy()\n",
    "    risk = 1.0 - s\n",
    "    if idx is not None:\n",
    "        return concordance_index_ipcw(y_train_struct,\n",
    "                                      Surv.from_arrays(event=e_test[idx].astype(bool),\n",
    "                                                       time=t_test[idx].astype(float)),\n",
    "                                      risk[idx], tau=tau_safe)[0]\n",
    "    return concordance_index_ipcw(y_train_struct, y_test_struct, risk, tau=tau_safe)[0]\n",
    "\n",
    "# Scores par horizon\n",
    "for t_eval in eval_times:\n",
    "    c = ipcw_at_t(t_eval)\n",
    "    print(f\"IPCW-C at t={t_eval:.3f}y: {c:.4f}\")\n",
    "\n",
    "# Bootstrap 95% CI au t* utilisé pour ton score principal\n",
    "rng = np.random.default_rng(42)\n",
    "B = 300\n",
    "n = len(df_test)\n",
    "c_boot = []\n",
    "for _ in range(B):\n",
    "    idx = rng.integers(0, n, n)  # bootstrap avec remise\n",
    "    c_boot.append(ipcw_at_t(t_star_clamped, idx))\n",
    "c_boot = np.sort(np.array(c_boot))\n",
    "lo, hi = c_boot[int(0.025*B)], c_boot[int(0.975*B)]\n",
    "print(f\"IPCW-C at t*={t_star_clamped:.3f}y: {ipcw_at_t(t_star_clamped):.4f} \"\n",
    "      f\"[95% CI {lo:.4f}, {hi:.4f}]\")"
   ],
   "id": "340e294461711e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPCW-C at t=0.727y: 0.6591\n",
      "IPCW-C at t=1.395y: 0.6585\n",
      "IPCW-C at t=2.749y: 0.6614\n",
      "IPCW-C at t=4.328y: 0.6664\n",
      "IPCW-C at t*=2.274y: 0.6582 [95% CI 0.5414, 0.7509]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T21:27:14.677414Z",
     "start_time": "2025-09-09T21:27:14.634640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ======================================================\n",
    "# Retrain Cox-Time on FULL df, then predict on df_new\n",
    "# Output: DataFrame with columns [\"ID\", \"Risk\"]\n",
    "# ======================================================\n",
    "\n",
    "# Config for this step\n",
    "ID_COL = \"ID\"\n",
    "HORIZON_QUANTILE = 0.7  # choose t* from event-time quantile on full data\n",
    "\n",
    "# Ensure these names match what you used earlier\n",
    "target_time = \"OS_YEARS\"\n",
    "target_event = \"OS_STATUS\"\n",
    "\n",
    "# 1) Build feature set from FULL df\n",
    "feature_cols_full = [c for c in df.columns if c not in [target_time, target_event]]\n",
    "X_full = df[feature_cols_full].copy()\n",
    "t_full = df[target_time].to_numpy(dtype=np.float32)\n",
    "e_full = df[target_event].to_numpy(dtype=np.int64)\n",
    "\n",
    "# 2) Preprocess on FULL df (float32)\n",
    "num_cols_full = [c for c in X_full.columns if pd.api.types.is_numeric_dtype(X_full[c])]\n",
    "cat_cols_full = [c for c in X_full.columns if c not in num_cols_full]\n",
    "try:\n",
    "    ohe_full = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, dtype=np.float32)\n",
    "except TypeError:\n",
    "    ohe_full = OneHotEncoder(handle_unknown=\"ignore\", sparse=False, dtype=np.float32)\n",
    "\n",
    "pre_full = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), num_cols_full),\n",
    "    (\"cat\", ohe_full, cat_cols_full),\n",
    "], remainder=\"drop\")\n",
    "\n",
    "pre_full.fit(X_full)\n",
    "Xfull = pre_full.transform(X_full).astype(np.float32)"
   ],
   "id": "eca5ef0e2d6153b7",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T21:27:27.094617Z",
     "start_time": "2025-09-09T21:27:17.971508Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3) Cox-Time with MLPVanillaCoxTime on FULL data\n",
    "net_full = MLPVanillaCoxTime(\n",
    "    in_features=Xfull.shape[1],\n",
    "    num_nodes=[256, 128],\n",
    "    batch_norm=True,\n",
    "    dropout=0.05,\n",
    ")\n",
    "optimizer_full = tt.optim.Adam(lr=3e-4, weight_decay=1e-4)\n",
    "model_full = CoxTime(net_full, optimizer_full, device=\"cpu\")\n",
    "\n",
    "labtrans_full = CoxTime.label_transform()\n",
    "y_full = labtrans_full.fit_transform(t_full, e_full)\n",
    "\n",
    "_ = model_full.fit(Xfull, y_full, batch_size=256, epochs=120, callbacks=None, verbose=False)\n",
    "\n",
    "# Baseline hazards are required before predict_surv_df\n",
    "try:\n",
    "    model_full.compute_baseline_hazards()\n",
    "except TypeError:\n",
    "    model_full.compute_baseline_hazards(Xfull, y_full)"
   ],
   "id": "8c9bea602fba563e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Concordance\\PycharmProjects\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\torchtuples\\tupletree.py:597: UserWarning: Using a non-tuple sequence for multidimensional indexing is deprecated and will be changed in pytorch 2.9; use x[tuple(seq)] instead of x[seq]. In pytorch 2.9 this will be interpreted as tensor index, x[torch.tensor(seq)], which will result either in an error or a different result (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\autograd\\python_variable_indexing.cpp:312.)\n",
      "  return self.tuple_.apply(lambda x: x[index])\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T21:27:54.558700Z",
     "start_time": "2025-09-09T21:27:46.459924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 4) Define horizon t* from FULL event times and clamp by tau from censoring KM\n",
    "surv_full_pred = model_full.predict_surv_df(Xfull)  # just to grab the time grid\n",
    "time_grid_full = surv_full_pred.index.values.astype(float)\n",
    "\n",
    "event_times_full = t_full[e_full.astype(bool) == 1]\n",
    "if event_times_full.size == 0:\n",
    "    raise ValueError(\"No events in full data. Cannot define evaluation horizon t*.\")\n",
    "\n",
    "t_star_raw_full = float(np.quantile(event_times_full, HORIZON_QUANTILE))\n",
    "\n",
    "# Tau from censoring KM on FULL data\n",
    "t_km_full, Ghat_full = kaplan_meier_estimator(~e_full.astype(bool), t_full.astype(float)\n",
    ")\n",
    "if np.any(Ghat_full > 0):\n",
    "    tau_max_full = t_km_full[Ghat_full > 0][-1]\n",
    "    tau_safe_full = float(np.nextafter(tau_max_full, 0.0))\n",
    "else:\n",
    "    tau_safe_full = float(t_full.max())\n",
    "\n",
    "def nearest_time(t, grid):\n",
    "    g = np.asarray(grid, dtype=float)\n",
    "    return float(g[np.argmin(np.abs(g - float(t)))])\n",
    "\n",
    "t_star_full = nearest_time(min(t_star_raw_full, tau_safe_full), time_grid_full)\n",
    "\n"
   ],
   "id": "528c437e8f93cb8",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-09T21:28:16.130221Z",
     "start_time": "2025-09-09T21:28:12.673456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 5) Load or reference df_new with ID and the SAME feature columns\n",
    "df_new = pd.read_csv(\"../data/df_eval_scaled.csv\")  # uncomment and set your path\n",
    "assert ID_COL in df_new.columns, f\"Missing ID column '{ID_COL}' in df_new.\"\n",
    "\n",
    "missing_cols = [c for c in feature_cols_full if c not in df_new.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"df_new is missing required feature columns: {missing_cols}\")\n",
    "\n",
    "X_new = df_new[feature_cols_full].copy()\n",
    "Xnew = pre_full.transform(X_new).astype(np.float32)\n",
    "\n",
    "# 6) Predict survival on df_new and compute Risk = 1 - S(t*)\n",
    "surv_new = model_full.predict_surv_df(Xnew)\n",
    "grid_new = surv_new.index.values.astype(float)\n",
    "use_t = nearest_time(min(t_star_full, tau_safe_full), grid_new)\n",
    "\n",
    "risk_new = 1.0 - surv_new.loc[use_t].to_numpy()\n",
    "\n",
    "# 7) Final DataFrame with exactly two columns: ID and Risk\n",
    "scores = pd.DataFrame({ID_COL: df_new[ID_COL].values, \"risk_score\": risk_new})\n",
    "print(scores.head())\n",
    "scores.to_csv(\"risk_scores.csv\", index=False)"
   ],
   "id": "ed32bcec7e536e22",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID  risk_score\n",
      "0  KYW1    1.000000\n",
      "1  KYW2    1.000000\n",
      "2  KYW3    0.131294\n",
      "3  KYW4    1.000000\n",
      "4  KYW5    1.000000\n"
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
