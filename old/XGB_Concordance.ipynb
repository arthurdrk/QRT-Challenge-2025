{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a16eefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_enhanced = pd.read_csv('../data/train_pivot4.csv', sep=',')\n",
    "eval_enhanced  = pd.read_csv('../data/eval_pivot4.csv',  sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef56a405",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "\n",
    "time_col  = \"OS_YEARS\"\n",
    "event_col = \"OS_STATUS\"\n",
    "exclude_cols = {time_col, event_col, \"ID\"}\n",
    "feature_cols = [c for c in train_enhanced.columns if c not in exclude_cols]\n",
    "\n",
    "X_df = train_enhanced[feature_cols].astype(float).replace([np.inf, -np.inf], np.nan)\n",
    "X = X_df.to_numpy(dtype=float)\n",
    "\n",
    "time_vals  = train_enhanced[time_col].to_numpy(dtype=float)\n",
    "event_vals = train_enhanced[event_col].to_numpy(dtype=int)  # 1=event, 0=censuré"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fa9667",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Custom metric C-index (XGBoost >= 2.x préfère custom_metric)\n",
    "def cindex_custom_metric(preds, dmatrix):\n",
    "    t = dmatrix.get_label().astype(float)\n",
    "    e = dmatrix.get_weight()\n",
    "    if e is None or len(e) == 0:\n",
    "        e = np.ones_like(t)\n",
    "    e = e.astype(bool)\n",
    "\n",
    "    c = concordance_index_censored(e, t, preds.astype(float))[0]\n",
    "    return (\"cindex\", float(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2cc44a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"survival:cox\",\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0.0, 5.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0.0, 10.0),\n",
    "        \"tree_method\": \"hist\",\n",
    "        \"seed\": 42,\n",
    "        # pas de eval_metric ici -> on utilise custom_metric\n",
    "    }\n",
    "\n",
    "    num_boost_round = trial.suggest_int(\"num_boost_round\", 50, 2000)\n",
    "    early_stopping_rounds = trial.suggest_int(\"early_stopping_rounds\", 20, 200)\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    c_indices = []\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_tr, X_va = X[train_idx], X[val_idx]\n",
    "        t_tr, t_va = time_vals[train_idx], time_vals[val_idx]\n",
    "        e_tr, e_va = event_vals[train_idx], event_vals[val_idx]\n",
    "\n",
    "        dtrain = xgb.DMatrix(X_tr, label=t_tr, weight=e_tr.astype(float))\n",
    "        dvalid = xgb.DMatrix(X_va, label=t_va, weight=e_va.astype(float))\n",
    "\n",
    "        model = xgb.train(\n",
    "            params,\n",
    "            dtrain,\n",
    "            num_boost_round=num_boost_round,\n",
    "            evals=[(dvalid, \"valid\")],\n",
    "            custom_metric=cindex_custom_metric,\n",
    "            maximize=True,\n",
    "            early_stopping_rounds=early_stopping_rounds,\n",
    "            verbose_eval=False,\n",
    "        )\n",
    "\n",
    "        pred_va = model.predict(dvalid, iteration_range=(0, model.best_iteration + 1))\n",
    "        c = concordance_index_censored(e_va.astype(bool), t_va, pred_va)[0]\n",
    "        c_indices.append(c)\n",
    "\n",
    "    return float(np.mean(c_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9698eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\", study_name=\"xgb_cindex_tuning\")\n",
    "study.optimize(objective, n_trials=1000, show_progress_bar=True)\n",
    "\n",
    "print(\"Meilleurs hyperparamètres:\")\n",
    "print(study.best_params)\n",
    "print(f\"\\nMeilleur C-index moyen: {study.best_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac1a38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = study.best_params.copy()\n",
    "best_num_boost_round = best_params.pop(\"num_boost_round\")\n",
    "best_early_stopping_rounds = best_params.pop(\"early_stopping_rounds\")\n",
    "\n",
    "best_params.update({\n",
    "    \"objective\": \"survival:cox\",\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"seed\": 42,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85283c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit final + early stopping sur un split interne\n",
    "idx = np.arange(X.shape[0])\n",
    "tr_idx, va_idx = train_test_split(idx, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "dtrain_full = xgb.DMatrix(X[tr_idx], label=time_vals[tr_idx], weight=event_vals[tr_idx].astype(float))\n",
    "dvalid_full = xgb.DMatrix(X[va_idx], label=time_vals[va_idx], weight=event_vals[va_idx].astype(float))\n",
    "\n",
    "model_tuned = xgb.train(\n",
    "    best_params,\n",
    "    dtrain_full,\n",
    "    num_boost_round=best_num_boost_round,\n",
    "    evals=[(dvalid_full, \"valid\")],\n",
    "    custom_metric=cindex_custom_metric,\n",
    "    maximize=True,\n",
    "    early_stopping_rounds=best_early_stopping_rounds,\n",
    "    verbose_eval=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462cc28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict eval\n",
    "X_eval_final = eval_enhanced[feature_cols].fillna(0.0).to_numpy(dtype=float)\n",
    "deval_final = xgb.DMatrix(X_eval_final)\n",
    "\n",
    "risk_score_tuned = model_tuned.predict(deval_final, iteration_range=(0, model_tuned.best_iteration + 1))\n",
    "\n",
    "submission_tuned = pd.DataFrame({\n",
    "    \"ID\": eval_enhanced[\"ID\"],\n",
    "    \"risk_score\": risk_score_tuned\n",
    "})\n",
    "\n",
    "submission_tuned.to_csv('../submissions/submission_xgb_cindex_tuned.csv', index=False)\n",
    "print(\"Prédictions sauvegardées dans '../submissions/submission_xgb_cindex_tuned.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adbff02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
