{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "collapsed": true,
    "id": "cJYyGsEWwBsx",
    "outputId": "484a2621-e6b3-4063-a765-2642a03b0f9c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.metrics import concordance_index_censored , concordance_index_ipcw\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sksurv.util import Surv\n",
    "from lifelines.utils import concordance_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "qnZmbXTe0WBc"
   },
   "outputs": [],
   "source": [
    "clinical_test=pd.read_csv('data/clinical_test.csv')\n",
    "clinical_train=pd.read_csv('data/clinical_train.csv')\n",
    "\n",
    "molecular_test=pd.read_csv('data/molecular_test.csv')\n",
    "molecular_train=pd.read_csv('data/molecular_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "s7wOdy5TBuqf"
   },
   "outputs": [],
   "source": [
    "target_df=pd.read_csv('data/target_train.csv')\n",
    "\n",
    "# Drop rows where 'OS_YEARS' is NaN if conversion caused any issues\n",
    "target_df.dropna(subset=['OS_YEARS', 'OS_STATUS'], inplace=True)\n",
    "\n",
    "\n",
    "# Contarget_dfvert 'OS_YEARS' to numeric if it isn’t already\n",
    "target_df['OS_YEARS'] = pd.to_numeric(target_df['OS_YEARS'], errors='coerce')\n",
    "\n",
    "# Ensure 'OS_STATUS' is boolean\n",
    "target_df['OS_STATUS'] = target_df['OS_STATUS'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "LoqKGgFMOoqI",
    "outputId": "fc073aa5-cc60-4e9d-b070-345ecc99e34f"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "def precise_missing_values(df):\n",
    "    # Imputation KNN pour les variables numériques\n",
    "    num_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    df[num_cols] = imputer.fit_transform(df[num_cols])\n",
    "\n",
    "    # Pour les variables catégorielles, on remplace par 'Missing'\n",
    "    cat_cols = df.select_dtypes(include=['object']).columns\n",
    "    for col in cat_cols:\n",
    "        df[col] = df[col].fillna('Missing')\n",
    "    return df\n",
    "\n",
    "clinical_train = precise_missing_values(clinical_train)\n",
    "clinical_test = precise_missing_values(clinical_test)\n",
    "molecular_train = precise_missing_values(molecular_train)\n",
    "molecular_test = precise_missing_values(molecular_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def aggregate_leukemia_data_improved(df, clinical_df=None):\n",
    "    \"\"\"\n",
    "    Agrégation avancée des données de mutations par patient avec intégration\n",
    "    des facteurs pronostiques ELN 2022 et des recommandations cliniques.\n",
    "    (Version sans intégration des données cliniques)\n",
    "    \"\"\"\n",
    "    # === DÉFINITIONS DES GÈNES SELON ELN 2022 ===\n",
    "    adverse_genes = {\n",
    "        'TP53', 'ASXL1', 'RUNX1', 'EZH2', 'SF3B1', 'SRSF2', 'U2AF1', \n",
    "        'ZRSR2', 'STAG2', 'BCOR', 'SETBP1'\n",
    "    }\n",
    "    dna_methylation_genes = {'DNMT3A', 'TET2', 'IDH1', 'IDH2'}\n",
    "    favorable_genes = {'NPM1', 'CEBPA'}\n",
    "    all_genes = [\n",
    "        'GNB1', 'CSF3R', 'MPL', 'NRAS', 'HAX1', 'RIT1', 'SMC3', 'WT1', 'ATM', 'CBL',\n",
    "        'ETV6', 'ETNK1', 'KRAS', 'ARID2', 'NFE2', 'SH2B3', 'PTPN11', 'FLT3', 'BRCA2',\n",
    "        'PDS5B', 'IDH2', 'BLM', 'CREBBP', 'CTCF', 'PRPF8', 'TP53', 'NF1', 'SUZ12',\n",
    "        'STAT5B', 'STAT3', 'PPM1D', 'SRSF2', 'SETBP1', 'BCL2', 'EPOR', 'CALR', 'CEBPA',\n",
    "        'U2AF2', 'DNMT3A', 'ASXL2', 'SF3B1', 'IDH1', 'ASXL1', 'GNAS', 'RUNX1', 'U2AF1',\n",
    "        'CHEK2', 'MYD88', 'GATA2', 'KIT', 'TET2', 'TERT', 'IRF1', 'CSNK1A1', 'NPM1',\n",
    "        'NSD1', 'DDX41', 'JARID2', 'CCND3', 'VEGFA', 'IKZF1', 'EGFR', 'SBDS', 'CUX1',\n",
    "        'BRAF', 'EZH2', 'RAD21', 'JAK2', 'CDKN2A', 'FANCG', 'NOTCH1', 'PIGA', 'ZRSR2',\n",
    "        'BCOR', 'USP9X', 'KDM6A', 'SMC1A', 'MED12', 'STAG2', 'BCORL1', 'PHF6', 'BRCC3',\n",
    "        'MLL'\n",
    "    ]\n",
    "    gene_weights = {\n",
    "        'TP53': 5.0,\n",
    "        'ASXL1': 2.0, 'RUNX1': 2.0, 'EZH2': 2.0,\n",
    "        'SF3B1': 1.8, 'SRSF2': 1.8, 'U2AF1': 1.8, 'ZRSR2': 1.8,\n",
    "        'STAG2': 1.5, 'BCOR': 1.5, 'SETBP1': 1.5,\n",
    "        'DNMT3A': 1.5, 'TET2': 1.5, 'IDH1': 1.8, 'IDH2': 1.8,\n",
    "        'FLT3': 2.0,\n",
    "        'NPM1': -2.5,\n",
    "        'CEBPA': -3.0,\n",
    "        'KIT': 1.2, 'NRAS': 0.8, 'KRAS': 0.8, 'PTPN11': 0.8\n",
    "    }\n",
    "    bad_effects = ['nonsense', 'frameshift', 'splice_site', 'stop_gained']\n",
    "    # === AGRÉGATION BASIQUE ===\n",
    "    result = df.groupby('ID').agg({\n",
    "        'GENE': ['count', 'nunique'],\n",
    "        'CHR': 'nunique',\n",
    "        'VAF': ['mean', 'max', 'median', 'min', 'var'],\n",
    "        'DEPTH': ['mean', 'median', 'min', 'max', 'var']\n",
    "    }).reset_index()\n",
    "    result.columns = [\n",
    "        'ID', 'nb_mutations', 'nb_genes', 'nb_chromosomes',\n",
    "        'vaf_mean', 'vaf_max', 'vaf_median', 'vaf_min', 'vaf_var',\n",
    "        'depth_mean', 'depth_median', 'depth_min', 'depth_max', 'depth_var'\n",
    "    ]\n",
    "    # === MATRICE BINAIRE GÈNE x PATIENT ===\n",
    "    has_gene = (\n",
    "        df.pivot_table(index='ID', columns='GENE', values='CHR', aggfunc='size', fill_value=0)\n",
    "        .reindex(columns=all_genes, fill_value=0)\n",
    "        .astype(int)\n",
    "    )\n",
    "    has_gene.columns = [f'has_{g}' for g in has_gene.columns]\n",
    "    has_gene.reset_index(inplace=True)\n",
    "    result = result.merge(has_gene, on='ID', how='left')\n",
    "    # === NOUVEAUX INDICATEURS GÉNÉTIQUES ===\n",
    "    adverse_cols = [f'has_{g}' for g in adverse_genes if f'has_{g}' in result.columns]\n",
    "    result['has_adverse_gene'] = result[adverse_cols].sum(axis=1).clip(upper=1)\n",
    "    result['nb_adverse_genes'] = result[adverse_cols].sum(axis=1)\n",
    "    methylation_cols = [f'has_{g}' for g in dna_methylation_genes if f'has_{g}' in result.columns]\n",
    "    result['has_methylation_gene'] = result[methylation_cols].sum(axis=1).clip(upper=1)\n",
    "    result['nb_methylation_genes'] = result[methylation_cols].sum(axis=1)\n",
    "    result['has_NPM1_favorable'] = result.get('has_NPM1', 0)\n",
    "    result['has_CEBPA_favorable'] = result.get('has_CEBPA', 0)\n",
    "    result['high_mutation_burden'] = (result['nb_mutations'] > 3).astype(int)\n",
    "    result['mutation_burden_score'] = np.where(\n",
    "        result['nb_mutations'] > 3, \n",
    "        (result['nb_mutations'] - 3) * 0.5, \n",
    "        0\n",
    "    )\n",
    "    result['nb_bad_effects'] = df.groupby('ID')['EFFECT'].apply(lambda x: x.isin(bad_effects).sum()).values\n",
    "    result['nb_high_vaf'] = df.groupby('ID')['VAF'].apply(lambda x: (x > 0.4).sum()).values\n",
    "    result['nb_very_high_vaf'] = df.groupby('ID')['VAF'].apply(lambda x: (x > 0.6).sum()).values\n",
    "    # === CALCUL DU SCORE DE RISQUE AMÉLIORÉ (SANS CLINIQUE) ===\n",
    "    has_cols = [f'has_{g}' for g in gene_weights if f'has_{g}' in result.columns]\n",
    "    weights_series = pd.Series([gene_weights[g] for g in gene_weights if f'has_{g}' in result.columns], \n",
    "                              index=has_cols)\n",
    "    gene_score = result[has_cols].dot(weights_series)\n",
    "    methylation_penalty = np.where(result['nb_methylation_genes'] >= 2, \n",
    "                                  result['nb_methylation_genes'] * 0.8, 0)\n",
    "    npm1_modulation = 0\n",
    "    if 'has_NPM1' in result.columns and 'has_FLT3' in result.columns:\n",
    "        npm1_modulation = np.where(\n",
    "            (result['has_NPM1'] == 1) & (result['has_FLT3'] == 1),\n",
    "            1.5,\n",
    "            0\n",
    "        )\n",
    "    result['risk_score_genetic'] = (\n",
    "        gene_score +\n",
    "        methylation_penalty +\n",
    "        npm1_modulation +\n",
    "        result['mutation_burden_score'] +\n",
    "        0.3 * result['nb_high_vaf'] +\n",
    "        0.5 * result['nb_very_high_vaf']\n",
    "    )\n",
    "    result['risk_score_raw'] = result['risk_score_genetic']\n",
    "    def enhanced_logistic(score, intercept=3.0, scale=2.5, floor=0.05, ceiling=0.95):\n",
    "        z = (score - intercept) / scale\n",
    "        prob = 1.0 / (1.0 + np.exp(-z))\n",
    "        return np.clip(prob, floor, ceiling)\n",
    "    result['risk_score_prob'] = result['risk_score_raw'].apply(enhanced_logistic)\n",
    "    def classify_eln_risk(row):\n",
    "        if ((row.get('has_NPM1', 0) == 1 and row.get('has_FLT3', 0) == 0) or\n",
    "            row.get('has_CEBPA', 0) == 1):\n",
    "            if row['has_adverse_gene'] == 0:\n",
    "                return 'Favorable'\n",
    "        if (row['has_adverse_gene'] == 1 or \n",
    "            row.get('has_TP53', 0) == 1 or\n",
    "            row['nb_adverse_genes'] >= 2):\n",
    "            return 'Adverse'\n",
    "        return 'Intermediate'\n",
    "    result['eln_risk_category'] = result.apply(classify_eln_risk, axis=1)\n",
    "    result['genetic_complexity'] = (\n",
    "        result['nb_genes'] + \n",
    "        result['nb_adverse_genes'] * 2 + \n",
    "        result['nb_methylation_genes']\n",
    "    )\n",
    "    result['vaf_heterogeneity'] = result['vaf_var'].fillna(0)\n",
    "    return result\n",
    "\n",
    "def aggregation(molecular_train, molecular_test, clinical_train=None, clinical_test=None):\n",
    "    molecular_train_agg = aggregate_leukemia_data_improved(molecular_train, clinical_train)\n",
    "    molecular_test_agg = aggregate_leukemia_data_improved(molecular_test, clinical_test)\n",
    "    return molecular_train_agg, molecular_test_agg\n",
    "\n",
    "# Exemple d'utilisation :\n",
    "molecular_train_agg, molecular_test_agg = aggregation(molecular_train, molecular_test, clinical_train, clinical_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "qTN7kbb01RpM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arthr\\Desktop\\ENSAE 1A\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "c:\\Users\\arthr\\Desktop\\ENSAE 1A\\QRT-Challenge-2025\\.venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "def extract_cytogenetic_features(data):\n",
    "    \"\"\"Extrait les anomalies chromosomiques fréquentes\"\"\"\n",
    "    abnormalities = {\n",
    "        \"monosomy_7\": r\"[-]7|\\bdel\\(7\",\n",
    "        \"monosomy_5\": r\"[-]5|\\bdel\\(5\",\n",
    "        \"del_20q\": r\"del\\(20\\)\\(q\",\n",
    "        \"inv_16\": r\"inv\\(16\\)\",\n",
    "        \"t_8_21\": r\"t\\(8;21\\)\",\n",
    "        \"t_15_17\": r\"t\\(15;17\\)\",\n",
    "        \"t_3_3\": r\"t\\(3;3\",\n",
    "        \"del_3_q26\": r\"del\\(3\\)\\(q26\",\n",
    "        \"t_3_9\": r\"t\\(3;9\\)\",\n",
    "        \"trisomy_8\": r\"\\+8\"\n",
    "    }\n",
    "\n",
    "    for name, regex in abnormalities.items():\n",
    "        data[name] = data[\"CYTOGENETICS\"].str.contains(regex, case=False, na=False).astype(int)\n",
    "\n",
    "    # Complex karyotype = 3 anomalies ou plus\n",
    "    def is_complex(k):\n",
    "        if pd.isna(k):\n",
    "            return 0\n",
    "        # Compter les délétions, translocations, inversions, etc.\n",
    "        anomalies = re.findall(r\"del\\(|t\\(|inv\\(|ins\\(|\\+\\d+|-\\d+\", str(k))\n",
    "        return int(len(anomalies) >= 3)\n",
    "    \n",
    "    data[\"complex_karyotype\"] = data[\"CYTOGENETICS\"].apply(is_complex)\n",
    "    return data\n",
    "\n",
    "def assign_eln_risk(row):\n",
    "    \"\"\"Classification ELN 2022 des risques pronostiques\"\"\"\n",
    "    # Risque favorable\n",
    "    if row[\"t_8_21\"] == 1 or row[\"inv_16\"] == 1 or row[\"t_15_17\"] == 1:\n",
    "        return \"favorable\"\n",
    "    # Risque défavorable\n",
    "    elif (row[\"monosomy_7\"] == 1 or row[\"monosomy_5\"] == 1 or \n",
    "          row[\"complex_karyotype\"] == 1 or row[\"t_3_3\"] == 1 or row[\"del_3_q26\"] == 1):\n",
    "        return \"adverse\"\n",
    "    # Risque intermédiaire\n",
    "    else:\n",
    "        return \"intermediate\"\n",
    "\n",
    "def extract_structural_numerical_anomalies(data):\n",
    "    \"\"\"Extrait les anomalies structurelles vs numériques\"\"\"\n",
    "    def count_structural(k):\n",
    "        if pd.isna(k):\n",
    "            return 0\n",
    "        # Anomalies structurelles : délétions, translocations, inversions, insertions\n",
    "        structural = re.findall(r\"del\\(|t\\(|inv\\(|ins\\(\", str(k))\n",
    "        return len(structural)\n",
    "    \n",
    "    def count_numerical(k):\n",
    "        if pd.isna(k):\n",
    "            return 0\n",
    "        # Anomalies numériques : gains (+) et pertes (-) de chromosomes entiers\n",
    "        numerical = re.findall(r\"\\+\\d+|-\\d+\", str(k))\n",
    "        return len(numerical)\n",
    "    \n",
    "    data[\"structural_anomalies_count\"] = data[\"CYTOGENETICS\"].apply(count_structural)\n",
    "    data[\"numerical_anomalies_count\"] = data[\"CYTOGENETICS\"].apply(count_numerical)\n",
    "    return data\n",
    "\n",
    "def extract_chromosome_details(data):\n",
    "    \"\"\"Extrait les détails des chromosomes impliqués\"\"\"\n",
    "    def get_involved_chromosomes(k):\n",
    "        if pd.isna(k):\n",
    "            return []\n",
    "        # Extraire tous les numéros de chromosomes mentionnés\n",
    "        chromosomes = re.findall(r\"(?:del\\(|t\\(|inv\\(|ins\\()(\\d+)\", str(k))\n",
    "        chromosomes += re.findall(r\"[+-](\\d+)\", str(k))\n",
    "        return list(set(chromosomes))  # Supprimer les doublons\n",
    "    \n",
    "    data[\"involved_chromosomes\"] = data[\"CYTOGENETICS\"].apply(get_involved_chromosomes)\n",
    "    data[\"num_involved_chromosomes\"] = data[\"involved_chromosomes\"].apply(len)\n",
    "    \n",
    "    # Créer des colonnes binaires pour les chromosomes les plus fréquemment impliqués\n",
    "    common_chromosomes = ['3', '5', '7', '8', '9', '11', '15', '16', '17', '20', '21', '22']\n",
    "    for chr_num in common_chromosomes:\n",
    "        data[f\"chr_{chr_num}_involved\"] = data[\"involved_chromosomes\"].apply(\n",
    "            lambda x: 1 if chr_num in x else 0\n",
    "        )\n",
    "    \n",
    "    return data\n",
    "\n",
    "def create_cytogenetic_embeddings(data, max_features=100):\n",
    "    \"\"\"Crée des embeddings TF-IDF sur les chaînes CYTOGENETICS\"\"\"\n",
    "    # Préparation des données pour TF-IDF\n",
    "    cyto_texts = data[\"CYTOGENETICS\"].fillna(\"normal\").astype(str)\n",
    "    \n",
    "    # Tokenization spéciale pour les données cytogénétiques\n",
    "    def cyto_tokenizer(text):\n",
    "        # Extraire les éléments cytogénétiques comme tokens\n",
    "        tokens = []\n",
    "        tokens.extend(re.findall(r\"del\\(\\d+\\)\\([pq]\\d*\\)\", text))  # délétions\n",
    "        tokens.extend(re.findall(r\"t\\(\\d+;\\d+\\)\", text))  # translocations\n",
    "        tokens.extend(re.findall(r\"inv\\(\\d+\\)\", text))  # inversions\n",
    "        tokens.extend(re.findall(r\"[+-]\\d+\", text))  # gains/pertes\n",
    "        tokens.extend(re.findall(r\"\\d+,XX|\\d+,XY\", text))  # formules de base\n",
    "        return tokens\n",
    "    \n",
    "    # Créer le vectoriseur TF-IDF\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        tokenizer=cyto_tokenizer,\n",
    "        max_features=max_features,\n",
    "        lowercase=False\n",
    "    )\n",
    "    \n",
    "    # Ajuster et transformer\n",
    "    tfidf_matrix = vectorizer.fit_transform(cyto_texts)\n",
    "    \n",
    "    # Convertir en DataFrame\n",
    "    feature_names = [f\"tfidf_{i}\" for i in range(tfidf_matrix.shape[1])]\n",
    "    tfidf_df = pd.DataFrame(\n",
    "        tfidf_matrix.toarray(), \n",
    "        columns=feature_names, \n",
    "        index=data.index\n",
    "    )\n",
    "    \n",
    "    # Joindre au DataFrame principal\n",
    "    data = pd.concat([data, tfidf_df], axis=1)\n",
    "    return data\n",
    "\n",
    "def preprocess(data, include_embeddings=True):\n",
    "    \"\"\"\n",
    "    Fonction de preprocessing complète pour les données cytogénétiques\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pd.DataFrame\n",
    "        DataFrame contenant la colonne CYTOGENETICS\n",
    "    include_embeddings : bool\n",
    "        Si True, inclut les embeddings TF-IDF (peut être coûteux en mémoire)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame enrichi avec toutes les features cytogénétiques\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Normalisation de la casse des chromosomes (tout en majuscule)\n",
    "    data[\"CYTOGENETICS\"] = data[\"CYTOGENETICS\"].str.upper()\n",
    "    \n",
    "    # 2. Indicateur si le caryotype est anormal (inversé par rapport à l'original)\n",
    "    data[\"is_abnormal\"] = (~data[\"CYTOGENETICS\"].str.contains(\"46,XX|46,XY\", case=False, na=False)).astype(int)\n",
    "    # Garder aussi l'indicateur normal pour compatibilité\n",
    "    data[\"is_normal\"] = 1 - data[\"is_abnormal\"]\n",
    "    \n",
    "    # 3. Extraction du nombre total de chromosomes\n",
    "    data[\"total_chromosomes\"] = data[\"CYTOGENETICS\"].str.extract(r\"^(\\d+)\", expand=False).astype(float)\n",
    "    # Remplir avec 46 si non détecté et caryotype normal\n",
    "    data.loc[~data[\"total_chromosomes\"].notna(), \"total_chromosomes\"] = 46\n",
    "    \n",
    "    # 4. Extraction du sexe brut (ex: XY, XX)\n",
    "    data[\"sex_raw\"] = data[\"CYTOGENETICS\"].str.extract(r\"\\b(XX|XY|XYY|XXY|XXX|YY)\\b\", expand=False)\n",
    "    \n",
    "    # 5. Normalisation du sexe : catégorisation des cas atypiques\n",
    "    data[\"sex\"] = data[\"sex_raw\"].apply(lambda s: s if s in [\"XX\", \"XY\"] else \"Other\")\n",
    "    \n",
    "    # 6. Extraction des anomalies chromosomiques fréquentes\n",
    "    data = extract_cytogenetic_features(data)\n",
    "    \n",
    "    # 7. Classification ELN des risques\n",
    "    data[\"eln_risk\"] = data.apply(assign_eln_risk, axis=1)\n",
    "    \n",
    "    # 8. Encodage ordinal du risque ELN\n",
    "    eln_risk_mapping = {\"favorable\": 0, \"intermediate\": 1, \"adverse\": 2}\n",
    "    data[\"eln_risk_ordinal\"] = data[\"eln_risk\"].map(eln_risk_mapping)\n",
    "    \n",
    "    # 9. Nombre de clones\n",
    "    data[\"number_of_clones\"] = data[\"CYTOGENETICS\"].str.findall(r\"\\[(\\d+)\\]\").apply(\n",
    "        lambda x: sum(map(int, x)) if x else 0\n",
    "    )\n",
    "    \n",
    "    # 10. Anomalies structurelles vs numériques\n",
    "    data = extract_structural_numerical_anomalies(data)\n",
    "    \n",
    "    # 11. Détails des chromosomes impliqués\n",
    "    data = extract_chromosome_details(data)\n",
    "    \n",
    "    # 12. Ratio anomalies structurelles/numériques\n",
    "    data[\"structural_numerical_ratio\"] = data[\"structural_anomalies_count\"] / (\n",
    "        data[\"numerical_anomalies_count\"] + 1\n",
    "    )  # +1 pour éviter division par zéro\n",
    "    \n",
    "    # 13. Score de complexité globale\n",
    "    data[\"complexity_score\"] = (\n",
    "        data[\"structural_anomalies_count\"] + \n",
    "        data[\"numerical_anomalies_count\"] + \n",
    "        data[\"num_involved_chromosomes\"]\n",
    "    )\n",
    "    \n",
    "    # 14. Embeddings TF-IDF (optionnel)\n",
    "    if include_embeddings:\n",
    "        data = create_cytogenetic_embeddings(data)\n",
    "    \n",
    "    # 15. Nettoyage des colonnes intermédiaires\n",
    "    columns_to_drop = [\"sex_raw\", \"involved_chromosomes\"]\n",
    "    data.drop(columns=[col for col in columns_to_drop if col in data.columns], inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Exemple d'utilisation avec gestion des erreurs\n",
    "def preprocess_safe(data, include_embeddings=True):\n",
    "    \"\"\"Version sécurisée du preprocessing avec gestion des erreurs\"\"\"\n",
    "    try:\n",
    "        return preprocess(data.copy(), include_embeddings=include_embeddings)\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du preprocessing: {e}\")\n",
    "        print(\"Retour de la version de base...\")\n",
    "        return preprocess_basic(data.copy())\n",
    "\n",
    "def preprocess_basic(data):\n",
    "    \"\"\"Version de base du preprocessing en cas d'erreur\"\"\"\n",
    "    data[\"CYTOGENETICS\"] = data[\"CYTOGENETICS\"].str.upper()\n",
    "    data[\"is_abnormal\"] = (~data[\"CYTOGENETICS\"].str.contains(\"46,XX|46,XY\", case=False, na=False)).astype(int)\n",
    "    data[\"total_chromosomes\"] = data[\"CYTOGENETICS\"].str.extract(r\"^(\\d+)\", expand=False).astype(float)\n",
    "    data.loc[~data[\"total_chromosomes\"].notna(), \"total_chromosomes\"] = 46\n",
    "    return data\n",
    "\n",
    "# Appliquer la fonction aux datasets\n",
    "clinical_test = preprocess(clinical_test)\n",
    "clinical_train = preprocess(clinical_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "id": "zwcMsT1Waem9"
   },
   "outputs": [],
   "source": [
    "clinical_test = clinical_test.drop('CYTOGENETICS', axis=1)\n",
    "clinical_train = clinical_train.drop('CYTOGENETICS', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = clinical_train.merge(molecular_train_agg, on='ID', how='left').fillna(0)\n",
    "df_test = clinical_test.merge(molecular_test_agg, on='ID', how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['mutation_burden'] = df_train['nb_mutations'] * df_train['vaf_mean']\n",
    "df_test['mutation_burden'] = df_test['nb_mutations'] * df_test['vaf_mean']\n",
    "\n",
    "\n",
    "for col in ['HB', 'PLT', 'BM_BLAST']:\n",
    "    lower = df_train[col].quantile(0.01)\n",
    "    upper = df_train[col].quantile(0.99)\n",
    "    df_train[col] = df_train[col].clip(lower, upper)\n",
    "    df_test[col] = df_test[col].clip(lower, upper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Colonnes numériques hors cibles, présentes dans le train\n",
    "features = [col for col in df_train.select_dtypes(include='number').columns if col not in ['OS_YEARS', 'OS_STATUS']]\n",
    "\n",
    "# Ajoute les colonnes manquantes dans df_test\n",
    "for col in features:\n",
    "    if col not in df_test.columns:\n",
    "        df_test[col] = 0\n",
    "\n",
    "# Aligne l'ordre des colonnes\n",
    "df_test = df_test.reindex(columns=df_train.columns)\n",
    "\n",
    "scaler = RobustScaler()\n",
    "df_train_scaled = df_train.copy()\n",
    "df_test_scaled = df_test.copy()\n",
    "\n",
    "df_train_scaled[features] = scaler.fit_transform(df_train[features])\n",
    "df_test_scaled[features] = scaler.transform(df_test[features][features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_scaled = df_train_scaled.merge(target_df, on='ID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "b6EjsUgMNTCe"
   },
   "outputs": [],
   "source": [
    "# prompt: supprime les variables ID et CENTER de df_train et de df_test\n",
    "ID_test = df_test_scaled['ID']\n",
    "\n",
    "df_train_scaled = df_train_scaled.drop(['ID', 'CENTER'], axis=1)\n",
    "df_test_scaled = df_test_scaled.drop(['CENTER'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BM_BLAST</th>\n",
       "      <th>WBC</th>\n",
       "      <th>ANC</th>\n",
       "      <th>MONOCYTES</th>\n",
       "      <th>HB</th>\n",
       "      <th>PLT</th>\n",
       "      <th>is_abnormal</th>\n",
       "      <th>is_normal</th>\n",
       "      <th>total_chromosomes</th>\n",
       "      <th>sex</th>\n",
       "      <th>...</th>\n",
       "      <th>nb_very_high_vaf</th>\n",
       "      <th>risk_score_genetic</th>\n",
       "      <th>risk_score_raw</th>\n",
       "      <th>risk_score_prob</th>\n",
       "      <th>eln_risk_category</th>\n",
       "      <th>genetic_complexity</th>\n",
       "      <th>vaf_heterogeneity</th>\n",
       "      <th>mutation_burden</th>\n",
       "      <th>OS_YEARS</th>\n",
       "      <th>OS_STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.567164</td>\n",
       "      <td>-0.393048</td>\n",
       "      <td>-0.692308</td>\n",
       "      <td>0.498039</td>\n",
       "      <td>-0.88</td>\n",
       "      <td>-0.056962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>XY</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.854015</td>\n",
       "      <td>1.854015</td>\n",
       "      <td>0.496949</td>\n",
       "      <td>Adverse</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.331931</td>\n",
       "      <td>1.305079</td>\n",
       "      <td>1.115068</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.373134</td>\n",
       "      <td>0.836898</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>-0.482353</td>\n",
       "      <td>0.72</td>\n",
       "      <td>-0.544304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>XX</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.145985</td>\n",
       "      <td>-0.145985</td>\n",
       "      <td>-0.174463</td>\n",
       "      <td>Adverse</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-0.260711</td>\n",
       "      <td>-0.001265</td>\n",
       "      <td>4.928767</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.716418</td>\n",
       "      <td>-0.152406</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>-0.482353</td>\n",
       "      <td>1.76</td>\n",
       "      <td>-0.297468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>XY</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.175182</td>\n",
       "      <td>-0.175182</td>\n",
       "      <td>-0.211470</td>\n",
       "      <td>Adverse</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-0.261176</td>\n",
       "      <td>-0.634376</td>\n",
       "      <td>2.043836</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.373134</td>\n",
       "      <td>-0.098930</td>\n",
       "      <td>-0.038462</td>\n",
       "      <td>-0.482353</td>\n",
       "      <td>-0.36</td>\n",
       "      <td>-0.322785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>XY</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.620438</td>\n",
       "      <td>1.620438</td>\n",
       "      <td>0.496949</td>\n",
       "      <td>Adverse</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.242486</td>\n",
       "      <td>1.338785</td>\n",
       "      <td>2.476712</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.373134</td>\n",
       "      <td>33.082888</td>\n",
       "      <td>2.961538</td>\n",
       "      <td>0.824837</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.424051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>XX</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.394161</td>\n",
       "      <td>-0.394161</td>\n",
       "      <td>-0.495984</td>\n",
       "      <td>Adverse</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.262710</td>\n",
       "      <td>-0.314386</td>\n",
       "      <td>3.145205</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3168</th>\n",
       "      <td>-0.373134</td>\n",
       "      <td>-0.473262</td>\n",
       "      <td>-0.376923</td>\n",
       "      <td>-0.318954</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.316456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>XY</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.569343</td>\n",
       "      <td>0.569343</td>\n",
       "      <td>0.427624</td>\n",
       "      <td>Adverse</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.072479</td>\n",
       "      <td>-0.130128</td>\n",
       "      <td>0.547945</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3169</th>\n",
       "      <td>-0.298507</td>\n",
       "      <td>1.024064</td>\n",
       "      <td>0.253846</td>\n",
       "      <td>0.089542</td>\n",
       "      <td>0.60</td>\n",
       "      <td>-0.556962</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>XX</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.116788</td>\n",
       "      <td>0.116788</td>\n",
       "      <td>0.122341</td>\n",
       "      <td>Adverse</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>8.083546</td>\n",
       "      <td>0.031628</td>\n",
       "      <td>2.339726</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3170</th>\n",
       "      <td>-0.522388</td>\n",
       "      <td>-0.660428</td>\n",
       "      <td>-0.557692</td>\n",
       "      <td>-0.171895</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.265823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>XY</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014599</td>\n",
       "      <td>0.014599</td>\n",
       "      <td>0.016227</td>\n",
       "      <td>Adverse</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.467528</td>\n",
       "      <td>0.585487</td>\n",
       "      <td>1.997260</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3171</th>\n",
       "      <td>0.223881</td>\n",
       "      <td>-0.775401</td>\n",
       "      <td>-0.626923</td>\n",
       "      <td>-0.466013</td>\n",
       "      <td>0.64</td>\n",
       "      <td>-0.164557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>XX</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.487010</td>\n",
       "      <td>Adverse</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.067959</td>\n",
       "      <td>-0.075005</td>\n",
       "      <td>0.095890</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3172</th>\n",
       "      <td>-0.522388</td>\n",
       "      <td>-0.419786</td>\n",
       "      <td>-0.492308</td>\n",
       "      <td>-0.269935</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.702532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>XY</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.963504</td>\n",
       "      <td>0.496949</td>\n",
       "      <td>Adverse</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.279019</td>\n",
       "      <td>0.502530</td>\n",
       "      <td>2.290411</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3173 rows × 252 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      BM_BLAST        WBC       ANC  MONOCYTES    HB       PLT  is_abnormal  \\\n",
       "0     1.567164  -0.393048 -0.692308   0.498039 -0.88 -0.056962          0.0   \n",
       "1    -0.373134   0.836898  0.153846  -0.482353  0.72 -0.544304          0.0   \n",
       "2     1.716418  -0.152406  0.038462  -0.482353  1.76 -0.297468          0.0   \n",
       "3    -0.373134  -0.098930 -0.038462  -0.482353 -0.36 -0.322785          0.0   \n",
       "4     0.373134  33.082888  2.961538   0.824837  0.52  0.424051          0.0   \n",
       "...        ...        ...       ...        ...   ...       ...          ...   \n",
       "3168 -0.373134  -0.473262 -0.376923  -0.318954  0.16 -0.316456          0.0   \n",
       "3169 -0.298507   1.024064  0.253846   0.089542  0.60 -0.556962          1.0   \n",
       "3170 -0.522388  -0.660428 -0.557692  -0.171895 -0.16 -0.265823          0.0   \n",
       "3171  0.223881  -0.775401 -0.626923  -0.466013  0.64 -0.164557          0.0   \n",
       "3172 -0.522388  -0.419786 -0.492308  -0.269935 -0.64  0.702532          0.0   \n",
       "\n",
       "      is_normal  total_chromosomes sex  ...  nb_very_high_vaf  \\\n",
       "0           0.0                0.0  XY  ...               0.0   \n",
       "1           0.0                0.0  XX  ...               0.0   \n",
       "2           0.0                0.0  XY  ...               0.0   \n",
       "3           0.0                0.0  XY  ...               0.0   \n",
       "4           0.0                0.0  XX  ...               0.0   \n",
       "...         ...                ...  ..  ...               ...   \n",
       "3168        0.0                1.0  XY  ...               0.0   \n",
       "3169       -1.0               -2.0  XX  ...               1.0   \n",
       "3170        0.0                0.0  XY  ...               0.0   \n",
       "3171        0.0                0.0  XX  ...               0.0   \n",
       "3172        0.0                0.0  XY  ...               0.0   \n",
       "\n",
       "      risk_score_genetic  risk_score_raw  risk_score_prob  eln_risk_category  \\\n",
       "0               1.854015        1.854015         0.496949            Adverse   \n",
       "1              -0.145985       -0.145985        -0.174463            Adverse   \n",
       "2              -0.175182       -0.175182        -0.211470            Adverse   \n",
       "3               1.620438        1.620438         0.496949            Adverse   \n",
       "4              -0.394161       -0.394161        -0.495984            Adverse   \n",
       "...                  ...             ...              ...                ...   \n",
       "3168            0.569343        0.569343         0.427624            Adverse   \n",
       "3169            0.116788        0.116788         0.122341            Adverse   \n",
       "3170            0.014599        0.014599         0.016227            Adverse   \n",
       "3171            0.744526        0.744526         0.487010            Adverse   \n",
       "3172            0.963504        0.963504         0.496949            Adverse   \n",
       "\n",
       "      genetic_complexity  vaf_heterogeneity  mutation_burden  OS_YEARS  \\\n",
       "0               1.666667           0.331931         1.305079  1.115068   \n",
       "1               0.166667          -0.260711        -0.001265  4.928767   \n",
       "2               0.166667          -0.261176        -0.634376  2.043836   \n",
       "3               2.500000           0.242486         1.338785  2.476712   \n",
       "4              -0.500000          -0.262710        -0.314386  3.145205   \n",
       "...                  ...                ...              ...       ...   \n",
       "3168            0.666667           1.072479        -0.130128  0.547945   \n",
       "3169           -0.333333           8.083546         0.031628  2.339726   \n",
       "3170            0.500000           0.467528         0.585487  1.997260   \n",
       "3171            0.166667           0.067959        -0.075005  0.095890   \n",
       "3172            1.000000           0.279019         0.502530  2.290411   \n",
       "\n",
       "      OS_STATUS  \n",
       "0          True  \n",
       "1         False  \n",
       "2         False  \n",
       "3          True  \n",
       "4         False  \n",
       "...         ...  \n",
       "3168      False  \n",
       "3169      False  \n",
       "3170      False  \n",
       "3171       True  \n",
       "3172      False  \n",
       "\n",
       "[3173 rows x 252 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_scaled.to_csv('data/df_train_scaled.csv', index=False)\n",
    "df_test_scaled.to_csv('data/df_eval_scaled.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
