{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f8bc55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sksurv.metrics import concordance_index_censored , concordance_index_ipcw\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sksurv.util import Surv\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "\n",
    "# For preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import torch # For building the networks \n",
    "import torchtuples as tt # Some useful functions\n",
    "\n",
    "from pycox.datasets import metabric\n",
    "from pycox.models import DeepHitSingle\n",
    "from pycox.evaluation import EvalSurv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28d75086",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "_ = torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfae6c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_scaled = pd.read_csv('data/df_train_scaled.csv')\n",
    "df_eval_scaled = pd.read_csv('data/df_eval_scaled.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7579517f",
   "metadata": {},
   "source": [
    "# DeepHit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "036e1ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\t[0s / 0s],\t\ttrain_loss: 0.5874\n",
      "1:\t[0s / 0s],\t\ttrain_loss: 0.5185\n",
      "2:\t[0s / 0s],\t\ttrain_loss: 0.4812\n",
      "3:\t[0s / 0s],\t\ttrain_loss: 0.4521\n",
      "4:\t[0s / 0s],\t\ttrain_loss: 0.4431\n",
      "5:\t[0s / 0s],\t\ttrain_loss: 0.4201\n",
      "6:\t[0s / 0s],\t\ttrain_loss: 0.4127\n",
      "7:\t[0s / 0s],\t\ttrain_loss: 0.4062\n",
      "8:\t[0s / 0s],\t\ttrain_loss: 0.3975\n",
      "9:\t[0s / 1s],\t\ttrain_loss: 0.3849\n",
      "C-index (Antolini): 0.4351\n",
      "IPCW C-index: 0.5652\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchtuples as tt\n",
    "from pycox.models import DeepHitSingle\n",
    "from pycox.evaluation import EvalSurv\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Préparation des données\n",
    "features = df_train_scaled.drop(columns=['OS_YEARS', 'OS_STATUS'])\n",
    "features_encoded = pd.get_dummies(features, drop_first=True)\n",
    "X = features_encoded.values.astype('float32')\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "durations = df_train_scaled['OS_YEARS'].values\n",
    "events = df_train_scaled['OS_STATUS'].values.astype('bool')\n",
    "\n",
    "# Discrétisation du temps et transformation des labels\n",
    "num_durations = 50\n",
    "labtrans = DeepHitSingle.label_transform(num_durations)\n",
    "y_train = labtrans.fit_transform(durations, events)\n",
    "\n",
    "# Réseau\n",
    "in_features = X.shape[1]\n",
    "num_nodes = [64, 32]\n",
    "out_features = labtrans.out_features\n",
    "net = tt.practical.MLPVanilla(in_features, num_nodes, out_features, batch_norm=True, dropout=0.1, activation=torch.nn.ReLU)\n",
    "\n",
    "# Modèle DeepHit\n",
    "model = DeepHitSingle(net, tt.optim.Adam, alpha=0.2, sigma=0.1, duration_index=labtrans.cuts)\n",
    "model.optimizer.set_lr(0.01)\n",
    "\n",
    "# Early stopping\n",
    "epochs = 100\n",
    "callbacks = [tt.callbacks.EarlyStopping()]\n",
    "\n",
    "# Entraînement\n",
    "log = model.fit(\n",
    "    X, (y_train[0], y_train[1]),\n",
    "    batch_size=128,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    verbose=True,\n",
    "    val_data=None\n",
    ")\n",
    "\n",
    "# Prédiction de survie sur le train\n",
    "surv = model.predict_surv_df(X)\n",
    "\n",
    "# Évaluation Antolini\n",
    "ev = EvalSurv(surv, durations, events, censor_surv='km')\n",
    "c_index = ev.concordance_td('antolini')\n",
    "print(f\"C-index (Antolini): {c_index:.4f}\")\n",
    "\n",
    "# Évaluation IPCW C-index\n",
    "from sksurv.util import Surv\n",
    "from sksurv.metrics import concordance_index_ipcw\n",
    "\n",
    "y_struct = Surv.from_arrays(event=events, time=durations)\n",
    "median_pred = []\n",
    "for surv_curve in surv.values.T:\n",
    "    below_half = np.where(surv_curve <= 0.5)[0]\n",
    "    if below_half.size > 0:\n",
    "        median_pred.append(surv.index[below_half[0]])\n",
    "    else:\n",
    "        median_pred.append(surv.index[-1])\n",
    "median_pred = np.array(median_pred)\n",
    "\n",
    "result = concordance_index_ipcw(\n",
    "    y_struct, y_struct, -median_pred\n",
    ")\n",
    "cindex_ipcw = result[0] if isinstance(result, (tuple, list, np.ndarray)) else result.cindex\n",
    "print(f\"IPCW C-index: {cindex_ipcw:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71827c7",
   "metadata": {},
   "source": [
    "# N-MTLR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8297e013",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_train_scaled.sample(frac=0.2)\n",
    "df_train_scaled = df_train_scaled.drop(df_test.index)\n",
    "df_val = df_train_scaled.sample(frac=0.2)\n",
    "df_train = df_train_scaled.drop(df_val.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d762202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_durations = 10\n",
    "labtrans = MTLR.label_transform(num_durations)\n",
    "get_target = lambda df: (df['duration'].values, df['event'].values)\n",
    "y_train = labtrans.fit_transform(*get_target(df_train))\n",
    "y_val = labtrans.transform(*get_target(df_val))\n",
    "\n",
    "train = (x_train, y_train)\n",
    "val = (x_val, y_val)\n",
    "\n",
    "# We don't need to transform the test labels\n",
    "durations_test, events_test = get_target(df_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
