{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Importation des librairies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "collapsed": true,
        "id": "cJYyGsEWwBsx",
        "outputId": "484a2621-e6b3-4063-a765-2642a03b0f9c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import os.path\n",
        "\n",
        "from sklearn.tree import plot_tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sksurv.ensemble import RandomSurvivalForest\n",
        "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
        "from sksurv.metrics import concordance_index_censored , concordance_index_ipcw\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sksurv.util import Surv\n",
        "from lifelines.utils import concordance_index\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qnZmbXTe0WBc"
      },
      "outputs": [],
      "source": [
        "clinical_test=pd.read_csv('clinical_test.csv')\n",
        "clinical_train=pd.read_csv('clinical_train.csv')\n",
        "\n",
        "molecular_test=pd.read_csv('molecular_test.csv')\n",
        "molecular_train=pd.read_csv('molecular_train.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "s7wOdy5TBuqf"
      },
      "outputs": [],
      "source": [
        "target_df=pd.read_csv('target_train.csv')\n",
        "\n",
        "# Drop rows where 'OS_YEARS' is NaN if conversion caused any issues\n",
        "target_df.dropna(subset=['OS_YEARS', 'OS_STATUS'], inplace=True)\n",
        "\n",
        "\n",
        "# Contarget_dfvert 'OS_YEARS' to numeric if it isn’t already\n",
        "target_df['OS_YEARS'] = pd.to_numeric(target_df['OS_YEARS'], errors='coerce')\n",
        "\n",
        "# Ensure 'OS_STATUS' is boolean\n",
        "target_df['OS_STATUS'] = target_df['OS_STATUS'].astype(bool)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LoqKGgFMOoqI",
        "outputId": "fc073aa5-cc60-4e9d-b070-345ecc99e34f"
      },
      "outputs": [],
      "source": [
        "def handle_missing_values(df):\n",
        "    for col in df.columns:\n",
        "        if df[col].isnull().any():\n",
        "            if df[col].dtype in [np.int64, np.float64]:\n",
        "                # Numérique : remplacer par la médiane\n",
        "                median_val = df[col].median()\n",
        "                df[col] = df[col].fillna(median_val)\n",
        "            else:\n",
        "                # Catégoriel : remplacer par 'Missing'\n",
        "                df[col] = df[col].fillna('Missing')\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colonnes disponibles: ['ID', 'CHR', 'START', 'END', 'REF', 'ALT', 'GENE', 'PROTEIN_CHANGE', 'EFFECT', 'VAF', 'DEPTH']\n",
            "Colonnes disponibles: ['ID', 'CHR', 'START', 'END', 'REF', 'ALT', 'GENE', 'PROTEIN_CHANGE', 'EFFECT', 'VAF', 'DEPTH']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def aggregate_leukemia_data(df):\n",
        "    \"\"\"\n",
        "    Agrégation simple des données de mutations par patient\n",
        "    \"\"\"\n",
        "    \n",
        "    # Gènes à haut risque\n",
        "    high_risk_genes = ['TP53', 'ASXL1', 'RUNX1', 'FLT3', 'EZH2', 'DNMT3A', 'TET2', 'IDH1', 'IDH2']\n",
        "    \n",
        "    # Gènes à bon pronostic  \n",
        "    good_genes = ['NPM1', 'CEBPA']\n",
        "    \n",
        "    # Effets délétères\n",
        "    bad_effects = ['nonsense', 'frameshift', 'splice_site', 'stop_gained']\n",
        "    \n",
        "    # D'abord voir les colonnes disponibles\n",
        "    print(\"Colonnes disponibles:\", df.columns.tolist())\n",
        "    \n",
        "    # Agrégation de base\n",
        "    result = df.groupby('ID').agg({\n",
        "        'GENE': ['count', 'nunique'],\n",
        "        'CHR': 'nunique',\n",
        "        'VAF': ['mean', 'max', 'median'],\n",
        "        'DEPTH': ['mean', 'min']\n",
        "    }).reset_index()\n",
        "    \n",
        "    # Simplifier les noms de colonnes\n",
        "    result.columns = ['ID', 'nb_mutations', 'nb_genes', 'nb_chromosomes', \n",
        "                      'vaf_mean', 'vaf_max', 'vaf_median', 'depth_mean', 'depth_min']\n",
        "    \n",
        "    # Ajouter les variables spécifiques\n",
        "    for patient_id in result['ID']:\n",
        "        patient_data = df[df['ID'] == patient_id]\n",
        "        \n",
        "        # Gènes à risque\n",
        "        result.loc[result['ID'] == patient_id, 'nb_high_risk_genes'] = len(set(patient_data['GENE']) & set(high_risk_genes))\n",
        "        result.loc[result['ID'] == patient_id, 'nb_good_genes'] = len(set(patient_data['GENE']) & set(good_genes))\n",
        "        \n",
        "        # Effets délétères\n",
        "        result.loc[result['ID'] == patient_id, 'nb_bad_effects'] = patient_data['EFFECT'].isin(bad_effects).sum()\n",
        "        \n",
        "        # Mutations importantes\n",
        "        result.loc[result['ID'] == patient_id, 'has_TP53'] = int('TP53' in patient_data['GENE'].values)\n",
        "        result.loc[result['ID'] == patient_id, 'has_FLT3'] = int('FLT3' in patient_data['GENE'].values)\n",
        "        result.loc[result['ID'] == patient_id, 'has_NPM1'] = int('NPM1' in patient_data['GENE'].values)\n",
        "        \n",
        "        # VAF élevée (charge mutationelle)\n",
        "        result.loc[result['ID'] == patient_id, 'nb_high_vaf'] = (patient_data['VAF'] > 0.4).sum()\n",
        "    \n",
        "    # Score de risque simple\n",
        "    result['risk_score'] = (result['nb_high_risk_genes'] * 2 + \n",
        "                           result['nb_bad_effects'] + \n",
        "                           result['nb_high_vaf'] * 0.5 - \n",
        "                           result['nb_good_genes'])\n",
        "    \n",
        "    return result\n",
        "\n",
        "molecular_train = aggregate_leukemia_data(molecular_train)\n",
        "molecular_test = aggregate_leukemia_data(molecular_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "\n",
        "# print(\"=== ANALYSE DES VARIABLES CATÉGORIELLES DE molecular_test (SAUF ID) ===\\n\")\n",
        "\n",
        "# # Identifier les variables catégorielles (exclure ID)\n",
        "# categorical_cols = molecular_test.select_dtypes(include=['object']).columns\n",
        "# categorical_cols = [col for col in categorical_cols if col != 'ID']  # Exclure ID\n",
        "# numerical_cols = molecular_test.select_dtypes(include=['number']).columns\n",
        "\n",
        "# print(f\"Variables catégorielles (sauf ID): {list(categorical_cols)}\")\n",
        "# print(f\"Variables numériques: {list(numerical_cols)}\\n\")\n",
        "\n",
        "# # Analyser chaque variable catégorielle\n",
        "# for col in categorical_cols:\n",
        "#     print(f\"--- {col} ---\")\n",
        "#     unique_values = molecular_test[col].unique()\n",
        "#     print(f\"Nombre de valeurs uniques: {len(unique_values)}\")\n",
        "    \n",
        "#     # Gérer le tri en séparant les NaN et les valeurs non-numériques\n",
        "#     try:\n",
        "#         # Essayer de trier normalement\n",
        "#         sorted_values = sorted(unique_values)\n",
        "#         print(f\"Valeurs uniques: {sorted_values}\")\n",
        "#     except TypeError:\n",
        "#         # Si erreur de tri, afficher sans trier\n",
        "#         print(f\"Valeurs uniques (non triées): {list(unique_values)}\")\n",
        "    \n",
        "#     print(f\"Valeurs manquantes: {molecular_test[col].isnull().sum()}\")\n",
        "#     print()\n",
        "\n",
        "# # Analyse spéciale pour les variables numériques qui pourraient être catégorielles\n",
        "# print(\"=== VARIABLES NUMÉRIQUES QUI POURRAIENT ÊTRE CATÉGORIELLES ===\\n\")\n",
        "\n",
        "# for col in numerical_cols:\n",
        "#     unique_count = molecular_test[col].nunique()\n",
        "#     total_count = len(molecular_test)\n",
        "    \n",
        "#     # Si moins de 20% de valeurs uniques, considérer comme potentiellement catégorielle\n",
        "#     if unique_count / total_count < 0.2:\n",
        "#         print(f\"--- {col} (potentiellement catégorielle) ---\")\n",
        "#         print(f\"Nombre de valeurs uniques: {unique_count}\")\n",
        "#         try:\n",
        "#             sorted_values = sorted(molecular_test[col].unique())\n",
        "#             print(f\"Valeurs uniques: {sorted_values}\")\n",
        "#         except TypeError:\n",
        "#             print(f\"Valeurs uniques (non triées): {list(molecular_test[col].unique())}\")\n",
        "#         print(f\"Valeurs manquantes: {molecular_test[col].isnull().sum()}\")\n",
        "#         print()\n",
        "\n",
        "# # Statistiques générales\n",
        "# print(\"=== STATISTIQUES GÉNÉRALES ===\\n\")\n",
        "# print(f\"Nombre total de lignes: {len(molecular_test)}\")\n",
        "# print(f\"Nombre de patients uniques: {molecular_test['ID'].nunique()}\")\n",
        "# print(f\"Nombre de gènes uniques: {molecular_test['GENE'].nunique()}\")\n",
        "# print(f\"Nombre de chromosomes uniques: {molecular_test['CHR'].nunique()}\")\n",
        "# print(f\"Nombre d'effets uniques: {molecular_test['EFFECT'].nunique()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qTN7kbb01RpM"
      },
      "outputs": [],
      "source": [
        "def add_cytogenetic_features(data):\n",
        "    # Indicateur si le caryotype est \"Normal\"\n",
        "    data[\"is_normal\"] = data[\"CYTOGENETICS\"].str.contains(\"Normal\", case=False, na=False).astype(int)\n",
        "\n",
        "    # Extraction du nombre total de chromosomes\n",
        "    data[\"total_chromosomes\"] = data[\"CYTOGENETICS\"].str.extract(r\"^(\\d+)\", expand=False).astype(float)\n",
        "    data.loc[data[\"is_normal\"] == 1, \"total_chromosomes\"] = 46  # Valeur par défaut pour caryotype normal\n",
        "\n",
        "    # Normalisation de la casse des chromosomes (tout en majuscule)\n",
        "    data[\"CYTOGENETICS\"] = data[\"CYTOGENETICS\"].str.upper()\n",
        "\n",
        "    # Extraction du sexe brut (ex: XY, XX)\n",
        "    data[\"sex_raw\"] = data[\"CYTOGENETICS\"].str.extract(r\"\\b(XX|XY|XYY|XXY|XXX|YY)\\b\", expand=False)\n",
        "\n",
        "    # Normalisation du sexe : catégorisation des cas atypiques\n",
        "    def normalize_sex(s):\n",
        "        if s in [\"XX\", \"XY\"]:\n",
        "            return s  # Sexe standard\n",
        "        elif pd.notna(s):\n",
        "            return \"Other\"  # Cas atypiques connus\n",
        "        return \"Unknown\"  # Non défini\n",
        "\n",
        "    data[\"sex\"] = data[\"sex_raw\"].apply(normalize_sex)\n",
        "\n",
        "    # Nettoyage des colonnes intermédiaires\n",
        "    data.drop(columns=[\"sex_raw\"], inplace=True)\n",
        "\n",
        "    return data\n",
        "\n",
        "# Appliquer la fonction aux datasets\n",
        "clinical_test = add_cytogenetic_features(clinical_test)\n",
        "clinical_train = add_cytogenetic_features(clinical_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "zwcMsT1Waem9"
      },
      "outputs": [],
      "source": [
        "clinical_test = clinical_test.drop('CYTOGENETICS', axis=1)\n",
        "clinical_train = clinical_train.drop('CYTOGENETICS', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train = clinical_train.merge(molecular_train, on='ID', how='left').fillna(0)\n",
        "df_test = clinical_test.merge(molecular_test, on='ID', how='left').fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WI1vvf4_cfKH"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Select numerical columns excluding 'OS_YEARS' and ID (which is an identifier)\n",
        "numerical_cols_train = df_train.select_dtypes(include=np.number).columns.tolist()\n",
        "numerical_cols_test = df_test.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "\n",
        "if 'OS_YEARS' in numerical_cols_train:\n",
        "    numerical_cols_train.remove('OS_YEARS') # Exclude the target variable\n",
        "if 'OS_STATUS' in numerical_cols_train:\n",
        "    numerical_cols_train.remove('OS_STATUS') # Exclude the target variable\n",
        "\n",
        "# Initialize StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit and transform on the training data using the filtered numerical columns\n",
        "df_train[numerical_cols_train] = scaler.fit_transform(df_train[numerical_cols_train])\n",
        "\n",
        "# Transform on the test data using the filtered numerical columns (and scaler fitted on training data)\n",
        "# Need to ensure the columns in df_test match the columns used for fitting the scaler on df_train\n",
        "numerical_cols_test_filtered = [col for col in numerical_cols_train if col in numerical_cols_test]\n",
        "df_test[numerical_cols_test_filtered] = scaler.transform(df_test[numerical_cols_test_filtered])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train = df_train.merge(target_df, on='ID', how='inner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "b6EjsUgMNTCe"
      },
      "outputs": [],
      "source": [
        "# prompt: supprime les variables ID et CENTER de df_train et de df_test\n",
        "ID_test = df_test['ID']\n",
        "\n",
        "df_train = df_train.drop(['ID', 'CENTER'], axis=1)\n",
        "df_test = df_test.drop(['ID', 'CENTER'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MODELE FLAML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n",
            "Warning: Your H2O cluster version is (3 months and 21 days) old.  There may be a newer version available.\n",
            "Please download and install the latest version from: https://h2o-release.s3.amazonaws.com/h2o/latest_stable.html\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "#h2o-table-5.h2o-container {\n",
              "  overflow-x: auto;\n",
              "}\n",
              "#h2o-table-5 .h2o-table {\n",
              "  /* width: 100%; */\n",
              "  margin-top: 1em;\n",
              "  margin-bottom: 1em;\n",
              "}\n",
              "#h2o-table-5 .h2o-table caption {\n",
              "  white-space: nowrap;\n",
              "  caption-side: top;\n",
              "  text-align: left;\n",
              "  /* margin-left: 1em; */\n",
              "  margin: 0;\n",
              "  font-size: larger;\n",
              "}\n",
              "#h2o-table-5 .h2o-table thead {\n",
              "  white-space: nowrap; \n",
              "  position: sticky;\n",
              "  top: 0;\n",
              "  box-shadow: 0 -1px inset;\n",
              "}\n",
              "#h2o-table-5 .h2o-table tbody {\n",
              "  overflow: auto;\n",
              "}\n",
              "#h2o-table-5 .h2o-table th,\n",
              "#h2o-table-5 .h2o-table td {\n",
              "  text-align: right;\n",
              "  /* border: 1px solid; */\n",
              "}\n",
              "#h2o-table-5 .h2o-table tr:nth-child(even) {\n",
              "  /* background: #F5F5F5 */\n",
              "}\n",
              "\n",
              "</style>      \n",
              "<div id=\"h2o-table-5\" class=\"h2o-container\">\n",
              "  <table class=\"h2o-table\">\n",
              "    <caption></caption>\n",
              "    <thead></thead>\n",
              "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
              "<td>6 mins 38 secs</td></tr>\n",
              "<tr><td>H2O_cluster_timezone:</td>\n",
              "<td>Europe/Paris</td></tr>\n",
              "<tr><td>H2O_data_parsing_timezone:</td>\n",
              "<td>UTC</td></tr>\n",
              "<tr><td>H2O_cluster_version:</td>\n",
              "<td>3.46.0.7</td></tr>\n",
              "<tr><td>H2O_cluster_version_age:</td>\n",
              "<td>3 months and 21 days</td></tr>\n",
              "<tr><td>H2O_cluster_name:</td>\n",
              "<td>H2O_from_python_arthr_4us451</td></tr>\n",
              "<tr><td>H2O_cluster_total_nodes:</td>\n",
              "<td>1</td></tr>\n",
              "<tr><td>H2O_cluster_free_memory:</td>\n",
              "<td>3.341 Gb</td></tr>\n",
              "<tr><td>H2O_cluster_total_cores:</td>\n",
              "<td>16</td></tr>\n",
              "<tr><td>H2O_cluster_allowed_cores:</td>\n",
              "<td>16</td></tr>\n",
              "<tr><td>H2O_cluster_status:</td>\n",
              "<td>locked, healthy</td></tr>\n",
              "<tr><td>H2O_connection_url:</td>\n",
              "<td>http://localhost:54321</td></tr>\n",
              "<tr><td>H2O_connection_proxy:</td>\n",
              "<td>{\"http\": null, \"https\": null}</td></tr>\n",
              "<tr><td>H2O_internal_security:</td>\n",
              "<td>False</td></tr>\n",
              "<tr><td>Python_version:</td>\n",
              "<td>3.12.10 final</td></tr></tbody>\n",
              "  </table>\n",
              "</div>\n"
            ],
            "text/plain": [
              "--------------------------  -----------------------------\n",
              "H2O_cluster_uptime:         6 mins 38 secs\n",
              "H2O_cluster_timezone:       Europe/Paris\n",
              "H2O_data_parsing_timezone:  UTC\n",
              "H2O_cluster_version:        3.46.0.7\n",
              "H2O_cluster_version_age:    3 months and 21 days\n",
              "H2O_cluster_name:           H2O_from_python_arthr_4us451\n",
              "H2O_cluster_total_nodes:    1\n",
              "H2O_cluster_free_memory:    3.341 Gb\n",
              "H2O_cluster_total_cores:    16\n",
              "H2O_cluster_allowed_cores:  16\n",
              "H2O_cluster_status:         locked, healthy\n",
              "H2O_connection_url:         http://localhost:54321\n",
              "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
              "H2O_internal_security:      False\n",
              "Python_version:             3.12.10 final\n",
              "--------------------------  -----------------------------"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
            "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "H2OCoxProportionalHazardsEstimator.__init__() got an unexpected keyword argument 'event_column'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     28\u001b[39m event_col = \u001b[33m'\u001b[39m\u001b[33mOS_STATUS\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Entraînement du modèle CoxPH (event_column à l'instanciation)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m coxph = \u001b[43mH2OCoxProportionalHazardsEstimator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent_column\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevent_col\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m coxph.train(x=x, y=time_col, training_frame=h2o_train)\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Prédiction sur le test\u001b[39;00m\n",
            "\u001b[31mTypeError\u001b[39m: H2OCoxProportionalHazardsEstimator.__init__() got an unexpected keyword argument 'event_column'"
          ]
        }
      ],
      "source": [
        "import h2o\n",
        "from h2o.estimators import H2OCoxProportionalHazardsEstimator\n",
        "\n",
        "h2o.init(max_mem_size=\"4G\")\n",
        "\n",
        "# Préparation des données\n",
        "train = df_train.copy()\n",
        "test = df_test.copy()\n",
        "\n",
        "# Forcer les bons types\n",
        "train['OS_YEARS'] = train['OS_YEARS'].astype(float)\n",
        "train['OS_STATUS'] = train['OS_STATUS'].astype(int).astype('category')\n",
        "test['OS_YEARS'] = 0.0  # ou np.nan si inconnu\n",
        "test['OS_STATUS'] = 0   # ou np.nan si inconnu\n",
        "test['OS_STATUS'] = test['OS_STATUS'].astype(int).astype('category')\n",
        "\n",
        "# Encodage des variables catégorielles\n",
        "for col in train.select_dtypes(include='object').columns:\n",
        "    train[col] = train[col].astype('category')\n",
        "    if col in test.columns:\n",
        "        test[col] = test[col].astype('category')\n",
        "\n",
        "h2o_train = h2o.H2OFrame(train)\n",
        "h2o_test = h2o.H2OFrame(test)\n",
        "\n",
        "x = [col for col in train.columns if col not in ['OS_YEARS', 'OS_STATUS']]\n",
        "time_col = 'OS_YEARS'\n",
        "event_col = 'OS_STATUS'\n",
        "\n",
        "# Entraînement du modèle CoxPH (event_column à l'instanciation)\n",
        "coxph = H2OCoxProportionalHazardsEstimator()\n",
        "coxph.train(x=x, y=time_col, training_frame=h2o_train)\n",
        "\n",
        "# Prédiction sur le test\n",
        "pred = coxph.predict(h2o_test)\n",
        "risk_score = pred.as_data_frame()['risk_index']  # plus haut = plus risqué\n",
        "\n",
        "submission = pd.DataFrame({'ID': ID_test.values, 'risk_score': risk_score})\n",
        "submission.to_csv('submission_h2o_coxph.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
